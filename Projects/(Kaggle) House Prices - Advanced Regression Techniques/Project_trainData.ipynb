{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de0d812d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno #Heatmap\n",
    "import sklearn\n",
    "import xgboost #ML algo\n",
    "from sklearn.ensemble import RandomForestRegressor #ML algo\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn import linear_model #ML algo\n",
    "import pickle \n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LeakyReLU,PReLU,ELU\n",
    "from keras.layers import Dropout\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53440f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('project/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f71a4c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8244873e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e39e8abe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "msno.heatmap(df) #corrlations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c57002b",
   "metadata": {},
   "source": [
    "# Imputation the missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "085e1afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Alley'],axis=1,inplace=True)\n",
    "df.drop(['GarageYrBlt'],axis=1,inplace=True)\n",
    "df.drop(['PoolQC','Fence','MiscFeature'],axis=1,inplace=True)\n",
    "df.drop(['Id'],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb392bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LotFrontage']=df['LotFrontage'].fillna(df['LotFrontage'].mean())\n",
    "df['BsmtCond']=df['BsmtCond'].fillna(df['BsmtCond'].mode()[0])#mode of this column\n",
    "df['BsmtQual']=df['BsmtQual'].fillna(df['BsmtQual'].mode()[0])\n",
    "df['FireplaceQu']=df['FireplaceQu'].fillna(df['FireplaceQu'].mode()[0])\n",
    "df['GarageType']=df['GarageType'].fillna(df['GarageType'].mode()[0])\n",
    "df['GarageFinish']=df['GarageFinish'].fillna(df['GarageFinish'].mode()[0])\n",
    "df['GarageQual']=df['GarageQual'].fillna(df['GarageQual'].mode()[0])\n",
    "df['GarageCond']=df['GarageCond'].fillna(df['GarageCond'].mode()[0])\n",
    "df['MasVnrType']=df['MasVnrType'].fillna(df['MasVnrType'].mode()[0])\n",
    "df['MasVnrArea']=df['MasVnrArea'].fillna(df['MasVnrArea'].mode()[0])\n",
    "df['BsmtExposure']=df['BsmtExposure'].fillna(df['BsmtExposure'].mode()[0])\n",
    "df['BsmtFinType2']=df['BsmtFinType2'].fillna(df['BsmtFinType2'].mode()[0])\n",
    "df.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36c5e314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSSubClass       0\n",
       "MSZoning         0\n",
       "LotFrontage      0\n",
       "LotArea          0\n",
       "Street           0\n",
       "LotShape         0\n",
       "LandContour      0\n",
       "Utilities        0\n",
       "LotConfig        0\n",
       "LandSlope        0\n",
       "Neighborhood     0\n",
       "Condition1       0\n",
       "Condition2       0\n",
       "BldgType         0\n",
       "HouseStyle       0\n",
       "OverallQual      0\n",
       "OverallCond      0\n",
       "YearBuilt        0\n",
       "YearRemodAdd     0\n",
       "RoofStyle        0\n",
       "RoofMatl         0\n",
       "Exterior1st      0\n",
       "Exterior2nd      0\n",
       "MasVnrType       0\n",
       "MasVnrArea       0\n",
       "ExterQual        0\n",
       "ExterCond        0\n",
       "Foundation       0\n",
       "BsmtQual         0\n",
       "BsmtCond         0\n",
       "BsmtExposure     0\n",
       "BsmtFinType1     0\n",
       "BsmtFinSF1       0\n",
       "BsmtFinType2     0\n",
       "BsmtFinSF2       0\n",
       "BsmtUnfSF        0\n",
       "TotalBsmtSF      0\n",
       "Heating          0\n",
       "HeatingQC        0\n",
       "CentralAir       0\n",
       "Electrical       0\n",
       "1stFlrSF         0\n",
       "2ndFlrSF         0\n",
       "LowQualFinSF     0\n",
       "GrLivArea        0\n",
       "BsmtFullBath     0\n",
       "BsmtHalfBath     0\n",
       "FullBath         0\n",
       "HalfBath         0\n",
       "BedroomAbvGr     0\n",
       "KitchenAbvGr     0\n",
       "KitchenQual      0\n",
       "TotRmsAbvGrd     0\n",
       "Functional       0\n",
       "Fireplaces       0\n",
       "FireplaceQu      0\n",
       "GarageType       0\n",
       "GarageFinish     0\n",
       "GarageCars       0\n",
       "GarageArea       0\n",
       "GarageQual       0\n",
       "GarageCond       0\n",
       "PavedDrive       0\n",
       "WoodDeckSF       0\n",
       "OpenPorchSF      0\n",
       "EnclosedPorch    0\n",
       "3SsnPorch        0\n",
       "ScreenPorch      0\n",
       "PoolArea         0\n",
       "MiscVal          0\n",
       "MoSold           0\n",
       "YrSold           0\n",
       "SaleType         0\n",
       "SaleCondition    0\n",
       "SalePrice        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a02fd946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1422, 75)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a141a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0          60       RL         65.0     8450   Pave      Reg         Lvl   \n",
       "1          20       RL         80.0     9600   Pave      Reg         Lvl   \n",
       "2          60       RL         68.0    11250   Pave      IR1         Lvl   \n",
       "3          70       RL         60.0     9550   Pave      IR1         Lvl   \n",
       "4          60       RL         84.0    14260   Pave      IR1         Lvl   \n",
       "\n",
       "  Utilities LotConfig LandSlope  ... EnclosedPorch 3SsnPorch ScreenPorch  \\\n",
       "0    AllPub    Inside       Gtl  ...             0         0           0   \n",
       "1    AllPub       FR2       Gtl  ...             0         0           0   \n",
       "2    AllPub    Inside       Gtl  ...             0         0           0   \n",
       "3    AllPub    Corner       Gtl  ...           272         0           0   \n",
       "4    AllPub       FR2       Gtl  ...             0         0           0   \n",
       "\n",
       "  PoolArea MiscVal  MoSold  YrSold  SaleType  SaleCondition SalePrice  \n",
       "0        0       0       2    2008        WD         Normal    208500  \n",
       "1        0       0       5    2007        WD         Normal    181500  \n",
       "2        0       0       9    2008        WD         Normal    223500  \n",
       "3        0       0       2    2006        WD        Abnorml    140000  \n",
       "4        0       0      12    2008        WD         Normal    250000  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11ec5e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 39 categorical feature\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['MSZoning',\n",
       " 'Street',\n",
       " 'LotShape',\n",
       " 'LandContour',\n",
       " 'Utilities',\n",
       " 'LotConfig',\n",
       " 'LandSlope',\n",
       " 'Neighborhood',\n",
       " 'Condition1',\n",
       " 'Condition2',\n",
       " 'BldgType',\n",
       " 'HouseStyle',\n",
       " 'RoofStyle',\n",
       " 'RoofMatl',\n",
       " 'Exterior1st',\n",
       " 'Exterior2nd',\n",
       " 'MasVnrType',\n",
       " 'ExterQual',\n",
       " 'ExterCond',\n",
       " 'Foundation',\n",
       " 'BsmtQual',\n",
       " 'BsmtCond',\n",
       " 'BsmtExposure',\n",
       " 'BsmtFinType1',\n",
       " 'BsmtFinType2',\n",
       " 'Heating',\n",
       " 'HeatingQC',\n",
       " 'CentralAir',\n",
       " 'Electrical',\n",
       " 'KitchenQual',\n",
       " 'Functional',\n",
       " 'FireplaceQu',\n",
       " 'GarageType',\n",
       " 'GarageFinish',\n",
       " 'GarageQual',\n",
       " 'GarageCond',\n",
       " 'PavedDrive',\n",
       " 'SaleType',\n",
       " 'SaleCondition']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns=df.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f'There is {len(categorical_columns)} categorical feature')\n",
    "categorical_columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc847b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63bd6f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df=pd.read_csv('handledtestdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01c672c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 75)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_prices=pd.concat([df,concat_df],axis=0) #horizontal concatenation\n",
    "house_prices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8a2bb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function handles the categorical columns\n",
    "def category_onehot_multcols(multcolumns):\n",
    "    final_df=house_prices\n",
    "    i=0\n",
    "    for fields in multcolumns:\n",
    "        \n",
    "        print(fields)\n",
    "        df1=pd.get_dummies(house_prices[fields],drop_first=True)\n",
    "        \n",
    "        house_prices.drop([fields],axis=1,inplace=True)\n",
    "        if i==0:\n",
    "            final_df=df1.copy()\n",
    "        else:\n",
    "            \n",
    "            final_df=pd.concat([final_df,df1],axis=1)\n",
    "        i=i+1\n",
    "       \n",
    "        \n",
    "    final_df=pd.concat([house_prices,final_df],axis=1)\n",
    "        \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9534065a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSZoning\n",
      "Street\n",
      "LotShape\n",
      "LandContour\n",
      "Utilities\n",
      "LotConfig\n",
      "LandSlope\n",
      "Neighborhood\n",
      "Condition1\n",
      "Condition2\n",
      "BldgType\n",
      "HouseStyle\n",
      "RoofStyle\n",
      "RoofMatl\n",
      "Exterior1st\n",
      "Exterior2nd\n",
      "MasVnrType\n",
      "ExterQual\n",
      "ExterCond\n",
      "Foundation\n",
      "BsmtQual\n",
      "BsmtCond\n",
      "BsmtExposure\n",
      "BsmtFinType1\n",
      "BsmtFinType2\n",
      "Heating\n",
      "HeatingQC\n",
      "CentralAir\n",
      "Electrical\n",
      "KitchenQual\n",
      "Functional\n",
      "FireplaceQu\n",
      "GarageType\n",
      "GarageFinish\n",
      "GarageQual\n",
      "GarageCond\n",
      "PavedDrive\n",
      "SaleType\n",
      "SaleCondition\n"
     ]
    }
   ],
   "source": [
    "house_prices=category_onehot_multcols(categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6fc7e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 235)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_prices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d78e963",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df =house_prices.loc[:,~house_prices.columns.duplicated()] #removing duplicates columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d1b5323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 175)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4556c5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Train=final_df.iloc[:1422,:] #The number of observations in train data\n",
    "df_Test=final_df.iloc[1422:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff8d65e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>ConLI</th>\n",
       "      <th>ConLw</th>\n",
       "      <th>New</th>\n",
       "      <th>Oth</th>\n",
       "      <th>WD</th>\n",
       "      <th>AdjLand</th>\n",
       "      <th>Alloca</th>\n",
       "      <th>Family</th>\n",
       "      <th>Normal</th>\n",
       "      <th>Partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0          60         65.0     8450            7            5       2003   \n",
       "1          20         80.0     9600            6            8       1976   \n",
       "2          60         68.0    11250            7            5       2001   \n",
       "3          70         60.0     9550            7            5       1915   \n",
       "4          60         84.0    14260            8            5       2000   \n",
       "\n",
       "   YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  ConLI  ConLw  New  \\\n",
       "0          2003       196.0       706.0         0.0  ...      0      0    0   \n",
       "1          1976         0.0       978.0         0.0  ...      0      0    0   \n",
       "2          2002       162.0       486.0         0.0  ...      0      0    0   \n",
       "3          1970         0.0       216.0         0.0  ...      0      0    0   \n",
       "4          2000       350.0       655.0         0.0  ...      0      0    0   \n",
       "\n",
       "   Oth  WD  AdjLand  Alloca  Family  Normal  Partial  \n",
       "0    0   1        0       0       0       1        0  \n",
       "1    0   1        0       0       0       1        0  \n",
       "2    0   1        0       0       0       1        0  \n",
       "3    0   1        0       0       0       0        0  \n",
       "4    0   1        0       0       0       1        0  \n",
       "\n",
       "[5 rows x 175 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a857e422",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ameen\\AppData\\Local\\Temp\\ipykernel_10332\\191225162.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_Test.drop(['SalePrice'],axis=1,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#Dropping the saleprice column because its values are NaN in test data\n",
    "df_Test.drop(['SalePrice'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4084542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 174)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a945ad5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df_Train.drop(['SalePrice'],axis=1)\n",
    "Y_train=df_Train['SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92df8ae6",
   "metadata": {},
   "source": [
    "# Prediciton and choosing the proper Algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e22b9df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBRegressor\n",
    "classifier=xgboost.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "599a422f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "             importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "             learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "             max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "             missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100, n_jobs=0,\n",
       "             num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "             importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "             learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "             max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "             missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100, n_jobs=0,\n",
       "             num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "             importance_type=None, interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "             max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "             missing=nan, monotone_constraints='()', n_estimators=100, n_jobs=0,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, ...)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc7f6d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving as a pickle, so we won't train it again and again\n",
    "filename = 'finalized_model.pkl'\n",
    "pickle.dump(classifier, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3ee4074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([127646.5 , 144463.1 , 204446.92, ..., 153905.22, 105750.84,\n",
       "       233470.75], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred=classifier.predict(df_Test)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e01b732e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create Sample Submission file and Submit using ANN\n",
    "pred_df=pd.DataFrame(Y_pred) #Converting to DF\n",
    "submission_df=pd.read_csv('Project/sample_submission.csv') #Reading website's sample as csv\n",
    "datasets=pd.concat([submission_df['Id'],pred_df],axis=1) #Taking the ID from the submission after we deleted it at the beggning\n",
    "datasets.columns=['Id','SalePrice']\n",
    "datasets.to_csv('sample_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b6f2651",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Regressor\n",
    "regressor = RandomForestRegressor(n_estimators = 100, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "62f570be",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = regressor.fit(X_train,Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c087ac83",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = regressor.predict(df_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ef7aa2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create Sample Submission file and Submit using ANN\n",
    "pred_df=pd.DataFrame(Y_pred) #Converting to DF\n",
    "submission_df=pd.read_csv('Project/sample_submission.csv') #Reading website's sample as csv\n",
    "datasets=pd.concat([submission_df['Id'],pred_df],axis=1) #Taking the ID from the submission after we deleted it at the beggning\n",
    "datasets.columns=['Id','SalePrice']\n",
    "datasets.to_csv('sample_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0bbba7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "reg = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "afea1a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = reg.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "82486548",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = reg.predict(df_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3ae2a339",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create Sample Submission file and Submit using ANN\n",
    "pred_df=pd.DataFrame(Y_pred) #Converting to DF\n",
    "submission_df=pd.read_csv('Project/sample_submission.csv') #Reading website's sample as csv\n",
    "datasets=pd.concat([submission_df['Id'],pred_df],axis=1) #Taking the ID from the submission after we deleted it at the beggning\n",
    "datasets.columns=['Id','SalePrice']\n",
    "datasets.to_csv('sample_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4523f2ed",
   "metadata": {},
   "source": [
    "# Improvments\n",
    "As far as we have seen, XGB Regression has the best results so far, so we will try to foucs on it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fad52049",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor=xgboost.XGBRegressor()\n",
    "booster=['gbtree','gblinear']\n",
    "base_score=[0.25,0.5,0.75,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0c3681a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyper Parameter Optimization\n",
    "\n",
    "n_estimators = [100, 500, 900, 1100, 1500]\n",
    "max_depth = [2, 3, 5, 10, 15]\n",
    "booster=['gbtree','gblinear']\n",
    "learning_rate=[0.025,0.1,0.15,0.20]\n",
    "min_child_weight=[1,2,3,4]\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "hyperparameter_grid = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_depth':max_depth,\n",
    "    'learning_rate':learning_rate,\n",
    "    'min_child_weight':min_child_weight,\n",
    "    'booster':booster,\n",
    "    'base_score':base_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6928fee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the random search with 4-fold cross validation\n",
    "random_cv = sklearn.model_selection.RandomizedSearchCV(estimator=regressor,\n",
    "            param_distributions=hyperparameter_grid,\n",
    "            cv=5, n_iter=50,\n",
    "            scoring = 'neg_mean_absolute_error',n_jobs = 4,\n",
    "            verbose = 5, \n",
    "            return_train_score = True,\n",
    "            random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "98683ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          callbacks=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None,\n",
       "                                          early_stopping_rounds=None,\n",
       "                                          enable_categorical=False,\n",
       "                                          eval_metric=None, gamma=None,\n",
       "                                          gpu_id=None, grow_policy=None,\n",
       "                                          importance_type=None,\n",
       "                                          interaction_constraints=None,\n",
       "                                          learning_rate=None, max_bin=None,\n",
       "                                          m...\n",
       "                                          reg_alpha=None, reg_lambda=None, ...),\n",
       "                   n_iter=50, n_jobs=4,\n",
       "                   param_distributions={&#x27;base_score&#x27;: [0.25, 0.5, 0.75, 1],\n",
       "                                        &#x27;booster&#x27;: [&#x27;gbtree&#x27;, &#x27;gblinear&#x27;],\n",
       "                                        &#x27;learning_rate&#x27;: [0.025, 0.1, 0.15,\n",
       "                                                          0.2],\n",
       "                                        &#x27;max_depth&#x27;: [2, 3, 5, 10, 15],\n",
       "                                        &#x27;min_child_weight&#x27;: [1, 2, 3, 4],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 500, 900, 1100,\n",
       "                                                         1500]},\n",
       "                   random_state=42, return_train_score=True,\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;, verbose=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          callbacks=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None,\n",
       "                                          early_stopping_rounds=None,\n",
       "                                          enable_categorical=False,\n",
       "                                          eval_metric=None, gamma=None,\n",
       "                                          gpu_id=None, grow_policy=None,\n",
       "                                          importance_type=None,\n",
       "                                          interaction_constraints=None,\n",
       "                                          learning_rate=None, max_bin=None,\n",
       "                                          m...\n",
       "                                          reg_alpha=None, reg_lambda=None, ...),\n",
       "                   n_iter=50, n_jobs=4,\n",
       "                   param_distributions={&#x27;base_score&#x27;: [0.25, 0.5, 0.75, 1],\n",
       "                                        &#x27;booster&#x27;: [&#x27;gbtree&#x27;, &#x27;gblinear&#x27;],\n",
       "                                        &#x27;learning_rate&#x27;: [0.025, 0.1, 0.15,\n",
       "                                                          0.2],\n",
       "                                        &#x27;max_depth&#x27;: [2, 3, 5, 10, 15],\n",
       "                                        &#x27;min_child_weight&#x27;: [1, 2, 3, 4],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 500, 900, 1100,\n",
       "                                                         1500]},\n",
       "                   random_state=42, return_train_score=True,\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;, verbose=5)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, gamma=None,\n",
       "             gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "             num_parallel_tree=None, predictor=None, random_state=None,\n",
       "             reg_alpha=None, reg_lambda=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, gamma=None,\n",
       "             gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "             num_parallel_tree=None, predictor=None, random_state=None,\n",
       "             reg_alpha=None, reg_lambda=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          callbacks=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None,\n",
       "                                          early_stopping_rounds=None,\n",
       "                                          enable_categorical=False,\n",
       "                                          eval_metric=None, gamma=None,\n",
       "                                          gpu_id=None, grow_policy=None,\n",
       "                                          importance_type=None,\n",
       "                                          interaction_constraints=None,\n",
       "                                          learning_rate=None, max_bin=None,\n",
       "                                          m...\n",
       "                                          reg_alpha=None, reg_lambda=None, ...),\n",
       "                   n_iter=50, n_jobs=4,\n",
       "                   param_distributions={'base_score': [0.25, 0.5, 0.75, 1],\n",
       "                                        'booster': ['gbtree', 'gblinear'],\n",
       "                                        'learning_rate': [0.025, 0.1, 0.15,\n",
       "                                                          0.2],\n",
       "                                        'max_depth': [2, 3, 5, 10, 15],\n",
       "                                        'min_child_weight': [1, 2, 3, 4],\n",
       "                                        'n_estimators': [100, 500, 900, 1100,\n",
       "                                                         1500]},\n",
       "                   random_state=42, return_train_score=True,\n",
       "                   scoring='neg_mean_absolute_error', verbose=5)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cv.fit(X_train,Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e3b3525e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_esti=random_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c3d2ed21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=0.25, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "             importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "             learning_rate=0.1, max_bin=256, max_cat_to_onehot=4,\n",
       "             max_delta_step=0, max_depth=2, max_leaves=0, min_child_weight=1,\n",
       "             missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=900, n_jobs=0,\n",
       "             num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=0.25, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "             importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "             learning_rate=0.1, max_bin=256, max_cat_to_onehot=4,\n",
       "             max_delta_step=0, max_depth=2, max_leaves=0, min_child_weight=1,\n",
       "             missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=900, n_jobs=0,\n",
       "             num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=0.25, booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "             importance_type=None, interaction_constraints='',\n",
       "             learning_rate=0.1, max_bin=256, max_cat_to_onehot=4,\n",
       "             max_delta_step=0, max_depth=2, max_leaves=0, min_child_weight=1,\n",
       "             missing=nan, monotone_constraints='()', n_estimators=900, n_jobs=0,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, ...)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_esti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8d12d3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor=xgboost.XGBRegressor(base_score=0.25, booster='gbtree',callbacks=None, colsample_bylevel=1,colsample_bynode=1,\n",
    "       colsample_bytree=1,early_stopping_rounds=None, enable_categorical=False,\n",
    "                              eval_metric=None,  gamma=0,gpu_id=-1,grow_policy='depthwise',importance_type=None,interaction_constraints='',\n",
    "                               learning_rate=0.1,max_bin=256, max_cat_to_onehot=4, max_delta_step=0,\n",
    "       max_depth=2,max_leaves=0, min_child_weight=1,monotone_constraints='()', n_estimators=900,\n",
    "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4e8b1c79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:24:22] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/objective/regression_obj.cu:203: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[09:24:22] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=0.25, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "             importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "             learning_rate=0.1, max_bin=256, max_cat_to_onehot=4,\n",
       "             max_delta_step=0, max_depth=2, max_leaves=0, min_child_weight=1,\n",
       "             missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=900, n_jobs=1,\n",
       "             nthread=1, num_parallel_tree=1, objective=&#x27;reg:linear&#x27;,\n",
       "             predictor=&#x27;auto&#x27;, random_state=0, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=0.25, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "             importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "             learning_rate=0.1, max_bin=256, max_cat_to_onehot=4,\n",
       "             max_delta_step=0, max_depth=2, max_leaves=0, min_child_weight=1,\n",
       "             missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=900, n_jobs=1,\n",
       "             nthread=1, num_parallel_tree=1, objective=&#x27;reg:linear&#x27;,\n",
       "             predictor=&#x27;auto&#x27;, random_state=0, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=0.25, booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "             importance_type=None, interaction_constraints='',\n",
       "             learning_rate=0.1, max_bin=256, max_cat_to_onehot=4,\n",
       "             max_delta_step=0, max_depth=2, max_leaves=0, min_child_weight=1,\n",
       "             missing=nan, monotone_constraints='()', n_estimators=900, n_jobs=1,\n",
       "             nthread=1, num_parallel_tree=1, objective='reg:linear',\n",
       "             predictor='auto', random_state=0, ...)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "927e2ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'finalized_model.pkl'\n",
    "pickle.dump(classifier, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "86ea7d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = regressor.predict(df_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "92aa7d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create Sample Submission file and Submit using ANN\n",
    "pred_df=pd.DataFrame(Y_pred) #Converting to DF\n",
    "submission_df=pd.read_csv('Project/sample_submission.csv') #Reading website's sample as csv\n",
    "datasets=pd.concat([submission_df['Id'],pred_df],axis=1) #Taking the ID from the submission after we deleted it at the beggning\n",
    "datasets.columns=['Id','SalePrice']\n",
    "datasets.to_csv('sample_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625f4e2d",
   "metadata": {},
   "source": [
    "# Artifical Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8ee22a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "114/114 [==============================] - 1s 2ms/step - loss: 34815582208.0000 - val_loss: 28644995072.0000\n",
      "Epoch 2/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 18113654784.0000 - val_loss: 10516043776.0000\n",
      "Epoch 3/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 8930663424.0000 - val_loss: 6558352384.0000\n",
      "Epoch 4/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 7074913792.0000 - val_loss: 5745037312.0000\n",
      "Epoch 5/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 6482576896.0000 - val_loss: 5453433344.0000\n",
      "Epoch 6/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 6130475008.0000 - val_loss: 5290436096.0000\n",
      "Epoch 7/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 5834730496.0000 - val_loss: 5160568832.0000\n",
      "Epoch 8/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 5581344768.0000 - val_loss: 5068367360.0000\n",
      "Epoch 9/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 5356174336.0000 - val_loss: 4979109888.0000\n",
      "Epoch 10/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 5115859968.0000 - val_loss: 4873185280.0000\n",
      "Epoch 11/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 4887395840.0000 - val_loss: 4773040640.0000\n",
      "Epoch 12/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 4676846080.0000 - val_loss: 4701992960.0000\n",
      "Epoch 13/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 4457498112.0000 - val_loss: 4597073920.0000\n",
      "Epoch 14/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 4276581632.0000 - val_loss: 4531177984.0000\n",
      "Epoch 15/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 4118549760.0000 - val_loss: 4442544128.0000\n",
      "Epoch 16/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 3945312768.0000 - val_loss: 4369540096.0000\n",
      "Epoch 17/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 3780193024.0000 - val_loss: 4282170112.0000\n",
      "Epoch 18/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 3638306048.0000 - val_loss: 4188294400.0000\n",
      "Epoch 19/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 3473299456.0000 - val_loss: 4111822848.0000\n",
      "Epoch 20/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 3331509760.0000 - val_loss: 4023879936.0000\n",
      "Epoch 21/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 3200124416.0000 - val_loss: 3942668288.0000\n",
      "Epoch 22/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 3062993664.0000 - val_loss: 3862263552.0000\n",
      "Epoch 23/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 2929436928.0000 - val_loss: 3793008640.0000\n",
      "Epoch 24/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 2790050304.0000 - val_loss: 3688921600.0000\n",
      "Epoch 25/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 2664243712.0000 - val_loss: 3609022720.0000\n",
      "Epoch 26/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 2537579776.0000 - val_loss: 3512920832.0000\n",
      "Epoch 27/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 2404956416.0000 - val_loss: 3482546176.0000\n",
      "Epoch 28/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 2297595904.0000 - val_loss: 3376034048.0000\n",
      "Epoch 29/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 2200251136.0000 - val_loss: 3301428992.0000\n",
      "Epoch 30/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 2077338368.0000 - val_loss: 3252279296.0000\n",
      "Epoch 31/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1996316928.0000 - val_loss: 3257660416.0000\n",
      "Epoch 32/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1920003968.0000 - val_loss: 3187671296.0000\n",
      "Epoch 33/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1838666624.0000 - val_loss: 3208481280.0000\n",
      "Epoch 34/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1789632384.0000 - val_loss: 3312823040.0000\n",
      "Epoch 35/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1725874944.0000 - val_loss: 3237043968.0000\n",
      "Epoch 36/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1698361984.0000 - val_loss: 3259100160.0000\n",
      "Epoch 37/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1667507456.0000 - val_loss: 3230200064.0000\n",
      "Epoch 38/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1644493696.0000 - val_loss: 3318762752.0000\n",
      "Epoch 39/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1617848832.0000 - val_loss: 3442551296.0000\n",
      "Epoch 40/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1622836992.0000 - val_loss: 3387606016.0000\n",
      "Epoch 41/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1617652224.0000 - val_loss: 3355607296.0000\n",
      "Epoch 42/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1600304896.0000 - val_loss: 3341382400.0000\n",
      "Epoch 43/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1590586368.0000 - val_loss: 3525731584.0000\n",
      "Epoch 44/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1582912640.0000 - val_loss: 3359432960.0000\n",
      "Epoch 45/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1587601408.0000 - val_loss: 3337050880.0000\n",
      "Epoch 46/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1596692352.0000 - val_loss: 3304769024.0000\n",
      "Epoch 47/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1582181120.0000 - val_loss: 3416829952.0000\n",
      "Epoch 48/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1584986368.0000 - val_loss: 3496953344.0000\n",
      "Epoch 49/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1587166336.0000 - val_loss: 3380419584.0000\n",
      "Epoch 50/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1575409664.0000 - val_loss: 3419694592.0000\n",
      "Epoch 51/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1577152000.0000 - val_loss: 3345520896.0000\n",
      "Epoch 52/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1580225024.0000 - val_loss: 3394815744.0000\n",
      "Epoch 53/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1570751872.0000 - val_loss: 3454832896.0000\n",
      "Epoch 54/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1579467648.0000 - val_loss: 3614289408.0000\n",
      "Epoch 55/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1576098048.0000 - val_loss: 3469788928.0000\n",
      "Epoch 56/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1576627584.0000 - val_loss: 3445238528.0000\n",
      "Epoch 57/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1570942848.0000 - val_loss: 3488824576.0000\n",
      "Epoch 58/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1562818816.0000 - val_loss: 3559663616.0000\n",
      "Epoch 59/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1565080320.0000 - val_loss: 3314517504.0000\n",
      "Epoch 60/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1567344512.0000 - val_loss: 3536372736.0000\n",
      "Epoch 61/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1566509952.0000 - val_loss: 3576739072.0000\n",
      "Epoch 62/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1581376896.0000 - val_loss: 3486373632.0000\n",
      "Epoch 63/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1580268160.0000 - val_loss: 3493049600.0000\n",
      "Epoch 64/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1564053632.0000 - val_loss: 3435119104.0000\n",
      "Epoch 65/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1562633984.0000 - val_loss: 3390621440.0000\n",
      "Epoch 66/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1553832320.0000 - val_loss: 3516233728.0000\n",
      "Epoch 67/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1564311424.0000 - val_loss: 3532868864.0000\n",
      "Epoch 68/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1557224448.0000 - val_loss: 3296267520.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1558060416.0000 - val_loss: 3423906304.0000\n",
      "Epoch 70/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1549345280.0000 - val_loss: 3354527232.0000\n",
      "Epoch 71/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1561283840.0000 - val_loss: 3394119680.0000\n",
      "Epoch 72/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1549703296.0000 - val_loss: 3317225472.0000\n",
      "Epoch 73/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1545382400.0000 - val_loss: 3395384576.0000\n",
      "Epoch 74/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1562422912.0000 - val_loss: 3362624000.0000\n",
      "Epoch 75/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1556327040.0000 - val_loss: 3348167168.0000\n",
      "Epoch 76/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1546558592.0000 - val_loss: 3414607616.0000\n",
      "Epoch 77/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1541761664.0000 - val_loss: 3389907712.0000\n",
      "Epoch 78/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1549381888.0000 - val_loss: 3354384128.0000\n",
      "Epoch 79/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1534171392.0000 - val_loss: 3305904896.0000\n",
      "Epoch 80/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1555193728.0000 - val_loss: 3364785920.0000\n",
      "Epoch 81/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1556067712.0000 - val_loss: 3383410944.0000\n",
      "Epoch 82/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1544774784.0000 - val_loss: 3326832640.0000\n",
      "Epoch 83/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1550409472.0000 - val_loss: 3374269184.0000\n",
      "Epoch 84/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1538438400.0000 - val_loss: 3397688320.0000\n",
      "Epoch 85/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1543319808.0000 - val_loss: 3353652736.0000\n",
      "Epoch 86/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1552596992.0000 - val_loss: 3458683904.0000\n",
      "Epoch 87/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1545461248.0000 - val_loss: 3319179008.0000\n",
      "Epoch 88/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1537891584.0000 - val_loss: 3402468864.0000\n",
      "Epoch 89/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1545049472.0000 - val_loss: 3358070272.0000\n",
      "Epoch 90/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1543596800.0000 - val_loss: 3315323392.0000\n",
      "Epoch 91/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1542230272.0000 - val_loss: 3471782144.0000\n",
      "Epoch 92/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1540006016.0000 - val_loss: 3377515264.0000\n",
      "Epoch 93/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1533773824.0000 - val_loss: 3312402944.0000\n",
      "Epoch 94/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1534715008.0000 - val_loss: 3382232832.0000\n",
      "Epoch 95/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1526466688.0000 - val_loss: 3308678656.0000\n",
      "Epoch 96/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1528393216.0000 - val_loss: 3306115840.0000\n",
      "Epoch 97/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1532195200.0000 - val_loss: 3530739712.0000\n",
      "Epoch 98/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1532887168.0000 - val_loss: 3310264064.0000\n",
      "Epoch 99/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1526379904.0000 - val_loss: 3392728320.0000\n",
      "Epoch 100/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1518051072.0000 - val_loss: 3295534848.0000\n",
      "Epoch 101/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1533044480.0000 - val_loss: 3310455552.0000\n",
      "Epoch 102/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1516411264.0000 - val_loss: 3280709120.0000\n",
      "Epoch 103/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1528769664.0000 - val_loss: 3319412736.0000\n",
      "Epoch 104/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1520979456.0000 - val_loss: 3362805504.0000\n",
      "Epoch 105/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1524561024.0000 - val_loss: 3444134400.0000\n",
      "Epoch 106/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1528886016.0000 - val_loss: 3340118784.0000\n",
      "Epoch 107/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1513203584.0000 - val_loss: 3516274176.0000\n",
      "Epoch 108/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1523700992.0000 - val_loss: 3343904256.0000\n",
      "Epoch 109/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1515345664.0000 - val_loss: 3282407424.0000\n",
      "Epoch 110/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1517865344.0000 - val_loss: 3325645056.0000\n",
      "Epoch 111/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1516083840.0000 - val_loss: 3318420224.0000\n",
      "Epoch 112/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1512220160.0000 - val_loss: 3321419776.0000\n",
      "Epoch 113/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1511769856.0000 - val_loss: 3256087296.0000\n",
      "Epoch 114/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1513614976.0000 - val_loss: 3313651456.0000\n",
      "Epoch 115/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1512960000.0000 - val_loss: 3297452800.0000\n",
      "Epoch 116/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1507650176.0000 - val_loss: 3385476352.0000\n",
      "Epoch 117/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1511365504.0000 - val_loss: 3303356672.0000\n",
      "Epoch 118/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1510421120.0000 - val_loss: 3409032448.0000\n",
      "Epoch 119/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1525122688.0000 - val_loss: 3325005568.0000\n",
      "Epoch 120/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1506845056.0000 - val_loss: 3396812800.0000\n",
      "Epoch 121/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1500759680.0000 - val_loss: 3328652288.0000\n",
      "Epoch 122/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1504078848.0000 - val_loss: 3303903744.0000\n",
      "Epoch 123/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1494559104.0000 - val_loss: 3352814592.0000\n",
      "Epoch 124/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1495902592.0000 - val_loss: 3343808768.0000\n",
      "Epoch 125/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1496460032.0000 - val_loss: 3421550848.0000\n",
      "Epoch 126/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1498066688.0000 - val_loss: 3318051328.0000\n",
      "Epoch 127/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1505220992.0000 - val_loss: 3336948736.0000\n",
      "Epoch 128/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1492578048.0000 - val_loss: 3409065984.0000\n",
      "Epoch 129/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1498262528.0000 - val_loss: 3328155904.0000\n",
      "Epoch 130/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1493847808.0000 - val_loss: 3265569792.0000\n",
      "Epoch 131/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1492400000.0000 - val_loss: 3361368064.0000\n",
      "Epoch 132/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1493246208.0000 - val_loss: 3345256960.0000\n",
      "Epoch 133/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1474057984.0000 - val_loss: 3241051904.0000\n",
      "Epoch 134/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1496538880.0000 - val_loss: 3281834496.0000\n",
      "Epoch 135/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1492453504.0000 - val_loss: 3297837824.0000\n",
      "Epoch 136/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 1481001472.0000 - val_loss: 3370686720.0000\n",
      "Epoch 137/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1482489344.0000 - val_loss: 3321419520.0000\n",
      "Epoch 138/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1482709248.0000 - val_loss: 3292754432.0000\n",
      "Epoch 139/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1478370304.0000 - val_loss: 3245036800.0000\n",
      "Epoch 140/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1493318272.0000 - val_loss: 3353496832.0000\n",
      "Epoch 141/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1482219136.0000 - val_loss: 3322878976.0000\n",
      "Epoch 142/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1474176896.0000 - val_loss: 3254180352.0000\n",
      "Epoch 143/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1485787264.0000 - val_loss: 3445628416.0000\n",
      "Epoch 144/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1479042944.0000 - val_loss: 3306652672.0000\n",
      "Epoch 145/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1468102016.0000 - val_loss: 3326172416.0000\n",
      "Epoch 146/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1479492096.0000 - val_loss: 3325044992.0000\n",
      "Epoch 147/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1468742016.0000 - val_loss: 3382642944.0000\n",
      "Epoch 148/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1478409984.0000 - val_loss: 3379724288.0000\n",
      "Epoch 149/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1468973952.0000 - val_loss: 3315341568.0000\n",
      "Epoch 150/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1463883264.0000 - val_loss: 3273167360.0000\n",
      "Epoch 151/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1464740352.0000 - val_loss: 3502471680.0000\n",
      "Epoch 152/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1468750592.0000 - val_loss: 3374868224.0000\n",
      "Epoch 153/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1454286080.0000 - val_loss: 3389728512.0000\n",
      "Epoch 154/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1455866752.0000 - val_loss: 3351106816.0000\n",
      "Epoch 155/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1454825344.0000 - val_loss: 3310323968.0000\n",
      "Epoch 156/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1446748928.0000 - val_loss: 3321185280.0000\n",
      "Epoch 157/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1448866688.0000 - val_loss: 3335252480.0000\n",
      "Epoch 158/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1448026752.0000 - val_loss: 3384768512.0000\n",
      "Epoch 159/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1447718912.0000 - val_loss: 3271603712.0000\n",
      "Epoch 160/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1454874752.0000 - val_loss: 3340389120.0000\n",
      "Epoch 161/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1447200896.0000 - val_loss: 3288446208.0000\n",
      "Epoch 162/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1437062784.0000 - val_loss: 3256809216.0000\n",
      "Epoch 163/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1443506560.0000 - val_loss: 3271401728.0000\n",
      "Epoch 164/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1461007232.0000 - val_loss: 3366512128.0000\n",
      "Epoch 165/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1445436032.0000 - val_loss: 3323501056.0000\n",
      "Epoch 166/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1435250944.0000 - val_loss: 3245935616.0000\n",
      "Epoch 167/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1440523648.0000 - val_loss: 3360018432.0000\n",
      "Epoch 168/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1435643776.0000 - val_loss: 3273862656.0000\n",
      "Epoch 169/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1442938368.0000 - val_loss: 3310738944.0000\n",
      "Epoch 170/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1430693248.0000 - val_loss: 3340224256.0000\n",
      "Epoch 171/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1438782848.0000 - val_loss: 3323141376.0000\n",
      "Epoch 172/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1426291328.0000 - val_loss: 3387687680.0000\n",
      "Epoch 173/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1434593792.0000 - val_loss: 3285869824.0000\n",
      "Epoch 174/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1421812736.0000 - val_loss: 3391492864.0000\n",
      "Epoch 175/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1425876608.0000 - val_loss: 3305060608.0000\n",
      "Epoch 176/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1424344960.0000 - val_loss: 3336369664.0000\n",
      "Epoch 177/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1415275392.0000 - val_loss: 3422605056.0000\n",
      "Epoch 178/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1416817024.0000 - val_loss: 3303419648.0000\n",
      "Epoch 179/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1415474048.0000 - val_loss: 3345876992.0000\n",
      "Epoch 180/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1430046208.0000 - val_loss: 3346056192.0000\n",
      "Epoch 181/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1418722688.0000 - val_loss: 3288379136.0000\n",
      "Epoch 182/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1405432320.0000 - val_loss: 3292017152.0000\n",
      "Epoch 183/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1399930752.0000 - val_loss: 3375466752.0000\n",
      "Epoch 184/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1411914752.0000 - val_loss: 3284732928.0000\n",
      "Epoch 185/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1417124864.0000 - val_loss: 3299061504.0000\n",
      "Epoch 186/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1404008320.0000 - val_loss: 3336627456.0000\n",
      "Epoch 187/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1395780992.0000 - val_loss: 3293341440.0000\n",
      "Epoch 188/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1396717312.0000 - val_loss: 3241625856.0000\n",
      "Epoch 189/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1400125440.0000 - val_loss: 3333317632.0000\n",
      "Epoch 190/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1402354304.0000 - val_loss: 3278630912.0000\n",
      "Epoch 191/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1403799808.0000 - val_loss: 3337787904.0000\n",
      "Epoch 192/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1399141632.0000 - val_loss: 3257900800.0000\n",
      "Epoch 193/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1394032512.0000 - val_loss: 3276808960.0000\n",
      "Epoch 194/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1412720128.0000 - val_loss: 3253695744.0000\n",
      "Epoch 195/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1386361600.0000 - val_loss: 3321953792.0000\n",
      "Epoch 196/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1384288640.0000 - val_loss: 3244049664.0000\n",
      "Epoch 197/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1403027456.0000 - val_loss: 3281194240.0000\n",
      "Epoch 198/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1373762688.0000 - val_loss: 3310960640.0000\n",
      "Epoch 199/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1377219200.0000 - val_loss: 3307294976.0000\n",
      "Epoch 200/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1374007552.0000 - val_loss: 3339143168.0000\n",
      "Epoch 201/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1380509696.0000 - val_loss: 3322870016.0000\n",
      "Epoch 202/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1376054912.0000 - val_loss: 3340668160.0000\n",
      "Epoch 203/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 1379695744.0000 - val_loss: 3273181696.0000\n",
      "Epoch 204/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1368007808.0000 - val_loss: 3398482432.0000\n",
      "Epoch 205/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1369552640.0000 - val_loss: 3336445696.0000\n",
      "Epoch 206/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1368167424.0000 - val_loss: 3269836288.0000\n",
      "Epoch 207/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1373623808.0000 - val_loss: 3306125824.0000\n",
      "Epoch 208/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1363080704.0000 - val_loss: 3327348736.0000\n",
      "Epoch 209/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1364288640.0000 - val_loss: 3378733568.0000\n",
      "Epoch 210/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1360872448.0000 - val_loss: 3266301696.0000\n",
      "Epoch 211/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1355632512.0000 - val_loss: 3252707584.0000\n",
      "Epoch 212/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1353095168.0000 - val_loss: 3330195968.0000\n",
      "Epoch 213/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1359135488.0000 - val_loss: 3472877312.0000\n",
      "Epoch 214/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1353774592.0000 - val_loss: 3291214848.0000\n",
      "Epoch 215/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1356265600.0000 - val_loss: 3311093760.0000\n",
      "Epoch 216/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1349506560.0000 - val_loss: 3276498176.0000\n",
      "Epoch 217/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1343059200.0000 - val_loss: 3346255872.0000\n",
      "Epoch 218/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1340553984.0000 - val_loss: 3345935104.0000\n",
      "Epoch 219/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1348238976.0000 - val_loss: 3371771136.0000\n",
      "Epoch 220/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1335934336.0000 - val_loss: 3254747392.0000\n",
      "Epoch 221/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1329396224.0000 - val_loss: 3350977024.0000\n",
      "Epoch 222/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1333038080.0000 - val_loss: 3428321280.0000\n",
      "Epoch 223/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1341662976.0000 - val_loss: 3271174144.0000\n",
      "Epoch 224/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1330532480.0000 - val_loss: 3321298176.0000\n",
      "Epoch 225/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1328500480.0000 - val_loss: 3306185472.0000\n",
      "Epoch 226/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1329908992.0000 - val_loss: 3344390144.0000\n",
      "Epoch 227/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1342177792.0000 - val_loss: 3348472832.0000\n",
      "Epoch 228/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1322598400.0000 - val_loss: 3282678528.0000\n",
      "Epoch 229/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1331642368.0000 - val_loss: 3272872960.0000\n",
      "Epoch 230/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1328173056.0000 - val_loss: 3351698688.0000\n",
      "Epoch 231/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1325906560.0000 - val_loss: 3320144384.0000\n",
      "Epoch 232/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1321569664.0000 - val_loss: 3292323328.0000\n",
      "Epoch 233/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1323983744.0000 - val_loss: 3410812416.0000\n",
      "Epoch 234/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1304918016.0000 - val_loss: 3285637632.0000\n",
      "Epoch 235/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1311221504.0000 - val_loss: 3312163840.0000\n",
      "Epoch 236/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1308978944.0000 - val_loss: 3366429440.0000\n",
      "Epoch 237/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1317455488.0000 - val_loss: 3389754112.0000\n",
      "Epoch 238/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1307166080.0000 - val_loss: 3344254464.0000\n",
      "Epoch 239/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1324297728.0000 - val_loss: 3444186624.0000\n",
      "Epoch 240/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1303526016.0000 - val_loss: 3331981312.0000\n",
      "Epoch 241/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1303193856.0000 - val_loss: 3306403840.0000\n",
      "Epoch 242/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1306174976.0000 - val_loss: 3289252608.0000\n",
      "Epoch 243/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1298713472.0000 - val_loss: 3321931008.0000\n",
      "Epoch 244/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1292558464.0000 - val_loss: 3391133184.0000\n",
      "Epoch 245/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1294156544.0000 - val_loss: 3320142848.0000\n",
      "Epoch 246/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1294109568.0000 - val_loss: 3323152128.0000\n",
      "Epoch 247/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1303047680.0000 - val_loss: 3371691264.0000\n",
      "Epoch 248/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1298813824.0000 - val_loss: 3340547584.0000\n",
      "Epoch 249/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1284785152.0000 - val_loss: 3295245824.0000\n",
      "Epoch 250/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1287581184.0000 - val_loss: 3314004224.0000\n",
      "Epoch 251/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1285608960.0000 - val_loss: 3278503680.0000\n",
      "Epoch 252/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1284794496.0000 - val_loss: 3321889536.0000\n",
      "Epoch 253/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1285532672.0000 - val_loss: 3351279360.0000\n",
      "Epoch 254/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1276284800.0000 - val_loss: 3370680576.0000\n",
      "Epoch 255/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1279204736.0000 - val_loss: 3308370432.0000\n",
      "Epoch 256/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1270088960.0000 - val_loss: 3290174720.0000\n",
      "Epoch 257/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1279807360.0000 - val_loss: 3293340160.0000\n",
      "Epoch 258/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1278714880.0000 - val_loss: 3310965248.0000\n",
      "Epoch 259/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1276082048.0000 - val_loss: 3308400640.0000\n",
      "Epoch 260/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1268680320.0000 - val_loss: 3356854016.0000\n",
      "Epoch 261/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1270689024.0000 - val_loss: 3337630464.0000\n",
      "Epoch 262/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1277566080.0000 - val_loss: 3332398848.0000\n",
      "Epoch 263/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1266033536.0000 - val_loss: 3369214976.0000\n",
      "Epoch 264/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1266562944.0000 - val_loss: 3346460928.0000\n",
      "Epoch 265/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1262179328.0000 - val_loss: 3309209088.0000\n",
      "Epoch 266/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1276384384.0000 - val_loss: 3368651264.0000\n",
      "Epoch 267/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1259526272.0000 - val_loss: 3366516736.0000\n",
      "Epoch 268/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1262483072.0000 - val_loss: 3332169728.0000\n",
      "Epoch 269/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1264026496.0000 - val_loss: 3520689152.0000\n",
      "Epoch 270/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 1272107264.0000 - val_loss: 3365126656.0000\n",
      "Epoch 271/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1253859584.0000 - val_loss: 3372859904.0000\n",
      "Epoch 272/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1255237888.0000 - val_loss: 3332251648.0000\n",
      "Epoch 273/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1252326272.0000 - val_loss: 3402325504.0000\n",
      "Epoch 274/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1257293952.0000 - val_loss: 3368730112.0000\n",
      "Epoch 275/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1248924032.0000 - val_loss: 3355732736.0000\n",
      "Epoch 276/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1250528768.0000 - val_loss: 3285049600.0000\n",
      "Epoch 277/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1241336960.0000 - val_loss: 3405491456.0000\n",
      "Epoch 278/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1246224512.0000 - val_loss: 3401382656.0000\n",
      "Epoch 279/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1238963328.0000 - val_loss: 3309453824.0000\n",
      "Epoch 280/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1248411520.0000 - val_loss: 3277711872.0000\n",
      "Epoch 281/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1239115648.0000 - val_loss: 3235147264.0000\n",
      "Epoch 282/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1237735040.0000 - val_loss: 3321725440.0000\n",
      "Epoch 283/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1234775936.0000 - val_loss: 3360748544.0000\n",
      "Epoch 284/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1234443136.0000 - val_loss: 3291829248.0000\n",
      "Epoch 285/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1238824192.0000 - val_loss: 3301545472.0000\n",
      "Epoch 286/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1234188672.0000 - val_loss: 3329803008.0000\n",
      "Epoch 287/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1231336704.0000 - val_loss: 3465327104.0000\n",
      "Epoch 288/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1230590720.0000 - val_loss: 3341390336.0000\n",
      "Epoch 289/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1230608640.0000 - val_loss: 3289544448.0000\n",
      "Epoch 290/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1230132224.0000 - val_loss: 3308253952.0000\n",
      "Epoch 291/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1227136640.0000 - val_loss: 3228219648.0000\n",
      "Epoch 292/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1222375808.0000 - val_loss: 3333407232.0000\n",
      "Epoch 293/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1217363968.0000 - val_loss: 3272046336.0000\n",
      "Epoch 294/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1222072704.0000 - val_loss: 3295967488.0000\n",
      "Epoch 295/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1227878528.0000 - val_loss: 3302629120.0000\n",
      "Epoch 296/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1225693824.0000 - val_loss: 3237633280.0000\n",
      "Epoch 297/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1230716800.0000 - val_loss: 3275425024.0000\n",
      "Epoch 298/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1212271744.0000 - val_loss: 3207667968.0000\n",
      "Epoch 299/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1219763200.0000 - val_loss: 3243217152.0000\n",
      "Epoch 300/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1215211520.0000 - val_loss: 3286049024.0000\n",
      "Epoch 301/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1217411456.0000 - val_loss: 3300669440.0000\n",
      "Epoch 302/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1224807680.0000 - val_loss: 3322554368.0000\n",
      "Epoch 303/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1209697024.0000 - val_loss: 3299857408.0000\n",
      "Epoch 304/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1208099072.0000 - val_loss: 3244440576.0000\n",
      "Epoch 305/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1206565632.0000 - val_loss: 3312350976.0000\n",
      "Epoch 306/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1205995136.0000 - val_loss: 3407751168.0000\n",
      "Epoch 307/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1202763904.0000 - val_loss: 3251889152.0000\n",
      "Epoch 308/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1200815232.0000 - val_loss: 3333079040.0000\n",
      "Epoch 309/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1202327808.0000 - val_loss: 3321982720.0000\n",
      "Epoch 310/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1199807232.0000 - val_loss: 3280370176.0000\n",
      "Epoch 311/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1198691712.0000 - val_loss: 3294717440.0000\n",
      "Epoch 312/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1204227456.0000 - val_loss: 3301587712.0000\n",
      "Epoch 313/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1199173376.0000 - val_loss: 3391983872.0000\n",
      "Epoch 314/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1206730240.0000 - val_loss: 3262963456.0000\n",
      "Epoch 315/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1197804800.0000 - val_loss: 3282924288.0000\n",
      "Epoch 316/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1196977024.0000 - val_loss: 3253740544.0000\n",
      "Epoch 317/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1194214656.0000 - val_loss: 3238528000.0000\n",
      "Epoch 318/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1190342272.0000 - val_loss: 3334709248.0000\n",
      "Epoch 319/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1187849856.0000 - val_loss: 3259592960.0000\n",
      "Epoch 320/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1188259584.0000 - val_loss: 3263793152.0000\n",
      "Epoch 321/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1189047040.0000 - val_loss: 3195321856.0000\n",
      "Epoch 322/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1195040768.0000 - val_loss: 3229103616.0000\n",
      "Epoch 323/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1180723712.0000 - val_loss: 3223143680.0000\n",
      "Epoch 324/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1188692608.0000 - val_loss: 3297836288.0000\n",
      "Epoch 325/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1189836544.0000 - val_loss: 3240720640.0000\n",
      "Epoch 326/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1181700480.0000 - val_loss: 3288948736.0000\n",
      "Epoch 327/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1175055360.0000 - val_loss: 3253998848.0000\n",
      "Epoch 328/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1169665920.0000 - val_loss: 3183667200.0000\n",
      "Epoch 329/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1180122496.0000 - val_loss: 3322143488.0000\n",
      "Epoch 330/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1195505280.0000 - val_loss: 3253676032.0000\n",
      "Epoch 331/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1177411072.0000 - val_loss: 3177868800.0000\n",
      "Epoch 332/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1169320832.0000 - val_loss: 3193847040.0000\n",
      "Epoch 333/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1166374400.0000 - val_loss: 3189836800.0000\n",
      "Epoch 334/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1164568704.0000 - val_loss: 3190742272.0000\n",
      "Epoch 335/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1180873472.0000 - val_loss: 3260250624.0000\n",
      "Epoch 336/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1167583744.0000 - val_loss: 3251831808.0000\n",
      "Epoch 337/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 1166303232.0000 - val_loss: 3215486720.0000\n",
      "Epoch 338/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1158646784.0000 - val_loss: 3221242112.0000\n",
      "Epoch 339/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1156667008.0000 - val_loss: 3102055680.0000\n",
      "Epoch 340/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1155772672.0000 - val_loss: 3200656128.0000\n",
      "Epoch 341/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1159016960.0000 - val_loss: 3141532672.0000\n",
      "Epoch 342/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1154769024.0000 - val_loss: 3223792896.0000\n",
      "Epoch 343/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1150204544.0000 - val_loss: 3131056128.0000\n",
      "Epoch 344/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1160757632.0000 - val_loss: 3209438208.0000\n",
      "Epoch 345/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1151929088.0000 - val_loss: 3243556352.0000\n",
      "Epoch 346/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1165907584.0000 - val_loss: 3178523392.0000\n",
      "Epoch 347/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1149138048.0000 - val_loss: 3201160448.0000\n",
      "Epoch 348/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1150627712.0000 - val_loss: 3187128576.0000\n",
      "Epoch 349/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1145370624.0000 - val_loss: 3146098944.0000\n",
      "Epoch 350/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1141616640.0000 - val_loss: 3230211328.0000\n",
      "Epoch 351/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1147202432.0000 - val_loss: 3221635328.0000\n",
      "Epoch 352/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1144407168.0000 - val_loss: 3155199488.0000\n",
      "Epoch 353/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1138388096.0000 - val_loss: 3098303488.0000\n",
      "Epoch 354/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1144917888.0000 - val_loss: 3145799424.0000\n",
      "Epoch 355/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1132617600.0000 - val_loss: 3160114432.0000\n",
      "Epoch 356/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1142408704.0000 - val_loss: 3119750144.0000\n",
      "Epoch 357/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1145731200.0000 - val_loss: 3083059200.0000\n",
      "Epoch 358/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1129905024.0000 - val_loss: 3094675200.0000\n",
      "Epoch 359/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1136172160.0000 - val_loss: 3167349248.0000\n",
      "Epoch 360/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1131641344.0000 - val_loss: 3270441984.0000\n",
      "Epoch 361/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1133191424.0000 - val_loss: 3146124544.0000\n",
      "Epoch 362/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1130941824.0000 - val_loss: 3111900160.0000\n",
      "Epoch 363/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1131282944.0000 - val_loss: 3080131072.0000\n",
      "Epoch 364/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1128055552.0000 - val_loss: 3168540928.0000\n",
      "Epoch 365/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1126239232.0000 - val_loss: 3135822336.0000\n",
      "Epoch 366/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1127548416.0000 - val_loss: 3189061376.0000\n",
      "Epoch 367/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1138657152.0000 - val_loss: 3166027520.0000\n",
      "Epoch 368/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1113619328.0000 - val_loss: 3284676864.0000\n",
      "Epoch 369/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1119789952.0000 - val_loss: 3123084032.0000\n",
      "Epoch 370/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1123497728.0000 - val_loss: 3210159616.0000\n",
      "Epoch 371/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1117686784.0000 - val_loss: 3106238720.0000\n",
      "Epoch 372/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1119028352.0000 - val_loss: 3059804928.0000\n",
      "Epoch 373/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1117229312.0000 - val_loss: 3096814848.0000\n",
      "Epoch 374/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1114209408.0000 - val_loss: 3083009280.0000\n",
      "Epoch 375/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1111781632.0000 - val_loss: 3091735808.0000\n",
      "Epoch 376/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1111492608.0000 - val_loss: 3118812416.0000\n",
      "Epoch 377/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1110170752.0000 - val_loss: 3096206848.0000\n",
      "Epoch 378/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1119276416.0000 - val_loss: 3096341504.0000\n",
      "Epoch 379/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1106021888.0000 - val_loss: 3077125376.0000\n",
      "Epoch 380/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1110669440.0000 - val_loss: 3022124544.0000\n",
      "Epoch 381/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1100850688.0000 - val_loss: 3136686336.0000\n",
      "Epoch 382/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1111786368.0000 - val_loss: 3075452416.0000\n",
      "Epoch 383/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1095925504.0000 - val_loss: 3035786496.0000\n",
      "Epoch 384/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1101824640.0000 - val_loss: 3018090752.0000\n",
      "Epoch 385/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1093778176.0000 - val_loss: 3090022144.0000\n",
      "Epoch 386/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1106934528.0000 - val_loss: 3054758144.0000\n",
      "Epoch 387/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1093927808.0000 - val_loss: 3027915776.0000\n",
      "Epoch 388/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1114009344.0000 - val_loss: 3027533568.0000\n",
      "Epoch 389/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1100634752.0000 - val_loss: 3052589824.0000\n",
      "Epoch 390/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1090054528.0000 - val_loss: 2997095680.0000\n",
      "Epoch 391/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1094163584.0000 - val_loss: 3036156416.0000\n",
      "Epoch 392/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1084936576.0000 - val_loss: 3051748864.0000\n",
      "Epoch 393/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1097970560.0000 - val_loss: 2977784320.0000\n",
      "Epoch 394/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1083281664.0000 - val_loss: 2964718080.0000\n",
      "Epoch 395/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1089869056.0000 - val_loss: 2949907456.0000\n",
      "Epoch 396/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1080931072.0000 - val_loss: 2989285888.0000\n",
      "Epoch 397/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1088476928.0000 - val_loss: 3020501504.0000\n",
      "Epoch 398/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1077426176.0000 - val_loss: 2972541440.0000\n",
      "Epoch 399/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1081121280.0000 - val_loss: 2918975744.0000\n",
      "Epoch 400/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1070520128.0000 - val_loss: 3045317376.0000\n",
      "Epoch 401/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1083091200.0000 - val_loss: 3000587264.0000\n",
      "Epoch 402/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1075747968.0000 - val_loss: 2935983616.0000\n",
      "Epoch 403/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1074979328.0000 - val_loss: 3025169664.0000\n",
      "Epoch 404/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 1065321024.0000 - val_loss: 2965367296.0000\n",
      "Epoch 405/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1074944384.0000 - val_loss: 2949694464.0000\n",
      "Epoch 406/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1075835136.0000 - val_loss: 2895220736.0000\n",
      "Epoch 407/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1060217408.0000 - val_loss: 2844132608.0000\n",
      "Epoch 408/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1078961024.0000 - val_loss: 2935665408.0000\n",
      "Epoch 409/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1062871360.0000 - val_loss: 2880404992.0000\n",
      "Epoch 410/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1061057344.0000 - val_loss: 2922206208.0000\n",
      "Epoch 411/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1064108544.0000 - val_loss: 2983799040.0000\n",
      "Epoch 412/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1065056512.0000 - val_loss: 2871395584.0000\n",
      "Epoch 413/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1060245760.0000 - val_loss: 3004969472.0000\n",
      "Epoch 414/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1073085888.0000 - val_loss: 2919581696.0000\n",
      "Epoch 415/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1062237248.0000 - val_loss: 2956237312.0000\n",
      "Epoch 416/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1085289344.0000 - val_loss: 3045206016.0000\n",
      "Epoch 417/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1052924864.0000 - val_loss: 2843488000.0000\n",
      "Epoch 418/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1052252800.0000 - val_loss: 2938190080.0000\n",
      "Epoch 419/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1055813120.0000 - val_loss: 2866415872.0000\n",
      "Epoch 420/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1059578112.0000 - val_loss: 2914553600.0000\n",
      "Epoch 421/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1054243584.0000 - val_loss: 2884728064.0000\n",
      "Epoch 422/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1047160384.0000 - val_loss: 2839096320.0000\n",
      "Epoch 423/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1052501952.0000 - val_loss: 2907202048.0000\n",
      "Epoch 424/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1043046976.0000 - val_loss: 2917148672.0000\n",
      "Epoch 425/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1050372864.0000 - val_loss: 2829295360.0000\n",
      "Epoch 426/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1045724032.0000 - val_loss: 2836262912.0000\n",
      "Epoch 427/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1034574208.0000 - val_loss: 2844156672.0000\n",
      "Epoch 428/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1034567232.0000 - val_loss: 2878827776.0000\n",
      "Epoch 429/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1049842112.0000 - val_loss: 2863095040.0000\n",
      "Epoch 430/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1031214656.0000 - val_loss: 2879969280.0000\n",
      "Epoch 431/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1031821056.0000 - val_loss: 2842308864.0000\n",
      "Epoch 432/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1032025280.0000 - val_loss: 2805499136.0000\n",
      "Epoch 433/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1039493888.0000 - val_loss: 2764598528.0000\n",
      "Epoch 434/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1032855872.0000 - val_loss: 2868712704.0000\n",
      "Epoch 435/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1038112704.0000 - val_loss: 2741812480.0000\n",
      "Epoch 436/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1027904896.0000 - val_loss: 2892602880.0000\n",
      "Epoch 437/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1022522880.0000 - val_loss: 2836733440.0000\n",
      "Epoch 438/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1022256704.0000 - val_loss: 2769739776.0000\n",
      "Epoch 439/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1021516736.0000 - val_loss: 2885266432.0000\n",
      "Epoch 440/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1027719872.0000 - val_loss: 2764215296.0000\n",
      "Epoch 441/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1033920576.0000 - val_loss: 2886097920.0000\n",
      "Epoch 442/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1017479296.0000 - val_loss: 2773178368.0000\n",
      "Epoch 443/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1032385344.0000 - val_loss: 2737594624.0000\n",
      "Epoch 444/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1022693696.0000 - val_loss: 2754317568.0000\n",
      "Epoch 445/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1019550656.0000 - val_loss: 2819019008.0000\n",
      "Epoch 446/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1008041408.0000 - val_loss: 2741565184.0000\n",
      "Epoch 447/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1009440832.0000 - val_loss: 2815620608.0000\n",
      "Epoch 448/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1012082752.0000 - val_loss: 2910792960.0000\n",
      "Epoch 449/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1008443328.0000 - val_loss: 2811680000.0000\n",
      "Epoch 450/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1006987904.0000 - val_loss: 2713345280.0000\n",
      "Epoch 451/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1014119168.0000 - val_loss: 2754228480.0000\n",
      "Epoch 452/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1005654912.0000 - val_loss: 2813034496.0000\n",
      "Epoch 453/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1006251520.0000 - val_loss: 2802412032.0000\n",
      "Epoch 454/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1012943808.0000 - val_loss: 2742854400.0000\n",
      "Epoch 455/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1002175040.0000 - val_loss: 2766962432.0000\n",
      "Epoch 456/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 997797440.0000 - val_loss: 2725995008.0000\n",
      "Epoch 457/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 993497280.0000 - val_loss: 2733580288.0000\n",
      "Epoch 458/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 996196096.0000 - val_loss: 2755123200.0000\n",
      "Epoch 459/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 995674304.0000 - val_loss: 2787326720.0000\n",
      "Epoch 460/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 996950336.0000 - val_loss: 2854796800.0000\n",
      "Epoch 461/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 996102272.0000 - val_loss: 2779448832.0000\n",
      "Epoch 462/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 996514688.0000 - val_loss: 2715305728.0000\n",
      "Epoch 463/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 993314560.0000 - val_loss: 2838730496.0000\n",
      "Epoch 464/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 998794432.0000 - val_loss: 2747920640.0000\n",
      "Epoch 465/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 981780032.0000 - val_loss: 2712541952.0000\n",
      "Epoch 466/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 992870080.0000 - val_loss: 2723411456.0000\n",
      "Epoch 467/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 982237568.0000 - val_loss: 2696703232.0000\n",
      "Epoch 468/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 974223488.0000 - val_loss: 2761597440.0000\n",
      "Epoch 469/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 975709312.0000 - val_loss: 2738615040.0000\n",
      "Epoch 470/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 983512640.0000 - val_loss: 2668257536.0000\n",
      "Epoch 471/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 976026752.0000 - val_loss: 2732172544.0000\n",
      "Epoch 472/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 978634368.0000 - val_loss: 2640550400.0000\n",
      "Epoch 473/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 972606336.0000 - val_loss: 2701702400.0000\n",
      "Epoch 474/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 973893696.0000 - val_loss: 2686335232.0000\n",
      "Epoch 475/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 982033472.0000 - val_loss: 2743698688.0000\n",
      "Epoch 476/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 968588544.0000 - val_loss: 2669998336.0000\n",
      "Epoch 477/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 970449856.0000 - val_loss: 2640473600.0000\n",
      "Epoch 478/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 961413824.0000 - val_loss: 2701143040.0000\n",
      "Epoch 479/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 958533952.0000 - val_loss: 2669788160.0000\n",
      "Epoch 480/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 957507904.0000 - val_loss: 2708391168.0000\n",
      "Epoch 481/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 967107648.0000 - val_loss: 2596501504.0000\n",
      "Epoch 482/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 953284672.0000 - val_loss: 2631981056.0000\n",
      "Epoch 483/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 953854720.0000 - val_loss: 2724248832.0000\n",
      "Epoch 484/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 941451328.0000 - val_loss: 2621500416.0000\n",
      "Epoch 485/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 954483776.0000 - val_loss: 2646802944.0000\n",
      "Epoch 486/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 959685056.0000 - val_loss: 2587502592.0000\n",
      "Epoch 487/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 946776256.0000 - val_loss: 2721132800.0000\n",
      "Epoch 488/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 955282752.0000 - val_loss: 2662812416.0000\n",
      "Epoch 489/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 945024384.0000 - val_loss: 2601045760.0000\n",
      "Epoch 490/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 939916096.0000 - val_loss: 2621063168.0000\n",
      "Epoch 491/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 945724928.0000 - val_loss: 2606867968.0000\n",
      "Epoch 492/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 928734144.0000 - val_loss: 2719736064.0000\n",
      "Epoch 493/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 954368576.0000 - val_loss: 2580634880.0000\n",
      "Epoch 494/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 935514816.0000 - val_loss: 2686413568.0000\n",
      "Epoch 495/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 939236288.0000 - val_loss: 2623369472.0000\n",
      "Epoch 496/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 935422976.0000 - val_loss: 2606942208.0000\n",
      "Epoch 497/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 923486208.0000 - val_loss: 2560083712.0000\n",
      "Epoch 498/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 930612096.0000 - val_loss: 2575611136.0000\n",
      "Epoch 499/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 930439040.0000 - val_loss: 2590517248.0000\n",
      "Epoch 500/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 925894848.0000 - val_loss: 2712377344.0000\n",
      "Epoch 501/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 929779968.0000 - val_loss: 2566386176.0000\n",
      "Epoch 502/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 933168384.0000 - val_loss: 2549887488.0000\n",
      "Epoch 503/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 920840704.0000 - val_loss: 2529181696.0000\n",
      "Epoch 504/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 918271744.0000 - val_loss: 2585676544.0000\n",
      "Epoch 505/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 931667968.0000 - val_loss: 2579908608.0000\n",
      "Epoch 506/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 921816320.0000 - val_loss: 2551300352.0000\n",
      "Epoch 507/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 916190720.0000 - val_loss: 2520869632.0000\n",
      "Epoch 508/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 909384512.0000 - val_loss: 2619596032.0000\n",
      "Epoch 509/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 911358400.0000 - val_loss: 2518521600.0000\n",
      "Epoch 510/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 918279552.0000 - val_loss: 2497674496.0000\n",
      "Epoch 511/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 908452224.0000 - val_loss: 2700815104.0000\n",
      "Epoch 512/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 904636928.0000 - val_loss: 2505189888.0000\n",
      "Epoch 513/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 894579648.0000 - val_loss: 2599170816.0000\n",
      "Epoch 514/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 905003136.0000 - val_loss: 2538091520.0000\n",
      "Epoch 515/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 905938048.0000 - val_loss: 2542006272.0000\n",
      "Epoch 516/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 918844480.0000 - val_loss: 2530343168.0000\n",
      "Epoch 517/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 891639424.0000 - val_loss: 2543071744.0000\n",
      "Epoch 518/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 897311872.0000 - val_loss: 2451661568.0000\n",
      "Epoch 519/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 896224704.0000 - val_loss: 2512172032.0000\n",
      "Epoch 520/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 898303232.0000 - val_loss: 2537480704.0000\n",
      "Epoch 521/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 910159552.0000 - val_loss: 2599787008.0000\n",
      "Epoch 522/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 905246528.0000 - val_loss: 2601946880.0000\n",
      "Epoch 523/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 889253440.0000 - val_loss: 2575277056.0000\n",
      "Epoch 524/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 894288192.0000 - val_loss: 2585640704.0000\n",
      "Epoch 525/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 888584128.0000 - val_loss: 2476341760.0000\n",
      "Epoch 526/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 888806784.0000 - val_loss: 2489129216.0000\n",
      "Epoch 527/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 881627200.0000 - val_loss: 2496138496.0000\n",
      "Epoch 528/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 882504448.0000 - val_loss: 2484307968.0000\n",
      "Epoch 529/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 881181056.0000 - val_loss: 2509486848.0000\n",
      "Epoch 530/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 884278336.0000 - val_loss: 2472592384.0000\n",
      "Epoch 531/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 881932736.0000 - val_loss: 2466959360.0000\n",
      "Epoch 532/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 885599296.0000 - val_loss: 2475738624.0000\n",
      "Epoch 533/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 892996736.0000 - val_loss: 2485518336.0000\n",
      "Epoch 534/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 869336064.0000 - val_loss: 2494456064.0000\n",
      "Epoch 535/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 872080512.0000 - val_loss: 2702125568.0000\n",
      "Epoch 536/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 876046016.0000 - val_loss: 2415224832.0000\n",
      "Epoch 537/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 873791808.0000 - val_loss: 2456730368.0000\n",
      "Epoch 538/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 867831168.0000 - val_loss: 2595078656.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 539/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 878176960.0000 - val_loss: 2453558272.0000\n",
      "Epoch 540/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 873704256.0000 - val_loss: 2453085440.0000\n",
      "Epoch 541/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 861588352.0000 - val_loss: 2432227840.0000\n",
      "Epoch 542/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 860167488.0000 - val_loss: 2454260992.0000\n",
      "Epoch 543/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 864405184.0000 - val_loss: 2509115392.0000\n",
      "Epoch 544/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 855637696.0000 - val_loss: 2412286464.0000\n",
      "Epoch 545/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 850851264.0000 - val_loss: 2543827200.0000\n",
      "Epoch 546/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 860656128.0000 - val_loss: 2453387520.0000\n",
      "Epoch 547/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 844898624.0000 - val_loss: 2399159296.0000\n",
      "Epoch 548/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 852838848.0000 - val_loss: 2401981696.0000\n",
      "Epoch 549/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 848456960.0000 - val_loss: 2392369152.0000\n",
      "Epoch 550/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 849921408.0000 - val_loss: 2472410624.0000\n",
      "Epoch 551/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 862512192.0000 - val_loss: 2389473792.0000\n",
      "Epoch 552/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 849860800.0000 - val_loss: 2426408704.0000\n",
      "Epoch 553/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 847828160.0000 - val_loss: 2497612032.0000\n",
      "Epoch 554/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 855910400.0000 - val_loss: 2369226752.0000\n",
      "Epoch 555/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 847441024.0000 - val_loss: 2406426368.0000\n",
      "Epoch 556/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 837297664.0000 - val_loss: 2378317568.0000\n",
      "Epoch 557/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 838876160.0000 - val_loss: 2414501376.0000\n",
      "Epoch 558/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 830666944.0000 - val_loss: 2406860032.0000\n",
      "Epoch 559/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 833731840.0000 - val_loss: 2392989440.0000\n",
      "Epoch 560/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 833784640.0000 - val_loss: 2360228864.0000\n",
      "Epoch 561/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 827307200.0000 - val_loss: 2338764800.0000\n",
      "Epoch 562/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 830529536.0000 - val_loss: 2341378560.0000\n",
      "Epoch 563/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 859939776.0000 - val_loss: 2339801088.0000\n",
      "Epoch 564/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 838879040.0000 - val_loss: 2362073856.0000\n",
      "Epoch 565/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 833316544.0000 - val_loss: 2405541120.0000\n",
      "Epoch 566/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 830398464.0000 - val_loss: 2373915136.0000\n",
      "Epoch 567/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 830212672.0000 - val_loss: 2335936512.0000\n",
      "Epoch 568/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 833836800.0000 - val_loss: 2345127680.0000\n",
      "Epoch 569/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 851456640.0000 - val_loss: 2342525184.0000\n",
      "Epoch 570/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 821174208.0000 - val_loss: 2458934016.0000\n",
      "Epoch 571/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 823641536.0000 - val_loss: 2510260480.0000\n",
      "Epoch 572/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 825748224.0000 - val_loss: 2452042752.0000\n",
      "Epoch 573/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 818749376.0000 - val_loss: 2337803520.0000\n",
      "Epoch 574/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 807112640.0000 - val_loss: 2347625984.0000\n",
      "Epoch 575/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 822587840.0000 - val_loss: 2317629696.0000\n",
      "Epoch 576/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 828852096.0000 - val_loss: 2298888192.0000\n",
      "Epoch 577/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 808575808.0000 - val_loss: 2393812480.0000\n",
      "Epoch 578/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 810049664.0000 - val_loss: 2300763392.0000\n",
      "Epoch 579/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 810528064.0000 - val_loss: 2320113152.0000\n",
      "Epoch 580/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 802963968.0000 - val_loss: 2361398784.0000\n",
      "Epoch 581/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 812290752.0000 - val_loss: 2306157056.0000\n",
      "Epoch 582/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 803274240.0000 - val_loss: 2289384192.0000\n",
      "Epoch 583/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 810070976.0000 - val_loss: 2287761152.0000\n",
      "Epoch 584/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 808722112.0000 - val_loss: 2265004288.0000\n",
      "Epoch 585/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 795761408.0000 - val_loss: 2331703808.0000\n",
      "Epoch 586/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 808217024.0000 - val_loss: 2273129984.0000\n",
      "Epoch 587/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 810748544.0000 - val_loss: 2313510912.0000\n",
      "Epoch 588/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 802971136.0000 - val_loss: 2234308608.0000\n",
      "Epoch 589/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 804048704.0000 - val_loss: 2330852352.0000\n",
      "Epoch 590/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 798698176.0000 - val_loss: 2323017216.0000\n",
      "Epoch 591/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 812151040.0000 - val_loss: 2294935040.0000\n",
      "Epoch 592/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 793246272.0000 - val_loss: 2252400128.0000\n",
      "Epoch 593/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 784268800.0000 - val_loss: 2334974464.0000\n",
      "Epoch 594/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 805621312.0000 - val_loss: 2230166272.0000\n",
      "Epoch 595/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 787361088.0000 - val_loss: 2250324480.0000\n",
      "Epoch 596/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 792741120.0000 - val_loss: 2318394624.0000\n",
      "Epoch 597/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 788748032.0000 - val_loss: 2228964608.0000\n",
      "Epoch 598/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 797333312.0000 - val_loss: 2285843456.0000\n",
      "Epoch 599/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 790905408.0000 - val_loss: 2299964160.0000\n",
      "Epoch 600/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 787239616.0000 - val_loss: 2301548288.0000\n",
      "Epoch 601/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 789967744.0000 - val_loss: 2296258048.0000\n",
      "Epoch 602/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 791273152.0000 - val_loss: 2319191040.0000\n",
      "Epoch 603/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 799564032.0000 - val_loss: 2382779392.0000\n",
      "Epoch 604/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 781121856.0000 - val_loss: 2338613760.0000\n",
      "Epoch 605/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 789251776.0000 - val_loss: 2205071872.0000\n",
      "Epoch 606/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 784949056.0000 - val_loss: 2241972480.0000\n",
      "Epoch 607/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 784402304.0000 - val_loss: 2200367872.0000\n",
      "Epoch 608/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 789910144.0000 - val_loss: 2234309376.0000\n",
      "Epoch 609/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 791250496.0000 - val_loss: 2258002944.0000\n",
      "Epoch 610/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 765334208.0000 - val_loss: 2217521920.0000\n",
      "Epoch 611/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 770566080.0000 - val_loss: 2226818560.0000\n",
      "Epoch 612/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 774355584.0000 - val_loss: 2206440192.0000\n",
      "Epoch 613/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 768939904.0000 - val_loss: 2243727104.0000\n",
      "Epoch 614/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 782600448.0000 - val_loss: 2287467008.0000\n",
      "Epoch 615/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 777753024.0000 - val_loss: 2192654848.0000\n",
      "Epoch 616/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 769871488.0000 - val_loss: 2239265024.0000\n",
      "Epoch 617/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 765797760.0000 - val_loss: 2314642944.0000\n",
      "Epoch 618/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 776000704.0000 - val_loss: 2261459968.0000\n",
      "Epoch 619/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 769384832.0000 - val_loss: 2185072896.0000\n",
      "Epoch 620/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 771067264.0000 - val_loss: 2230789120.0000\n",
      "Epoch 621/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 768769088.0000 - val_loss: 2310738432.0000\n",
      "Epoch 622/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 759933120.0000 - val_loss: 2167243008.0000\n",
      "Epoch 623/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 771197760.0000 - val_loss: 2173319680.0000\n",
      "Epoch 624/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 754576000.0000 - val_loss: 2190700032.0000\n",
      "Epoch 625/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 777845184.0000 - val_loss: 2216074240.0000\n",
      "Epoch 626/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 752595008.0000 - val_loss: 2322479360.0000\n",
      "Epoch 627/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 749047296.0000 - val_loss: 2200973568.0000\n",
      "Epoch 628/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 761645248.0000 - val_loss: 2193862400.0000\n",
      "Epoch 629/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 768449216.0000 - val_loss: 2170823680.0000\n",
      "Epoch 630/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 763300288.0000 - val_loss: 2198347520.0000\n",
      "Epoch 631/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 760113536.0000 - val_loss: 2164670720.0000\n",
      "Epoch 632/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 770428992.0000 - val_loss: 2133298176.0000\n",
      "Epoch 633/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 771729600.0000 - val_loss: 2211991296.0000\n",
      "Epoch 634/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 751773376.0000 - val_loss: 2138170368.0000\n",
      "Epoch 635/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 774175360.0000 - val_loss: 2139787008.0000\n",
      "Epoch 636/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 743633216.0000 - val_loss: 2226836224.0000\n",
      "Epoch 637/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 742138048.0000 - val_loss: 2170788352.0000\n",
      "Epoch 638/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 741838720.0000 - val_loss: 2166016000.0000\n",
      "Epoch 639/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 764948544.0000 - val_loss: 2193959936.0000\n",
      "Epoch 640/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 745028608.0000 - val_loss: 2100127744.0000\n",
      "Epoch 641/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 743835008.0000 - val_loss: 2137198464.0000\n",
      "Epoch 642/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 753342912.0000 - val_loss: 2140622336.0000\n",
      "Epoch 643/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 741464576.0000 - val_loss: 2135554432.0000\n",
      "Epoch 644/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 733752704.0000 - val_loss: 2210820864.0000\n",
      "Epoch 645/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 737536256.0000 - val_loss: 2144097152.0000\n",
      "Epoch 646/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 735054400.0000 - val_loss: 2136395136.0000\n",
      "Epoch 647/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 736671104.0000 - val_loss: 2113140224.0000\n",
      "Epoch 648/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 742889920.0000 - val_loss: 2190662656.0000\n",
      "Epoch 649/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 741023552.0000 - val_loss: 2114215936.0000\n",
      "Epoch 650/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 741328064.0000 - val_loss: 2105808256.0000\n",
      "Epoch 651/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 774120512.0000 - val_loss: 2052396672.0000\n",
      "Epoch 652/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 730523136.0000 - val_loss: 2115262720.0000\n",
      "Epoch 653/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 739449792.0000 - val_loss: 2161655040.0000\n",
      "Epoch 654/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 727475648.0000 - val_loss: 2114320384.0000\n",
      "Epoch 655/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 736422464.0000 - val_loss: 2133105536.0000\n",
      "Epoch 656/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 731518208.0000 - val_loss: 2050976000.0000\n",
      "Epoch 657/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 731691200.0000 - val_loss: 2062883072.0000\n",
      "Epoch 658/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 731597376.0000 - val_loss: 2099604224.0000\n",
      "Epoch 659/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 727996224.0000 - val_loss: 2104097920.0000\n",
      "Epoch 660/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 718205056.0000 - val_loss: 2067454976.0000\n",
      "Epoch 661/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 726105920.0000 - val_loss: 2084800000.0000\n",
      "Epoch 662/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 722689152.0000 - val_loss: 2069429376.0000\n",
      "Epoch 663/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 721784512.0000 - val_loss: 2113662720.0000\n",
      "Epoch 664/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 735725376.0000 - val_loss: 2136745344.0000\n",
      "Epoch 665/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 720542592.0000 - val_loss: 2068177024.0000\n",
      "Epoch 666/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 719406144.0000 - val_loss: 2117132672.0000\n",
      "Epoch 667/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 723753984.0000 - val_loss: 2106151808.0000\n",
      "Epoch 668/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 723328064.0000 - val_loss: 2088948992.0000\n",
      "Epoch 669/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 726340800.0000 - val_loss: 2105162368.0000\n",
      "Epoch 670/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 707082304.0000 - val_loss: 2044369024.0000\n",
      "Epoch 671/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 711120064.0000 - val_loss: 2100571776.0000\n",
      "Epoch 672/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 729336960.0000 - val_loss: 2129547008.0000\n",
      "Epoch 673/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 711727552.0000 - val_loss: 2047390848.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 674/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 727940736.0000 - val_loss: 2055468288.0000\n",
      "Epoch 675/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 714925056.0000 - val_loss: 2071943424.0000\n",
      "Epoch 676/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 716258624.0000 - val_loss: 2060600448.0000\n",
      "Epoch 677/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 727890944.0000 - val_loss: 2047845760.0000\n",
      "Epoch 678/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 717415104.0000 - val_loss: 2072128512.0000\n",
      "Epoch 679/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 713978880.0000 - val_loss: 2091271040.0000\n",
      "Epoch 680/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 720361728.0000 - val_loss: 2032417792.0000\n",
      "Epoch 681/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 707933376.0000 - val_loss: 2067934848.0000\n",
      "Epoch 682/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 707542784.0000 - val_loss: 2030311936.0000\n",
      "Epoch 683/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 718186880.0000 - val_loss: 2103697536.0000\n",
      "Epoch 684/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 706783424.0000 - val_loss: 2082087424.0000\n",
      "Epoch 685/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 711495168.0000 - val_loss: 2008701824.0000\n",
      "Epoch 686/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 706166784.0000 - val_loss: 2061019776.0000\n",
      "Epoch 687/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 712467648.0000 - val_loss: 2017734144.0000\n",
      "Epoch 688/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 703405952.0000 - val_loss: 1995641984.0000\n",
      "Epoch 689/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 714270272.0000 - val_loss: 2023226240.0000\n",
      "Epoch 690/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 707004096.0000 - val_loss: 2065379200.0000\n",
      "Epoch 691/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 696707904.0000 - val_loss: 2097491456.0000\n",
      "Epoch 692/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 707199872.0000 - val_loss: 2065994368.0000\n",
      "Epoch 693/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 703243008.0000 - val_loss: 2022100608.0000\n",
      "Epoch 694/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 698386688.0000 - val_loss: 1996197760.0000\n",
      "Epoch 695/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 705473216.0000 - val_loss: 2073493760.0000\n",
      "Epoch 696/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 710135872.0000 - val_loss: 2018833024.0000\n",
      "Epoch 697/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 707708288.0000 - val_loss: 2047549952.0000\n",
      "Epoch 698/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 703379008.0000 - val_loss: 2056230912.0000\n",
      "Epoch 699/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 700458752.0000 - val_loss: 2062549632.0000\n",
      "Epoch 700/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 700974016.0000 - val_loss: 2042376320.0000\n",
      "Epoch 701/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 699040384.0000 - val_loss: 2098682368.0000\n",
      "Epoch 702/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 713036992.0000 - val_loss: 2108952576.0000\n",
      "Epoch 703/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 707814144.0000 - val_loss: 2034066176.0000\n",
      "Epoch 704/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 706707456.0000 - val_loss: 2049170176.0000\n",
      "Epoch 705/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 688006720.0000 - val_loss: 1989953024.0000\n",
      "Epoch 706/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 715436160.0000 - val_loss: 2039852800.0000\n",
      "Epoch 707/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 688887360.0000 - val_loss: 2004379520.0000\n",
      "Epoch 708/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 713288320.0000 - val_loss: 1998450176.0000\n",
      "Epoch 709/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 689624256.0000 - val_loss: 2007888256.0000\n",
      "Epoch 710/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 688919040.0000 - val_loss: 1988946560.0000\n",
      "Epoch 711/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 687068608.0000 - val_loss: 1974256640.0000\n",
      "Epoch 712/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 684947776.0000 - val_loss: 2049080960.0000\n",
      "Epoch 713/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 692976768.0000 - val_loss: 1950719104.0000\n",
      "Epoch 714/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 709558144.0000 - val_loss: 1984897152.0000\n",
      "Epoch 715/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 701236352.0000 - val_loss: 1987817728.0000\n",
      "Epoch 716/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 682662272.0000 - val_loss: 2030203648.0000\n",
      "Epoch 717/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 687244416.0000 - val_loss: 1950826624.0000\n",
      "Epoch 718/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 699024128.0000 - val_loss: 1975158272.0000\n",
      "Epoch 719/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 704043776.0000 - val_loss: 1963925120.0000\n",
      "Epoch 720/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 688369536.0000 - val_loss: 1931610112.0000\n",
      "Epoch 721/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 681359680.0000 - val_loss: 1957638912.0000\n",
      "Epoch 722/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 696515200.0000 - val_loss: 1977452160.0000\n",
      "Epoch 723/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 680352512.0000 - val_loss: 1942385152.0000\n",
      "Epoch 724/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 691073600.0000 - val_loss: 1971651968.0000\n",
      "Epoch 725/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 693617600.0000 - val_loss: 1963328640.0000\n",
      "Epoch 726/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 697845632.0000 - val_loss: 1953474048.0000\n",
      "Epoch 727/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 691162624.0000 - val_loss: 1983901184.0000\n",
      "Epoch 728/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 668646336.0000 - val_loss: 2090316672.0000\n",
      "Epoch 729/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 678105280.0000 - val_loss: 1949387904.0000\n",
      "Epoch 730/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 670137920.0000 - val_loss: 2084061824.0000\n",
      "Epoch 731/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 703550848.0000 - val_loss: 1952409856.0000\n",
      "Epoch 732/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 679715328.0000 - val_loss: 1961179264.0000\n",
      "Epoch 733/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 670799872.0000 - val_loss: 1934405376.0000\n",
      "Epoch 734/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 671675968.0000 - val_loss: 1922185088.0000\n",
      "Epoch 735/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 680259904.0000 - val_loss: 1936435456.0000\n",
      "Epoch 736/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 671388160.0000 - val_loss: 2063156352.0000\n",
      "Epoch 737/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 690777792.0000 - val_loss: 1997669760.0000\n",
      "Epoch 738/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 669064192.0000 - val_loss: 1947541632.0000\n",
      "Epoch 739/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 672389184.0000 - val_loss: 1916222464.0000\n",
      "Epoch 740/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 690287808.0000 - val_loss: 2043763328.0000\n",
      "Epoch 741/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 686219776.0000 - val_loss: 1966281472.0000\n",
      "Epoch 742/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 675729792.0000 - val_loss: 1936142976.0000\n",
      "Epoch 743/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 668377472.0000 - val_loss: 2020685056.0000\n",
      "Epoch 744/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 677801600.0000 - val_loss: 1939319040.0000\n",
      "Epoch 745/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 662757632.0000 - val_loss: 1890362496.0000\n",
      "Epoch 746/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 668518528.0000 - val_loss: 1920207872.0000\n",
      "Epoch 747/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 678943616.0000 - val_loss: 1901297152.0000\n",
      "Epoch 748/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 669522176.0000 - val_loss: 1972688128.0000\n",
      "Epoch 749/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 688223424.0000 - val_loss: 1998514816.0000\n",
      "Epoch 750/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 684206848.0000 - val_loss: 1932155136.0000\n",
      "Epoch 751/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 668560512.0000 - val_loss: 1905724544.0000\n",
      "Epoch 752/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 666077248.0000 - val_loss: 1933435520.0000\n",
      "Epoch 753/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 664349120.0000 - val_loss: 2019205376.0000\n",
      "Epoch 754/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 668240512.0000 - val_loss: 1911290112.0000\n",
      "Epoch 755/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 658640448.0000 - val_loss: 2023259776.0000\n",
      "Epoch 756/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 662189888.0000 - val_loss: 1916388224.0000\n",
      "Epoch 757/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 661444800.0000 - val_loss: 1916981120.0000\n",
      "Epoch 758/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 649096320.0000 - val_loss: 1866244864.0000\n",
      "Epoch 759/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 675198016.0000 - val_loss: 1913196928.0000\n",
      "Epoch 760/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 662723456.0000 - val_loss: 1943063296.0000\n",
      "Epoch 761/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 658601152.0000 - val_loss: 2015489536.0000\n",
      "Epoch 762/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 666688832.0000 - val_loss: 1918031488.0000\n",
      "Epoch 763/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 677114112.0000 - val_loss: 1915961600.0000\n",
      "Epoch 764/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 662100928.0000 - val_loss: 2011059072.0000\n",
      "Epoch 765/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 661119872.0000 - val_loss: 2000084864.0000\n",
      "Epoch 766/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 664725952.0000 - val_loss: 1925745280.0000\n",
      "Epoch 767/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 661960448.0000 - val_loss: 1910910080.0000\n",
      "Epoch 768/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 672164352.0000 - val_loss: 1979115904.0000\n",
      "Epoch 769/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 641962688.0000 - val_loss: 1909875968.0000\n",
      "Epoch 770/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 661105792.0000 - val_loss: 1860881664.0000\n",
      "Epoch 771/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 653313536.0000 - val_loss: 1887079168.0000\n",
      "Epoch 772/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 659041472.0000 - val_loss: 1924453248.0000\n",
      "Epoch 773/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 660646912.0000 - val_loss: 2063196800.0000\n",
      "Epoch 774/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 650114496.0000 - val_loss: 1902673920.0000\n",
      "Epoch 775/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 653647040.0000 - val_loss: 1888135168.0000\n",
      "Epoch 776/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 660659392.0000 - val_loss: 1850898944.0000\n",
      "Epoch 777/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 653089344.0000 - val_loss: 1884706176.0000\n",
      "Epoch 778/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 662098368.0000 - val_loss: 1923693568.0000\n",
      "Epoch 779/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 665340096.0000 - val_loss: 1888234112.0000\n",
      "Epoch 780/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 669473408.0000 - val_loss: 1882743552.0000\n",
      "Epoch 781/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 680805760.0000 - val_loss: 1881137152.0000\n",
      "Epoch 782/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 651215808.0000 - val_loss: 1878007424.0000\n",
      "Epoch 783/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 647815168.0000 - val_loss: 1849395456.0000\n",
      "Epoch 784/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 662451648.0000 - val_loss: 1935487616.0000\n",
      "Epoch 785/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 642283648.0000 - val_loss: 1852434560.0000\n",
      "Epoch 786/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 653800064.0000 - val_loss: 1885358464.0000\n",
      "Epoch 787/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 645475968.0000 - val_loss: 1939679104.0000\n",
      "Epoch 788/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 639631168.0000 - val_loss: 1874937728.0000\n",
      "Epoch 789/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 635976384.0000 - val_loss: 1965146112.0000\n",
      "Epoch 790/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 644741120.0000 - val_loss: 1920907008.0000\n",
      "Epoch 791/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 649805824.0000 - val_loss: 1890252800.0000\n",
      "Epoch 792/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 635793856.0000 - val_loss: 1848279552.0000\n",
      "Epoch 793/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 657454528.0000 - val_loss: 1843742976.0000\n",
      "Epoch 794/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 652570496.0000 - val_loss: 1937124352.0000\n",
      "Epoch 795/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 636002048.0000 - val_loss: 1859303808.0000\n",
      "Epoch 796/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 663475072.0000 - val_loss: 1890080256.0000\n",
      "Epoch 797/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 662273472.0000 - val_loss: 1875796864.0000\n",
      "Epoch 798/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 659028032.0000 - val_loss: 2004519040.0000\n",
      "Epoch 799/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 652955392.0000 - val_loss: 1866764416.0000\n",
      "Epoch 800/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 664824384.0000 - val_loss: 1847440000.0000\n",
      "Epoch 801/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 632829056.0000 - val_loss: 1928788992.0000\n",
      "Epoch 802/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 638732096.0000 - val_loss: 1964790656.0000\n",
      "Epoch 803/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 645740992.0000 - val_loss: 1841221760.0000\n",
      "Epoch 804/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 636178752.0000 - val_loss: 2047948544.0000\n",
      "Epoch 805/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 666039232.0000 - val_loss: 1847830272.0000\n",
      "Epoch 806/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 643299008.0000 - val_loss: 1842805632.0000\n",
      "Epoch 807/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 636971136.0000 - val_loss: 1851941248.0000\n",
      "Epoch 808/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 648014016.0000 - val_loss: 1855989248.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 809/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 644401408.0000 - val_loss: 1823243776.0000\n",
      "Epoch 810/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 628239104.0000 - val_loss: 1842638464.0000\n",
      "Epoch 811/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 633922752.0000 - val_loss: 1812618880.0000\n",
      "Epoch 812/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 635702848.0000 - val_loss: 1847737600.0000\n",
      "Epoch 813/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 629286848.0000 - val_loss: 1859971840.0000\n",
      "Epoch 814/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 632407488.0000 - val_loss: 1876640000.0000\n",
      "Epoch 815/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 629712000.0000 - val_loss: 1817174144.0000\n",
      "Epoch 816/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 616229248.0000 - val_loss: 1887951488.0000\n",
      "Epoch 817/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 629582400.0000 - val_loss: 1880812544.0000\n",
      "Epoch 818/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 659568896.0000 - val_loss: 1828029440.0000\n",
      "Epoch 819/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 636977728.0000 - val_loss: 1849076992.0000\n",
      "Epoch 820/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 635568640.0000 - val_loss: 1898596736.0000\n",
      "Epoch 821/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 643694656.0000 - val_loss: 1851477632.0000\n",
      "Epoch 822/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 626210496.0000 - val_loss: 1845320960.0000\n",
      "Epoch 823/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 617038464.0000 - val_loss: 1875617152.0000\n",
      "Epoch 824/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 632099392.0000 - val_loss: 1868041088.0000\n",
      "Epoch 825/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 617369664.0000 - val_loss: 1834595712.0000\n",
      "Epoch 826/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 616509184.0000 - val_loss: 1815629824.0000\n",
      "Epoch 827/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 631452736.0000 - val_loss: 1798238720.0000\n",
      "Epoch 828/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 625829056.0000 - val_loss: 1841631616.0000\n",
      "Epoch 829/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 621910784.0000 - val_loss: 1869986048.0000\n",
      "Epoch 830/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 638245888.0000 - val_loss: 1878012928.0000\n",
      "Epoch 831/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 628266688.0000 - val_loss: 1850525184.0000\n",
      "Epoch 832/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 632149888.0000 - val_loss: 1846894848.0000\n",
      "Epoch 833/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 625637376.0000 - val_loss: 1811774720.0000\n",
      "Epoch 834/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 634346688.0000 - val_loss: 1845152128.0000\n",
      "Epoch 835/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 621324224.0000 - val_loss: 1861582848.0000\n",
      "Epoch 836/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 614190720.0000 - val_loss: 1831002624.0000\n",
      "Epoch 837/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 626213120.0000 - val_loss: 1792911744.0000\n",
      "Epoch 838/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 621228160.0000 - val_loss: 1797941632.0000\n",
      "Epoch 839/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 624661760.0000 - val_loss: 1884334592.0000\n",
      "Epoch 840/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 618900544.0000 - val_loss: 1887866368.0000\n",
      "Epoch 841/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 619479616.0000 - val_loss: 1777996800.0000\n",
      "Epoch 842/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 615528128.0000 - val_loss: 1782354048.0000\n",
      "Epoch 843/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 624157760.0000 - val_loss: 1818816512.0000\n",
      "Epoch 844/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 622780544.0000 - val_loss: 1783413632.0000\n",
      "Epoch 845/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 622038784.0000 - val_loss: 1821893504.0000\n",
      "Epoch 846/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 626723072.0000 - val_loss: 1904447232.0000\n",
      "Epoch 847/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 627035072.0000 - val_loss: 1821849088.0000\n",
      "Epoch 848/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 607961664.0000 - val_loss: 1789983872.0000\n",
      "Epoch 849/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 612114112.0000 - val_loss: 1856864768.0000\n",
      "Epoch 850/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 621707904.0000 - val_loss: 1821582720.0000\n",
      "Epoch 851/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 606794048.0000 - val_loss: 1840724224.0000\n",
      "Epoch 852/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 597801792.0000 - val_loss: 1922967936.0000\n",
      "Epoch 853/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 616098368.0000 - val_loss: 1778105984.0000\n",
      "Epoch 854/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 615034880.0000 - val_loss: 1827267840.0000\n",
      "Epoch 855/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 605295360.0000 - val_loss: 1778340864.0000\n",
      "Epoch 856/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 609379392.0000 - val_loss: 1817772160.0000\n",
      "Epoch 857/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 602320448.0000 - val_loss: 1803705856.0000\n",
      "Epoch 858/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 623532480.0000 - val_loss: 1746685056.0000\n",
      "Epoch 859/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 620404672.0000 - val_loss: 1871572608.0000\n",
      "Epoch 860/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 599320448.0000 - val_loss: 1863295616.0000\n",
      "Epoch 861/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 612664960.0000 - val_loss: 1853597184.0000\n",
      "Epoch 862/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 608445376.0000 - val_loss: 1870751360.0000\n",
      "Epoch 863/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 618124352.0000 - val_loss: 1838026368.0000\n",
      "Epoch 864/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 609013952.0000 - val_loss: 1777562880.0000\n",
      "Epoch 865/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 622487488.0000 - val_loss: 1853429760.0000\n",
      "Epoch 866/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 626865152.0000 - val_loss: 1844209280.0000\n",
      "Epoch 867/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 587136896.0000 - val_loss: 1858493824.0000\n",
      "Epoch 868/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 599309312.0000 - val_loss: 1801397504.0000\n",
      "Epoch 869/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 614039936.0000 - val_loss: 1838518144.0000\n",
      "Epoch 870/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 602500800.0000 - val_loss: 1860487424.0000\n",
      "Epoch 871/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 601299136.0000 - val_loss: 1822636672.0000\n",
      "Epoch 872/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 612494976.0000 - val_loss: 1775250432.0000\n",
      "Epoch 873/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 607372800.0000 - val_loss: 1839033344.0000\n",
      "Epoch 874/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 598171392.0000 - val_loss: 1846737280.0000\n",
      "Epoch 875/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 605072448.0000 - val_loss: 1764127616.0000\n",
      "Epoch 876/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 599168832.0000 - val_loss: 1791832576.0000\n",
      "Epoch 877/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 602910976.0000 - val_loss: 1819457920.0000\n",
      "Epoch 878/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 609894400.0000 - val_loss: 1783053056.0000\n",
      "Epoch 879/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 589421120.0000 - val_loss: 1815924480.0000\n",
      "Epoch 880/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 595837952.0000 - val_loss: 1845180928.0000\n",
      "Epoch 881/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 596012736.0000 - val_loss: 1784194432.0000\n",
      "Epoch 882/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 601056192.0000 - val_loss: 1848433664.0000\n",
      "Epoch 883/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 592983872.0000 - val_loss: 1830380800.0000\n",
      "Epoch 884/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 606860736.0000 - val_loss: 1805606656.0000\n",
      "Epoch 885/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 611426752.0000 - val_loss: 1740721024.0000\n",
      "Epoch 886/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 590609088.0000 - val_loss: 1847140480.0000\n",
      "Epoch 887/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 609506752.0000 - val_loss: 1757486080.0000\n",
      "Epoch 888/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 597180672.0000 - val_loss: 1796624896.0000\n",
      "Epoch 889/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 595682752.0000 - val_loss: 1893029632.0000\n",
      "Epoch 890/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 595367168.0000 - val_loss: 1788090496.0000\n",
      "Epoch 891/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 585781248.0000 - val_loss: 1785727488.0000\n",
      "Epoch 892/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 586438784.0000 - val_loss: 1766836352.0000\n",
      "Epoch 893/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 618063488.0000 - val_loss: 1842652544.0000\n",
      "Epoch 894/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 583180224.0000 - val_loss: 1836198016.0000\n",
      "Epoch 895/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 585790592.0000 - val_loss: 1889554560.0000\n",
      "Epoch 896/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 591021184.0000 - val_loss: 1881701504.0000\n",
      "Epoch 897/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 599256704.0000 - val_loss: 1832034688.0000\n",
      "Epoch 898/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 594906496.0000 - val_loss: 1778407040.0000\n",
      "Epoch 899/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 600119680.0000 - val_loss: 1934252928.0000\n",
      "Epoch 900/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 586891328.0000 - val_loss: 1813155584.0000\n",
      "Epoch 901/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 574472128.0000 - val_loss: 1821384064.0000\n",
      "Epoch 902/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 587456896.0000 - val_loss: 1911695616.0000\n",
      "Epoch 903/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 602507136.0000 - val_loss: 1907177600.0000\n",
      "Epoch 904/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 586810944.0000 - val_loss: 1770067712.0000\n",
      "Epoch 905/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 575625280.0000 - val_loss: 1772978944.0000\n",
      "Epoch 906/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 565691520.0000 - val_loss: 1759687296.0000\n",
      "Epoch 907/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 582610560.0000 - val_loss: 1796470016.0000\n",
      "Epoch 908/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 585838784.0000 - val_loss: 1792838784.0000\n",
      "Epoch 909/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 593241600.0000 - val_loss: 1806581376.0000\n",
      "Epoch 910/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 587181568.0000 - val_loss: 1747840000.0000\n",
      "Epoch 911/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 573686528.0000 - val_loss: 1734382208.0000\n",
      "Epoch 912/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 578789824.0000 - val_loss: 1800139264.0000\n",
      "Epoch 913/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 581031424.0000 - val_loss: 1849288448.0000\n",
      "Epoch 914/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 587222016.0000 - val_loss: 1776014720.0000\n",
      "Epoch 915/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 588827648.0000 - val_loss: 1800020096.0000\n",
      "Epoch 916/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 579635392.0000 - val_loss: 1777392256.0000\n",
      "Epoch 917/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 577813312.0000 - val_loss: 1877472384.0000\n",
      "Epoch 918/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 583343360.0000 - val_loss: 1795638016.0000\n",
      "Epoch 919/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 584959488.0000 - val_loss: 1763121664.0000\n",
      "Epoch 920/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 575228352.0000 - val_loss: 1698941568.0000\n",
      "Epoch 921/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 565368896.0000 - val_loss: 1934132480.0000\n",
      "Epoch 922/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 586315968.0000 - val_loss: 1794929536.0000\n",
      "Epoch 923/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 573724864.0000 - val_loss: 1965131904.0000\n",
      "Epoch 924/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 576568832.0000 - val_loss: 1775649536.0000\n",
      "Epoch 925/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 576072192.0000 - val_loss: 1804096768.0000\n",
      "Epoch 926/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 571746304.0000 - val_loss: 1838148992.0000\n",
      "Epoch 927/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 565963264.0000 - val_loss: 1819484928.0000\n",
      "Epoch 928/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 558192384.0000 - val_loss: 1854052480.0000\n",
      "Epoch 929/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 571020416.0000 - val_loss: 1826981888.0000\n",
      "Epoch 930/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 561945152.0000 - val_loss: 1808330240.0000\n",
      "Epoch 931/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 559321344.0000 - val_loss: 1750153088.0000\n",
      "Epoch 932/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 553972096.0000 - val_loss: 1719441664.0000\n",
      "Epoch 933/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 560327296.0000 - val_loss: 1782222720.0000\n",
      "Epoch 934/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 560325184.0000 - val_loss: 1813377792.0000\n",
      "Epoch 935/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 565897024.0000 - val_loss: 1737235584.0000\n",
      "Epoch 936/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 556939968.0000 - val_loss: 1734040064.0000\n",
      "Epoch 937/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 577257024.0000 - val_loss: 1717253888.0000\n",
      "Epoch 938/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 569869376.0000 - val_loss: 1834105728.0000\n",
      "Epoch 939/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 571579520.0000 - val_loss: 1775359104.0000\n",
      "Epoch 940/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 562665536.0000 - val_loss: 1774629888.0000\n",
      "Epoch 941/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 566832192.0000 - val_loss: 1917228800.0000\n",
      "Epoch 942/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 570438784.0000 - val_loss: 1804108288.0000\n",
      "Epoch 943/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 552100032.0000 - val_loss: 1809473152.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 944/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 557185728.0000 - val_loss: 1802685824.0000\n",
      "Epoch 945/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 583001792.0000 - val_loss: 1754963328.0000\n",
      "Epoch 946/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 549498240.0000 - val_loss: 1823578752.0000\n",
      "Epoch 947/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 563929920.0000 - val_loss: 1714286208.0000\n",
      "Epoch 948/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 552617280.0000 - val_loss: 1729865344.0000\n",
      "Epoch 949/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 549821824.0000 - val_loss: 1794449920.0000\n",
      "Epoch 950/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 573350400.0000 - val_loss: 1738882560.0000\n",
      "Epoch 951/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 561106688.0000 - val_loss: 1752510208.0000\n",
      "Epoch 952/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 548705408.0000 - val_loss: 1816264064.0000\n",
      "Epoch 953/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 551847232.0000 - val_loss: 1693426560.0000\n",
      "Epoch 954/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 541285888.0000 - val_loss: 1711517056.0000\n",
      "Epoch 955/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 572920512.0000 - val_loss: 1714748160.0000\n",
      "Epoch 956/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 550417728.0000 - val_loss: 1718143360.0000\n",
      "Epoch 957/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 553504000.0000 - val_loss: 1756197888.0000\n",
      "Epoch 958/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 528634688.0000 - val_loss: 1839803648.0000\n",
      "Epoch 959/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 539169600.0000 - val_loss: 1889159040.0000\n",
      "Epoch 960/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 563361088.0000 - val_loss: 1694942976.0000\n",
      "Epoch 961/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 576571392.0000 - val_loss: 1886441600.0000\n",
      "Epoch 962/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 554181952.0000 - val_loss: 1722200832.0000\n",
      "Epoch 963/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 547795456.0000 - val_loss: 1748512768.0000\n",
      "Epoch 964/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 541900032.0000 - val_loss: 1794428544.0000\n",
      "Epoch 965/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 551141312.0000 - val_loss: 1732435712.0000\n",
      "Epoch 966/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 531164544.0000 - val_loss: 1699381504.0000\n",
      "Epoch 967/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 546135424.0000 - val_loss: 1736430208.0000\n",
      "Epoch 968/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 544977536.0000 - val_loss: 1718507264.0000\n",
      "Epoch 969/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 549002176.0000 - val_loss: 1783505920.0000\n",
      "Epoch 970/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 535682048.0000 - val_loss: 1776932736.0000\n",
      "Epoch 971/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 533610944.0000 - val_loss: 1701037312.0000\n",
      "Epoch 972/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 538264960.0000 - val_loss: 1685489152.0000\n",
      "Epoch 973/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 533385056.0000 - val_loss: 1763694592.0000\n",
      "Epoch 974/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 541468096.0000 - val_loss: 1745220608.0000\n",
      "Epoch 975/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 532788032.0000 - val_loss: 1755646720.0000\n",
      "Epoch 976/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 550345024.0000 - val_loss: 1856814464.0000\n",
      "Epoch 977/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 532294912.0000 - val_loss: 1739766784.0000\n",
      "Epoch 978/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 529715840.0000 - val_loss: 1740109568.0000\n",
      "Epoch 979/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 519945952.0000 - val_loss: 1710993792.0000\n",
      "Epoch 980/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 545995904.0000 - val_loss: 1778174208.0000\n",
      "Epoch 981/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 531581760.0000 - val_loss: 1751960192.0000\n",
      "Epoch 982/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 537938368.0000 - val_loss: 1763284608.0000\n",
      "Epoch 983/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 535102464.0000 - val_loss: 1745746048.0000\n",
      "Epoch 984/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 544005248.0000 - val_loss: 1705954560.0000\n",
      "Epoch 985/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 544457920.0000 - val_loss: 1748083200.0000\n",
      "Epoch 986/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 521615904.0000 - val_loss: 1807898368.0000\n",
      "Epoch 987/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 544500928.0000 - val_loss: 1719237888.0000\n",
      "Epoch 988/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 545086400.0000 - val_loss: 1712150144.0000\n",
      "Epoch 989/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 546240256.0000 - val_loss: 1701644928.0000\n",
      "Epoch 990/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 533121280.0000 - val_loss: 1690014720.0000\n",
      "Epoch 991/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 522812544.0000 - val_loss: 1711099904.0000\n",
      "Epoch 992/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 549175040.0000 - val_loss: 1746544640.0000\n",
      "Epoch 993/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 526320640.0000 - val_loss: 1769124224.0000\n",
      "Epoch 994/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 553572224.0000 - val_loss: 1831391872.0000\n",
      "Epoch 995/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 546356352.0000 - val_loss: 1656044416.0000\n",
      "Epoch 996/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 518638880.0000 - val_loss: 1720011520.0000\n",
      "Epoch 997/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 530897632.0000 - val_loss: 1749399424.0000\n",
      "Epoch 998/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 539150080.0000 - val_loss: 1746919168.0000\n",
      "Epoch 999/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 533674400.0000 - val_loss: 1663670528.0000\n",
      "Epoch 1000/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 521326208.0000 - val_loss: 1832396544.0000\n",
      "Epoch 1001/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 525975168.0000 - val_loss: 1726014336.0000\n",
      "Epoch 1002/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 513986240.0000 - val_loss: 2016574464.0000\n",
      "Epoch 1003/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 533588064.0000 - val_loss: 1835829888.0000\n",
      "Epoch 1004/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 522845632.0000 - val_loss: 1740925440.0000\n",
      "Epoch 1005/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 517524992.0000 - val_loss: 1684584064.0000\n",
      "Epoch 1006/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 513168832.0000 - val_loss: 1776774912.0000\n",
      "Epoch 1007/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 527470144.0000 - val_loss: 1719057280.0000\n",
      "Epoch 1008/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 526079264.0000 - val_loss: 1676757632.0000\n",
      "Epoch 1009/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 514040064.0000 - val_loss: 1798385792.0000\n",
      "Epoch 1010/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 525985536.0000 - val_loss: 1768676864.0000\n",
      "Epoch 1011/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 506742752.0000 - val_loss: 1664416128.0000\n",
      "Epoch 1012/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 519655968.0000 - val_loss: 1683202688.0000\n",
      "Epoch 1013/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 562687168.0000 - val_loss: 1792424064.0000\n",
      "Epoch 1014/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 502275168.0000 - val_loss: 1676218240.0000\n",
      "Epoch 1015/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 523132288.0000 - val_loss: 1756742784.0000\n",
      "Epoch 1016/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 503965888.0000 - val_loss: 1740024320.0000\n",
      "Epoch 1017/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 527927456.0000 - val_loss: 1897388672.0000\n",
      "Epoch 1018/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 519912416.0000 - val_loss: 1709392768.0000\n",
      "Epoch 1019/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 527792704.0000 - val_loss: 1677010688.0000\n",
      "Epoch 1020/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 528501088.0000 - val_loss: 1729569664.0000\n",
      "Epoch 1021/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 502046496.0000 - val_loss: 1677426944.0000\n",
      "Epoch 1022/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 511094688.0000 - val_loss: 1696186368.0000\n",
      "Epoch 1023/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 505716928.0000 - val_loss: 1747381632.0000\n",
      "Epoch 1024/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 496724832.0000 - val_loss: 1774088320.0000\n",
      "Epoch 1025/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 510019360.0000 - val_loss: 1691981440.0000\n",
      "Epoch 1026/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 529089184.0000 - val_loss: 1756902656.0000\n",
      "Epoch 1027/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 514871392.0000 - val_loss: 1752811520.0000\n",
      "Epoch 1028/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 522397824.0000 - val_loss: 1767015424.0000\n",
      "Epoch 1029/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 526839648.0000 - val_loss: 1680554880.0000\n",
      "Epoch 1030/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 504517984.0000 - val_loss: 1723795328.0000\n",
      "Epoch 1031/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 532554176.0000 - val_loss: 1705100416.0000\n",
      "Epoch 1032/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 531731904.0000 - val_loss: 1739157376.0000\n",
      "Epoch 1033/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 497009856.0000 - val_loss: 1686928384.0000\n",
      "Epoch 1034/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 507904800.0000 - val_loss: 1676228992.0000\n",
      "Epoch 1035/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 524530944.0000 - val_loss: 1707527424.0000\n",
      "Epoch 1036/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 493514208.0000 - val_loss: 1697761664.0000\n",
      "Epoch 1037/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 513328736.0000 - val_loss: 1763849728.0000\n",
      "Epoch 1038/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 519683008.0000 - val_loss: 1662848000.0000\n",
      "Epoch 1039/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 508391872.0000 - val_loss: 1692018560.0000\n",
      "Epoch 1040/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 496177952.0000 - val_loss: 1690372352.0000\n",
      "Epoch 1041/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 491860864.0000 - val_loss: 1677726848.0000\n",
      "Epoch 1042/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 501723680.0000 - val_loss: 1781948032.0000\n",
      "Epoch 1043/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 500479168.0000 - val_loss: 1716221056.0000\n",
      "Epoch 1044/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 508094336.0000 - val_loss: 1755830272.0000\n",
      "Epoch 1045/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 505195008.0000 - val_loss: 1908457472.0000\n",
      "Epoch 1046/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 502510848.0000 - val_loss: 1679336704.0000\n",
      "Epoch 1047/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 486055264.0000 - val_loss: 1757966720.0000\n",
      "Epoch 1048/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 529934752.0000 - val_loss: 1705197568.0000\n",
      "Epoch 1049/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 497959008.0000 - val_loss: 1639037824.0000\n",
      "Epoch 1050/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 510222272.0000 - val_loss: 1650628352.0000\n",
      "Epoch 1051/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 494402848.0000 - val_loss: 1709223680.0000\n",
      "Epoch 1052/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 501835424.0000 - val_loss: 1661852160.0000\n",
      "Epoch 1053/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 495806240.0000 - val_loss: 1671593344.0000\n",
      "Epoch 1054/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 507249152.0000 - val_loss: 1690477952.0000\n",
      "Epoch 1055/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 491704800.0000 - val_loss: 1685728384.0000\n",
      "Epoch 1056/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 487072256.0000 - val_loss: 1660738560.0000\n",
      "Epoch 1057/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 490335168.0000 - val_loss: 1687444480.0000\n",
      "Epoch 1058/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 503924800.0000 - val_loss: 1622304000.0000\n",
      "Epoch 1059/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 477410720.0000 - val_loss: 1681630464.0000\n",
      "Epoch 1060/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 504067360.0000 - val_loss: 1634101376.0000\n",
      "Epoch 1061/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 514754048.0000 - val_loss: 1627685376.0000\n",
      "Epoch 1062/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 484201696.0000 - val_loss: 1700250880.0000\n",
      "Epoch 1063/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 487393696.0000 - val_loss: 1647279872.0000\n",
      "Epoch 1064/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 490183168.0000 - val_loss: 1660251648.0000\n",
      "Epoch 1065/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 497009696.0000 - val_loss: 1692707072.0000\n",
      "Epoch 1066/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 488757216.0000 - val_loss: 1667303040.0000\n",
      "Epoch 1067/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 491978112.0000 - val_loss: 1714512896.0000\n",
      "Epoch 1068/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 496646464.0000 - val_loss: 1618962432.0000\n",
      "Epoch 1069/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 492018624.0000 - val_loss: 1665948160.0000\n",
      "Epoch 1070/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 475948160.0000 - val_loss: 1623875584.0000\n",
      "Epoch 1071/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 485656160.0000 - val_loss: 1765229056.0000\n",
      "Epoch 1072/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 512060480.0000 - val_loss: 1612338944.0000\n",
      "Epoch 1073/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 510597536.0000 - val_loss: 1645271936.0000\n",
      "Epoch 1074/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 505133856.0000 - val_loss: 1637353088.0000\n",
      "Epoch 1075/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 485912096.0000 - val_loss: 1761771008.0000\n",
      "Epoch 1076/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 485709824.0000 - val_loss: 1640563968.0000\n",
      "Epoch 1077/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 482501824.0000 - val_loss: 1628138880.0000\n",
      "Epoch 1078/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 494255168.0000 - val_loss: 1667450752.0000\n",
      "Epoch 1079/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 482443008.0000 - val_loss: 1643689728.0000\n",
      "Epoch 1080/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 488247680.0000 - val_loss: 1635255424.0000\n",
      "Epoch 1081/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 489734336.0000 - val_loss: 1604211584.0000\n",
      "Epoch 1082/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 487331008.0000 - val_loss: 1601313792.0000\n",
      "Epoch 1083/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 496210016.0000 - val_loss: 1675906560.0000\n",
      "Epoch 1084/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 478287232.0000 - val_loss: 1647065088.0000\n",
      "Epoch 1085/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 485605856.0000 - val_loss: 1874017792.0000\n",
      "Epoch 1086/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 474590368.0000 - val_loss: 1657893376.0000\n",
      "Epoch 1087/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 472433088.0000 - val_loss: 1627712128.0000\n",
      "Epoch 1088/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 520441952.0000 - val_loss: 1659264256.0000\n",
      "Epoch 1089/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 467102400.0000 - val_loss: 1651374464.0000\n",
      "Epoch 1090/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 505321760.0000 - val_loss: 1641777024.0000\n",
      "Epoch 1091/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 466090240.0000 - val_loss: 1781979008.0000\n",
      "Epoch 1092/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 511323104.0000 - val_loss: 1671747456.0000\n",
      "Epoch 1093/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 489652192.0000 - val_loss: 1636070656.0000\n",
      "Epoch 1094/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 463946368.0000 - val_loss: 1624968704.0000\n",
      "Epoch 1095/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 469331456.0000 - val_loss: 1626422272.0000\n",
      "Epoch 1096/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 481109728.0000 - val_loss: 1633486976.0000\n",
      "Epoch 1097/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 471738912.0000 - val_loss: 1641541760.0000\n",
      "Epoch 1098/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 463389440.0000 - val_loss: 1635246592.0000\n",
      "Epoch 1099/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 467642528.0000 - val_loss: 1728486912.0000\n",
      "Epoch 1100/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 471379136.0000 - val_loss: 1583854848.0000\n",
      "Epoch 1101/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 475461504.0000 - val_loss: 1614154624.0000\n",
      "Epoch 1102/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 493040192.0000 - val_loss: 1591461632.0000\n",
      "Epoch 1103/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 489279904.0000 - val_loss: 1639095680.0000\n",
      "Epoch 1104/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 479871552.0000 - val_loss: 1623777024.0000\n",
      "Epoch 1105/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 496847136.0000 - val_loss: 1648862976.0000\n",
      "Epoch 1106/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 460576704.0000 - val_loss: 1685179904.0000\n",
      "Epoch 1107/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 465543968.0000 - val_loss: 1631612032.0000\n",
      "Epoch 1108/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 466301824.0000 - val_loss: 1631479808.0000\n",
      "Epoch 1109/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 466333440.0000 - val_loss: 1645981568.0000\n",
      "Epoch 1110/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 459677280.0000 - val_loss: 1573936640.0000\n",
      "Epoch 1111/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 473304896.0000 - val_loss: 1679483776.0000\n",
      "Epoch 1112/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 501876288.0000 - val_loss: 1710785152.0000\n",
      "Epoch 1113/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 482077440.0000 - val_loss: 1757653888.0000\n",
      "Epoch 1114/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 509644608.0000 - val_loss: 1588398976.0000\n",
      "Epoch 1115/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 454290944.0000 - val_loss: 1599819904.0000\n",
      "Epoch 1116/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 457555616.0000 - val_loss: 1615818752.0000\n",
      "Epoch 1117/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 445691808.0000 - val_loss: 1584543360.0000\n",
      "Epoch 1118/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 472105088.0000 - val_loss: 1591196800.0000\n",
      "Epoch 1119/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 472169696.0000 - val_loss: 1677412864.0000\n",
      "Epoch 1120/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 500393344.0000 - val_loss: 1592922368.0000\n",
      "Epoch 1121/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 471110240.0000 - val_loss: 1604528512.0000\n",
      "Epoch 1122/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 463004448.0000 - val_loss: 1639370112.0000\n",
      "Epoch 1123/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 462721760.0000 - val_loss: 1562754048.0000\n",
      "Epoch 1124/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 463197984.0000 - val_loss: 1564954240.0000\n",
      "Epoch 1125/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 460881248.0000 - val_loss: 1674903552.0000\n",
      "Epoch 1126/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 469235968.0000 - val_loss: 1592094080.0000\n",
      "Epoch 1127/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 448416992.0000 - val_loss: 1616016640.0000\n",
      "Epoch 1128/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 442050784.0000 - val_loss: 1834310656.0000\n",
      "Epoch 1129/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 449012384.0000 - val_loss: 1606643712.0000\n",
      "Epoch 1130/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 459177120.0000 - val_loss: 1678657280.0000\n",
      "Epoch 1131/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 452828096.0000 - val_loss: 1618957184.0000\n",
      "Epoch 1132/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 449377024.0000 - val_loss: 1609877888.0000\n",
      "Epoch 1133/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 454844224.0000 - val_loss: 1571696256.0000\n",
      "Epoch 1134/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 465420864.0000 - val_loss: 1672299648.0000\n",
      "Epoch 1135/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 471549920.0000 - val_loss: 1651067648.0000\n",
      "Epoch 1136/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 460457408.0000 - val_loss: 1653404288.0000\n",
      "Epoch 1137/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 463422112.0000 - val_loss: 1786156288.0000\n",
      "Epoch 1138/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 474457152.0000 - val_loss: 1590757248.0000\n",
      "Epoch 1139/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 440032096.0000 - val_loss: 1585739008.0000\n",
      "Epoch 1140/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 460685024.0000 - val_loss: 1583839232.0000\n",
      "Epoch 1141/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 448313952.0000 - val_loss: 1613373312.0000\n",
      "Epoch 1142/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 463207328.0000 - val_loss: 1572604672.0000\n",
      "Epoch 1143/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 450040864.0000 - val_loss: 1614200448.0000\n",
      "Epoch 1144/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 463588064.0000 - val_loss: 1606350208.0000\n",
      "Epoch 1145/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 465576864.0000 - val_loss: 1598540544.0000\n",
      "Epoch 1146/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 437680864.0000 - val_loss: 1641106560.0000\n",
      "Epoch 1147/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 443931200.0000 - val_loss: 1580515712.0000\n",
      "Epoch 1148/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 457508288.0000 - val_loss: 1572552832.0000\n",
      "Epoch 1149/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 449266880.0000 - val_loss: 1551593600.0000\n",
      "Epoch 1150/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 446468704.0000 - val_loss: 1598771712.0000\n",
      "Epoch 1151/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 443758944.0000 - val_loss: 1561020160.0000\n",
      "Epoch 1152/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 448868224.0000 - val_loss: 1592280704.0000\n",
      "Epoch 1153/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 453785920.0000 - val_loss: 1565511040.0000\n",
      "Epoch 1154/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 443139872.0000 - val_loss: 1618909824.0000\n",
      "Epoch 1155/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 453225344.0000 - val_loss: 1683952128.0000\n",
      "Epoch 1156/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 452387200.0000 - val_loss: 1610572032.0000\n",
      "Epoch 1157/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 450795200.0000 - val_loss: 1572209792.0000\n",
      "Epoch 1158/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 439350176.0000 - val_loss: 1698926464.0000\n",
      "Epoch 1159/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 451014624.0000 - val_loss: 1550772352.0000\n",
      "Epoch 1160/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 455919008.0000 - val_loss: 1566345472.0000\n",
      "Epoch 1161/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 432425984.0000 - val_loss: 1656738176.0000\n",
      "Epoch 1162/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 477588704.0000 - val_loss: 1662260224.0000\n",
      "Epoch 1163/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 453758336.0000 - val_loss: 1567533568.0000\n",
      "Epoch 1164/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 434057952.0000 - val_loss: 1565159168.0000\n",
      "Epoch 1165/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 450477632.0000 - val_loss: 1536831872.0000\n",
      "Epoch 1166/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 479017920.0000 - val_loss: 1568428416.0000\n",
      "Epoch 1167/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 435525824.0000 - val_loss: 1585607936.0000\n",
      "Epoch 1168/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 459314112.0000 - val_loss: 1570071936.0000\n",
      "Epoch 1169/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 439284384.0000 - val_loss: 1533291008.0000\n",
      "Epoch 1170/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 442119488.0000 - val_loss: 1568779776.0000\n",
      "Epoch 1171/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 449906784.0000 - val_loss: 1577454208.0000\n",
      "Epoch 1172/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 444969728.0000 - val_loss: 1570578176.0000\n",
      "Epoch 1173/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 437902624.0000 - val_loss: 1564936960.0000\n",
      "Epoch 1174/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 447550400.0000 - val_loss: 1557782016.0000\n",
      "Epoch 1175/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 436921600.0000 - val_loss: 1570577536.0000\n",
      "Epoch 1176/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 437163328.0000 - val_loss: 1571451136.0000\n",
      "Epoch 1177/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 437689152.0000 - val_loss: 1561620864.0000\n",
      "Epoch 1178/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 430308704.0000 - val_loss: 1551845760.0000\n",
      "Epoch 1179/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 428258176.0000 - val_loss: 1645581824.0000\n",
      "Epoch 1180/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 427780000.0000 - val_loss: 1565950592.0000\n",
      "Epoch 1181/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 445520544.0000 - val_loss: 1542599936.0000\n",
      "Epoch 1182/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 431080320.0000 - val_loss: 1600060928.0000\n",
      "Epoch 1183/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 446306976.0000 - val_loss: 1553539328.0000\n",
      "Epoch 1184/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 439563360.0000 - val_loss: 1656103424.0000\n",
      "Epoch 1185/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 435020320.0000 - val_loss: 1611804800.0000\n",
      "Epoch 1186/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 428317600.0000 - val_loss: 1602516224.0000\n",
      "Epoch 1187/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 448041376.0000 - val_loss: 1537863680.0000\n",
      "Epoch 1188/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 432716832.0000 - val_loss: 1601985536.0000\n",
      "Epoch 1189/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 434183840.0000 - val_loss: 1581450880.0000\n",
      "Epoch 1190/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 438694144.0000 - val_loss: 1548170880.0000\n",
      "Epoch 1191/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 427891040.0000 - val_loss: 1576119296.0000\n",
      "Epoch 1192/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 441006944.0000 - val_loss: 1537496448.0000\n",
      "Epoch 1193/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 430328352.0000 - val_loss: 1527705216.0000\n",
      "Epoch 1194/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 417909376.0000 - val_loss: 1547476352.0000\n",
      "Epoch 1195/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 442724928.0000 - val_loss: 1537043456.0000\n",
      "Epoch 1196/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 423241568.0000 - val_loss: 1560481536.0000\n",
      "Epoch 1197/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 443768384.0000 - val_loss: 1592127360.0000\n",
      "Epoch 1198/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 452191648.0000 - val_loss: 1569618304.0000\n",
      "Epoch 1199/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 433051488.0000 - val_loss: 1534789248.0000\n",
      "Epoch 1200/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 456132352.0000 - val_loss: 1580195456.0000\n",
      "Epoch 1201/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 442550016.0000 - val_loss: 1550392448.0000\n",
      "Epoch 1202/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 435920672.0000 - val_loss: 1540311680.0000\n",
      "Epoch 1203/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 425598496.0000 - val_loss: 1621970816.0000\n",
      "Epoch 1204/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 453368096.0000 - val_loss: 1614771200.0000\n",
      "Epoch 1205/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 446960736.0000 - val_loss: 1552489472.0000\n",
      "Epoch 1206/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 433888608.0000 - val_loss: 1542568832.0000\n",
      "Epoch 1207/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 435836800.0000 - val_loss: 1623737728.0000\n",
      "Epoch 1208/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 445098656.0000 - val_loss: 1555874176.0000\n",
      "Epoch 1209/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 420549824.0000 - val_loss: 1803664256.0000\n",
      "Epoch 1210/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 455760608.0000 - val_loss: 1557765248.0000\n",
      "Epoch 1211/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 425939936.0000 - val_loss: 1559119872.0000\n",
      "Epoch 1212/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 425537856.0000 - val_loss: 1636730880.0000\n",
      "Epoch 1213/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 438982208.0000 - val_loss: 1624486400.0000\n",
      "Epoch 1214/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 418528192.0000 - val_loss: 1533090816.0000\n",
      "Epoch 1215/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 429614016.0000 - val_loss: 1560762496.0000\n",
      "Epoch 1216/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 424768544.0000 - val_loss: 1563456256.0000\n",
      "Epoch 1217/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 414440224.0000 - val_loss: 1566800640.0000\n",
      "Epoch 1218/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 414845536.0000 - val_loss: 1587320192.0000\n",
      "Epoch 1219/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 431140896.0000 - val_loss: 1557625600.0000\n",
      "Epoch 1220/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 428484576.0000 - val_loss: 1577320960.0000\n",
      "Epoch 1221/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 428432160.0000 - val_loss: 1617071872.0000\n",
      "Epoch 1222/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 450948576.0000 - val_loss: 1636731904.0000\n",
      "Epoch 1223/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 411481344.0000 - val_loss: 1555494400.0000\n",
      "Epoch 1224/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 438149760.0000 - val_loss: 1568991616.0000\n",
      "Epoch 1225/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 434837632.0000 - val_loss: 1568384896.0000\n",
      "Epoch 1226/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 418474464.0000 - val_loss: 1564146048.0000\n",
      "Epoch 1227/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 429421728.0000 - val_loss: 1544523008.0000\n",
      "Epoch 1228/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 424575328.0000 - val_loss: 1565967744.0000\n",
      "Epoch 1229/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 439893280.0000 - val_loss: 1545008896.0000\n",
      "Epoch 1230/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 410797600.0000 - val_loss: 1544846848.0000\n",
      "Epoch 1231/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 423606336.0000 - val_loss: 1565713792.0000\n",
      "Epoch 1232/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 418545056.0000 - val_loss: 1581779200.0000\n",
      "Epoch 1233/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 419018080.0000 - val_loss: 1521932032.0000\n",
      "Epoch 1234/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 411855200.0000 - val_loss: 1566909184.0000\n",
      "Epoch 1235/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 429763584.0000 - val_loss: 1564700544.0000\n",
      "Epoch 1236/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 406359584.0000 - val_loss: 1581488896.0000\n",
      "Epoch 1237/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 424121088.0000 - val_loss: 1576675456.0000\n",
      "Epoch 1238/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 431905760.0000 - val_loss: 1540640384.0000\n",
      "Epoch 1239/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 428258080.0000 - val_loss: 1615371520.0000\n",
      "Epoch 1240/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 414410464.0000 - val_loss: 1544187392.0000\n",
      "Epoch 1241/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 409528832.0000 - val_loss: 1563624704.0000\n",
      "Epoch 1242/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 407911584.0000 - val_loss: 1581882880.0000\n",
      "Epoch 1243/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 409717664.0000 - val_loss: 1514895616.0000\n",
      "Epoch 1244/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 475889152.0000 - val_loss: 1548680832.0000\n",
      "Epoch 1245/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 420570560.0000 - val_loss: 1523556608.0000\n",
      "Epoch 1246/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 416413888.0000 - val_loss: 1534975232.0000\n",
      "Epoch 1247/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 426238880.0000 - val_loss: 1748903808.0000\n",
      "Epoch 1248/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 431884672.0000 - val_loss: 1600121344.0000\n",
      "Epoch 1249/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 418696480.0000 - val_loss: 1534998528.0000\n",
      "Epoch 1250/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 409177952.0000 - val_loss: 1636773504.0000\n",
      "Epoch 1251/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 412049728.0000 - val_loss: 1531744128.0000\n",
      "Epoch 1252/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 404351840.0000 - val_loss: 1533118592.0000\n",
      "Epoch 1253/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 406167968.0000 - val_loss: 1602420736.0000\n",
      "Epoch 1254/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 411305824.0000 - val_loss: 1562799488.0000\n",
      "Epoch 1255/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 408808480.0000 - val_loss: 1526116480.0000\n",
      "Epoch 1256/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 416876384.0000 - val_loss: 1499058304.0000\n",
      "Epoch 1257/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 410703392.0000 - val_loss: 1532264960.0000\n",
      "Epoch 1258/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 398760256.0000 - val_loss: 1514398848.0000\n",
      "Epoch 1259/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 423153376.0000 - val_loss: 1512150656.0000\n",
      "Epoch 1260/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 429272064.0000 - val_loss: 1588263936.0000\n",
      "Epoch 1261/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 406858624.0000 - val_loss: 1505907456.0000\n",
      "Epoch 1262/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 403306944.0000 - val_loss: 1551912448.0000\n",
      "Epoch 1263/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 428906880.0000 - val_loss: 1538249728.0000\n",
      "Epoch 1264/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 426561408.0000 - val_loss: 1512969088.0000\n",
      "Epoch 1265/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 404120352.0000 - val_loss: 1499592960.0000\n",
      "Epoch 1266/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 400712608.0000 - val_loss: 1650731008.0000\n",
      "Epoch 1267/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 397613888.0000 - val_loss: 1534056448.0000\n",
      "Epoch 1268/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 417040224.0000 - val_loss: 1509683072.0000\n",
      "Epoch 1269/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 426587904.0000 - val_loss: 1575791360.0000\n",
      "Epoch 1270/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 436005728.0000 - val_loss: 1525505152.0000\n",
      "Epoch 1271/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 404159552.0000 - val_loss: 1608626560.0000\n",
      "Epoch 1272/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 428012512.0000 - val_loss: 1583595392.0000\n",
      "Epoch 1273/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 395358592.0000 - val_loss: 1520310400.0000\n",
      "Epoch 1274/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 447540544.0000 - val_loss: 1518466304.0000\n",
      "Epoch 1275/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 411326880.0000 - val_loss: 1506038272.0000\n",
      "Epoch 1276/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 428111616.0000 - val_loss: 1578228352.0000\n",
      "Epoch 1277/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 435699680.0000 - val_loss: 1553297024.0000\n",
      "Epoch 1278/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 397815264.0000 - val_loss: 1527799552.0000\n",
      "Epoch 1279/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 2ms/step - loss: 408678752.0000 - val_loss: 1610427776.0000\n",
      "Epoch 1280/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 407071200.0000 - val_loss: 1520996608.0000\n",
      "Epoch 1281/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 399266688.0000 - val_loss: 1531533440.0000\n",
      "Epoch 1282/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 406564704.0000 - val_loss: 1726480128.0000\n",
      "Epoch 1283/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 405274464.0000 - val_loss: 1518502784.0000\n",
      "Epoch 1284/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 420316928.0000 - val_loss: 1548858496.0000\n",
      "Epoch 1285/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 403047936.0000 - val_loss: 1592254464.0000\n",
      "Epoch 1286/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 411258272.0000 - val_loss: 1512269184.0000\n",
      "Epoch 1287/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 407051648.0000 - val_loss: 1539948800.0000\n",
      "Epoch 1288/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 397241440.0000 - val_loss: 1547085312.0000\n",
      "Epoch 1289/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 398909824.0000 - val_loss: 1506253568.0000\n",
      "Epoch 1290/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 415767008.0000 - val_loss: 1550103040.0000\n",
      "Epoch 1291/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 398886400.0000 - val_loss: 1597867520.0000\n",
      "Epoch 1292/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 406832288.0000 - val_loss: 1521987072.0000\n",
      "Epoch 1293/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 428940608.0000 - val_loss: 1548693376.0000\n",
      "Epoch 1294/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 394825600.0000 - val_loss: 1531421824.0000\n",
      "Epoch 1295/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 410814592.0000 - val_loss: 1541992832.0000\n",
      "Epoch 1296/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 398964928.0000 - val_loss: 1562500736.0000\n",
      "Epoch 1297/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 395385952.0000 - val_loss: 1498371584.0000\n",
      "Epoch 1298/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 386416928.0000 - val_loss: 1522017408.0000\n",
      "Epoch 1299/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 410859904.0000 - val_loss: 1513791616.0000\n",
      "Epoch 1300/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 391316800.0000 - val_loss: 1536341248.0000\n",
      "Epoch 1301/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 392581376.0000 - val_loss: 1497954176.0000\n",
      "Epoch 1302/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 403296960.0000 - val_loss: 1491767936.0000\n",
      "Epoch 1303/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 405641312.0000 - val_loss: 1511213568.0000\n",
      "Epoch 1304/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 397161984.0000 - val_loss: 1546017408.0000\n",
      "Epoch 1305/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 403722624.0000 - val_loss: 1514148480.0000\n",
      "Epoch 1306/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 418203424.0000 - val_loss: 1492022400.0000\n",
      "Epoch 1307/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 417519072.0000 - val_loss: 1506715776.0000\n",
      "Epoch 1308/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 379634208.0000 - val_loss: 1545143296.0000\n",
      "Epoch 1309/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 395993504.0000 - val_loss: 1626572288.0000\n",
      "Epoch 1310/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 434265472.0000 - val_loss: 1571896832.0000\n",
      "Epoch 1311/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 407034080.0000 - val_loss: 1522755072.0000\n",
      "Epoch 1312/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 394814144.0000 - val_loss: 1514599552.0000\n",
      "Epoch 1313/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 390305632.0000 - val_loss: 1543345664.0000\n",
      "Epoch 1314/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 389072832.0000 - val_loss: 1508292608.0000\n",
      "Epoch 1315/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 394321920.0000 - val_loss: 1507098368.0000\n",
      "Epoch 1316/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 385620800.0000 - val_loss: 1516657536.0000\n",
      "Epoch 1317/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 394168320.0000 - val_loss: 1652877184.0000\n",
      "Epoch 1318/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 396338208.0000 - val_loss: 1514394880.0000\n",
      "Epoch 1319/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 400671296.0000 - val_loss: 1568051072.0000\n",
      "Epoch 1320/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 397854400.0000 - val_loss: 1554329728.0000\n",
      "Epoch 1321/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 388206752.0000 - val_loss: 1521083392.0000\n",
      "Epoch 1322/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 387053760.0000 - val_loss: 1541271936.0000\n",
      "Epoch 1323/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 401889248.0000 - val_loss: 1525280768.0000\n",
      "Epoch 1324/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 380806848.0000 - val_loss: 1495753600.0000\n",
      "Epoch 1325/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 399262080.0000 - val_loss: 1547224320.0000\n",
      "Epoch 1326/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 404296672.0000 - val_loss: 1481855232.0000\n",
      "Epoch 1327/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 399200960.0000 - val_loss: 1632295552.0000\n",
      "Epoch 1328/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 399580320.0000 - val_loss: 1571691648.0000\n",
      "Epoch 1329/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 403008000.0000 - val_loss: 1529173504.0000\n",
      "Epoch 1330/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 369661920.0000 - val_loss: 1626568192.0000\n",
      "Epoch 1331/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 385529280.0000 - val_loss: 1529373952.0000\n",
      "Epoch 1332/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 385072672.0000 - val_loss: 1529066624.0000\n",
      "Epoch 1333/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 376736128.0000 - val_loss: 1506196224.0000\n",
      "Epoch 1334/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 382967136.0000 - val_loss: 1521114368.0000\n",
      "Epoch 1335/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 387544000.0000 - val_loss: 1486144768.0000\n",
      "Epoch 1336/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 390612192.0000 - val_loss: 1505051392.0000\n",
      "Epoch 1337/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 388027520.0000 - val_loss: 1556862848.0000\n",
      "Epoch 1338/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 378321792.0000 - val_loss: 1603289088.0000\n",
      "Epoch 1339/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 401349504.0000 - val_loss: 1553453056.0000\n",
      "Epoch 1340/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 385617760.0000 - val_loss: 1503795712.0000\n",
      "Epoch 1341/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 396266752.0000 - val_loss: 1520401024.0000\n",
      "Epoch 1342/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 379648864.0000 - val_loss: 1528243328.0000\n",
      "Epoch 1343/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 381062720.0000 - val_loss: 1503914880.0000\n",
      "Epoch 1344/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 385011424.0000 - val_loss: 1538416640.0000\n",
      "Epoch 1345/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 388734496.0000 - val_loss: 1553417472.0000\n",
      "Epoch 1346/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 378821152.0000 - val_loss: 1609143040.0000\n",
      "Epoch 1347/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 386107424.0000 - val_loss: 1534634368.0000\n",
      "Epoch 1348/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 411644800.0000 - val_loss: 1519707520.0000\n",
      "Epoch 1349/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 388133312.0000 - val_loss: 1507684992.0000\n",
      "Epoch 1350/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 375154336.0000 - val_loss: 1644187904.0000\n",
      "Epoch 1351/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 403795648.0000 - val_loss: 1544915968.0000\n",
      "Epoch 1352/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 374037952.0000 - val_loss: 1582103936.0000\n",
      "Epoch 1353/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 383039680.0000 - val_loss: 1532952064.0000\n",
      "Epoch 1354/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 388652768.0000 - val_loss: 1584537856.0000\n",
      "Epoch 1355/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 371884576.0000 - val_loss: 1512327168.0000\n",
      "Epoch 1356/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 387112544.0000 - val_loss: 1528878592.0000\n",
      "Epoch 1357/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 374920000.0000 - val_loss: 1492946816.0000\n",
      "Epoch 1358/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 371236672.0000 - val_loss: 1493386368.0000\n",
      "Epoch 1359/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 387004736.0000 - val_loss: 1506836992.0000\n",
      "Epoch 1360/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 377950112.0000 - val_loss: 1478870016.0000\n",
      "Epoch 1361/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 379092672.0000 - val_loss: 1584796032.0000\n",
      "Epoch 1362/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 373757408.0000 - val_loss: 1495352320.0000\n",
      "Epoch 1363/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 378583648.0000 - val_loss: 1512670848.0000\n",
      "Epoch 1364/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 405122912.0000 - val_loss: 1512580352.0000\n",
      "Epoch 1365/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 374998528.0000 - val_loss: 1498953088.0000\n",
      "Epoch 1366/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 380176928.0000 - val_loss: 1576520448.0000\n",
      "Epoch 1367/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 419847008.0000 - val_loss: 1541330816.0000\n",
      "Epoch 1368/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 374937408.0000 - val_loss: 1506932096.0000\n",
      "Epoch 1369/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 364801216.0000 - val_loss: 1522157952.0000\n",
      "Epoch 1370/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 359852160.0000 - val_loss: 1485904896.0000\n",
      "Epoch 1371/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 380612928.0000 - val_loss: 1488835328.0000\n",
      "Epoch 1372/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 366501824.0000 - val_loss: 1513584896.0000\n",
      "Epoch 1373/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 368009376.0000 - val_loss: 1553836032.0000\n",
      "Epoch 1374/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 382780832.0000 - val_loss: 1530634496.0000\n",
      "Epoch 1375/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 386725760.0000 - val_loss: 1518721536.0000\n",
      "Epoch 1376/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 388229888.0000 - val_loss: 1556700032.0000\n",
      "Epoch 1377/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 375896832.0000 - val_loss: 1562496768.0000\n",
      "Epoch 1378/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 374555392.0000 - val_loss: 1522883584.0000\n",
      "Epoch 1379/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 361179488.0000 - val_loss: 1533220992.0000\n",
      "Epoch 1380/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 377225984.0000 - val_loss: 1517480320.0000\n",
      "Epoch 1381/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 394094560.0000 - val_loss: 1507025536.0000\n",
      "Epoch 1382/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 407183680.0000 - val_loss: 1515153536.0000\n",
      "Epoch 1383/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 367457152.0000 - val_loss: 1620123904.0000\n",
      "Epoch 1384/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 371648544.0000 - val_loss: 1571307520.0000\n",
      "Epoch 1385/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 398056768.0000 - val_loss: 1556470912.0000\n",
      "Epoch 1386/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 374473760.0000 - val_loss: 1548396928.0000\n",
      "Epoch 1387/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 392750304.0000 - val_loss: 1513483008.0000\n",
      "Epoch 1388/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 376301280.0000 - val_loss: 1515185152.0000\n",
      "Epoch 1389/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 379536800.0000 - val_loss: 1571661568.0000\n",
      "Epoch 1390/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 373090880.0000 - val_loss: 1535863680.0000\n",
      "Epoch 1391/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 381889280.0000 - val_loss: 1497256320.0000\n",
      "Epoch 1392/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 380854912.0000 - val_loss: 1518754688.0000\n",
      "Epoch 1393/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 363764480.0000 - val_loss: 1583906304.0000\n",
      "Epoch 1394/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 378316096.0000 - val_loss: 1549517696.0000\n",
      "Epoch 1395/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 384989920.0000 - val_loss: 1581403648.0000\n",
      "Epoch 1396/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 382587776.0000 - val_loss: 1498889216.0000\n",
      "Epoch 1397/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 372731712.0000 - val_loss: 1557421696.0000\n",
      "Epoch 1398/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 363735392.0000 - val_loss: 1530693504.0000\n",
      "Epoch 1399/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 387743552.0000 - val_loss: 1513160960.0000\n",
      "Epoch 1400/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 369692096.0000 - val_loss: 1514609792.0000\n",
      "Epoch 1401/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 354970176.0000 - val_loss: 1552945280.0000\n",
      "Epoch 1402/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 365702176.0000 - val_loss: 1490865536.0000\n",
      "Epoch 1403/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 377723776.0000 - val_loss: 1517780224.0000\n",
      "Epoch 1404/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 382795680.0000 - val_loss: 1491479296.0000\n",
      "Epoch 1405/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 366661024.0000 - val_loss: 1514235392.0000\n",
      "Epoch 1406/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 373518528.0000 - val_loss: 1534723456.0000\n",
      "Epoch 1407/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 381678624.0000 - val_loss: 1547730944.0000\n",
      "Epoch 1408/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 386066464.0000 - val_loss: 1587067520.0000\n",
      "Epoch 1409/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 395491008.0000 - val_loss: 1511282304.0000\n",
      "Epoch 1410/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 355723904.0000 - val_loss: 1481070336.0000\n",
      "Epoch 1411/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 369206240.0000 - val_loss: 1588812032.0000\n",
      "Epoch 1412/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 376030976.0000 - val_loss: 1522356992.0000\n",
      "Epoch 1413/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 358424928.0000 - val_loss: 1533804032.0000\n",
      "Epoch 1414/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 395848704.0000 - val_loss: 1500005760.0000\n",
      "Epoch 1415/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 355712736.0000 - val_loss: 1508238848.0000\n",
      "Epoch 1416/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 380971936.0000 - val_loss: 1564746752.0000\n",
      "Epoch 1417/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 353742784.0000 - val_loss: 1518102400.0000\n",
      "Epoch 1418/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 378803520.0000 - val_loss: 1492777216.0000\n",
      "Epoch 1419/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 367788608.0000 - val_loss: 1588781824.0000\n",
      "Epoch 1420/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 365573760.0000 - val_loss: 1559480448.0000\n",
      "Epoch 1421/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 383939040.0000 - val_loss: 1494480000.0000\n",
      "Epoch 1422/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 361974432.0000 - val_loss: 1499661568.0000\n",
      "Epoch 1423/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 375329376.0000 - val_loss: 1480953728.0000\n",
      "Epoch 1424/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 362458400.0000 - val_loss: 1545527040.0000\n",
      "Epoch 1425/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 392275488.0000 - val_loss: 1516510848.0000\n",
      "Epoch 1426/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 380522112.0000 - val_loss: 1492611200.0000\n",
      "Epoch 1427/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 357483456.0000 - val_loss: 1523762176.0000\n",
      "Epoch 1428/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 381519360.0000 - val_loss: 1501141760.0000\n",
      "Epoch 1429/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 363311424.0000 - val_loss: 1490769792.0000\n",
      "Epoch 1430/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 375157568.0000 - val_loss: 1508760320.0000\n",
      "Epoch 1431/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 377869088.0000 - val_loss: 1502810624.0000\n",
      "Epoch 1432/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 364979520.0000 - val_loss: 1584784896.0000\n",
      "Epoch 1433/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 361763520.0000 - val_loss: 1550530816.0000\n",
      "Epoch 1434/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 359424128.0000 - val_loss: 1530425216.0000\n",
      "Epoch 1435/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 355094784.0000 - val_loss: 1525816448.0000\n",
      "Epoch 1436/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 360097824.0000 - val_loss: 1490249600.0000\n",
      "Epoch 1437/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 362837600.0000 - val_loss: 1480753024.0000\n",
      "Epoch 1438/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 367520256.0000 - val_loss: 1630242944.0000\n",
      "Epoch 1439/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 360965728.0000 - val_loss: 1537398016.0000\n",
      "Epoch 1440/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 367439776.0000 - val_loss: 1494395136.0000\n",
      "Epoch 1441/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 362648768.0000 - val_loss: 1648231936.0000\n",
      "Epoch 1442/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 370857056.0000 - val_loss: 1637090944.0000\n",
      "Epoch 1443/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 371791264.0000 - val_loss: 1489861760.0000\n",
      "Epoch 1444/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 367604704.0000 - val_loss: 1502797312.0000\n",
      "Epoch 1445/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 357805280.0000 - val_loss: 1488398848.0000\n",
      "Epoch 1446/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 359468576.0000 - val_loss: 1514831360.0000\n",
      "Epoch 1447/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 366972480.0000 - val_loss: 1524500224.0000\n",
      "Epoch 1448/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 367149920.0000 - val_loss: 1546880640.0000\n",
      "Epoch 1449/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 357454208.0000 - val_loss: 1518488320.0000\n",
      "Epoch 1450/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 379951936.0000 - val_loss: 1539375616.0000\n",
      "Epoch 1451/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 374237056.0000 - val_loss: 1527962880.0000\n",
      "Epoch 1452/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 349665024.0000 - val_loss: 1503537664.0000\n",
      "Epoch 1453/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 362010016.0000 - val_loss: 1516439168.0000\n",
      "Epoch 1454/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 383251872.0000 - val_loss: 1720786432.0000\n",
      "Epoch 1455/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 359842400.0000 - val_loss: 1499399040.0000\n",
      "Epoch 1456/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 370067456.0000 - val_loss: 1485847424.0000\n",
      "Epoch 1457/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 356144224.0000 - val_loss: 1506768512.0000\n",
      "Epoch 1458/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 351823968.0000 - val_loss: 1602393088.0000\n",
      "Epoch 1459/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 349384352.0000 - val_loss: 1522179072.0000\n",
      "Epoch 1460/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 359992928.0000 - val_loss: 1497892992.0000\n",
      "Epoch 1461/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 380108992.0000 - val_loss: 1497329536.0000\n",
      "Epoch 1462/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 365773248.0000 - val_loss: 1516401280.0000\n",
      "Epoch 1463/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 381298176.0000 - val_loss: 1494776448.0000\n",
      "Epoch 1464/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 358541632.0000 - val_loss: 1545413760.0000\n",
      "Epoch 1465/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 373860992.0000 - val_loss: 1623241728.0000\n",
      "Epoch 1466/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 354673344.0000 - val_loss: 1528028928.0000\n",
      "Epoch 1467/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 356203232.0000 - val_loss: 1521396224.0000\n",
      "Epoch 1468/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 343815808.0000 - val_loss: 1487075712.0000\n",
      "Epoch 1469/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 383420736.0000 - val_loss: 1625799424.0000\n",
      "Epoch 1470/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 369002368.0000 - val_loss: 1495543168.0000\n",
      "Epoch 1471/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 343809216.0000 - val_loss: 1585882880.0000\n",
      "Epoch 1472/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 353066176.0000 - val_loss: 1482932096.0000\n",
      "Epoch 1473/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 359404576.0000 - val_loss: 1504690432.0000\n",
      "Epoch 1474/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 363775776.0000 - val_loss: 1501665408.0000\n",
      "Epoch 1475/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 354925440.0000 - val_loss: 1739418880.0000\n",
      "Epoch 1476/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 369389952.0000 - val_loss: 1505568896.0000\n",
      "Epoch 1477/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 361215744.0000 - val_loss: 1497166464.0000\n",
      "Epoch 1478/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 365093760.0000 - val_loss: 1491877504.0000\n",
      "Epoch 1479/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 343972224.0000 - val_loss: 1486568960.0000\n",
      "Epoch 1480/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 350815744.0000 - val_loss: 1474978560.0000\n",
      "Epoch 1481/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 356531168.0000 - val_loss: 1456828800.0000\n",
      "Epoch 1482/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 349453568.0000 - val_loss: 1588606848.0000\n",
      "Epoch 1483/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 372212736.0000 - val_loss: 1473342464.0000\n",
      "Epoch 1484/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 348956384.0000 - val_loss: 1506364544.0000\n",
      "Epoch 1485/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 345230976.0000 - val_loss: 1460046336.0000\n",
      "Epoch 1486/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 346379456.0000 - val_loss: 1506068224.0000\n",
      "Epoch 1487/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 358515680.0000 - val_loss: 1566744192.0000\n",
      "Epoch 1488/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 367472608.0000 - val_loss: 1464762112.0000\n",
      "Epoch 1489/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 344988928.0000 - val_loss: 1464979584.0000\n",
      "Epoch 1490/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 357422208.0000 - val_loss: 1473330048.0000\n",
      "Epoch 1491/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 349784736.0000 - val_loss: 1540666752.0000\n",
      "Epoch 1492/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 358771168.0000 - val_loss: 1479405440.0000\n",
      "Epoch 1493/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 365733536.0000 - val_loss: 1469601280.0000\n",
      "Epoch 1494/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 339780992.0000 - val_loss: 1518708480.0000\n",
      "Epoch 1495/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 340269664.0000 - val_loss: 1489474176.0000\n",
      "Epoch 1496/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 354786624.0000 - val_loss: 1530446720.0000\n",
      "Epoch 1497/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 338924544.0000 - val_loss: 1530496640.0000\n",
      "Epoch 1498/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 349529440.0000 - val_loss: 1504174976.0000\n",
      "Epoch 1499/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 381467520.0000 - val_loss: 1504837888.0000\n",
      "Epoch 1500/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 344914240.0000 - val_loss: 1511204096.0000\n",
      "Epoch 1501/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 349854912.0000 - val_loss: 1485773056.0000\n",
      "Epoch 1502/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 352657184.0000 - val_loss: 1493013248.0000\n",
      "Epoch 1503/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 341536352.0000 - val_loss: 1541325952.0000\n",
      "Epoch 1504/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 370411808.0000 - val_loss: 1654135808.0000\n",
      "Epoch 1505/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 351715712.0000 - val_loss: 1514124160.0000\n",
      "Epoch 1506/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 345865472.0000 - val_loss: 1515916544.0000\n",
      "Epoch 1507/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 347910528.0000 - val_loss: 1502338048.0000\n",
      "Epoch 1508/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 344204032.0000 - val_loss: 1486370816.0000\n",
      "Epoch 1509/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 362751232.0000 - val_loss: 1510182656.0000\n",
      "Epoch 1510/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 348166816.0000 - val_loss: 1496529280.0000\n",
      "Epoch 1511/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 353723744.0000 - val_loss: 1490352512.0000\n",
      "Epoch 1512/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 343374336.0000 - val_loss: 1494171648.0000\n",
      "Epoch 1513/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 335625952.0000 - val_loss: 1483982720.0000\n",
      "Epoch 1514/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 357500768.0000 - val_loss: 1487595904.0000\n",
      "Epoch 1515/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 354901600.0000 - val_loss: 1477716480.0000\n",
      "Epoch 1516/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 344541120.0000 - val_loss: 1490210048.0000\n",
      "Epoch 1517/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 339429952.0000 - val_loss: 1497435264.0000\n",
      "Epoch 1518/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 381021888.0000 - val_loss: 1560655872.0000\n",
      "Epoch 1519/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 346596544.0000 - val_loss: 1497875840.0000\n",
      "Epoch 1520/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 361938464.0000 - val_loss: 1529404928.0000\n",
      "Epoch 1521/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 334381216.0000 - val_loss: 1494450304.0000\n",
      "Epoch 1522/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 336208992.0000 - val_loss: 1662080256.0000\n",
      "Epoch 1523/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 348093248.0000 - val_loss: 1545681536.0000\n",
      "Epoch 1524/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 336533440.0000 - val_loss: 1513816832.0000\n",
      "Epoch 1525/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 337083840.0000 - val_loss: 1496793216.0000\n",
      "Epoch 1526/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 363300992.0000 - val_loss: 1478602624.0000\n",
      "Epoch 1527/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 354706336.0000 - val_loss: 1479236352.0000\n",
      "Epoch 1528/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 349392128.0000 - val_loss: 1486413440.0000\n",
      "Epoch 1529/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 335943872.0000 - val_loss: 1476101760.0000\n",
      "Epoch 1530/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 340495616.0000 - val_loss: 1518319360.0000\n",
      "Epoch 1531/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 337927232.0000 - val_loss: 1500920704.0000\n",
      "Epoch 1532/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 348027712.0000 - val_loss: 1467180928.0000\n",
      "Epoch 1533/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 346276768.0000 - val_loss: 1465225088.0000\n",
      "Epoch 1534/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 333673696.0000 - val_loss: 1577325312.0000\n",
      "Epoch 1535/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 343649568.0000 - val_loss: 1486819456.0000\n",
      "Epoch 1536/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 338084544.0000 - val_loss: 1626189568.0000\n",
      "Epoch 1537/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 352702176.0000 - val_loss: 1493839232.0000\n",
      "Epoch 1538/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 344903232.0000 - val_loss: 1503368704.0000\n",
      "Epoch 1539/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 325150688.0000 - val_loss: 1462148864.0000\n",
      "Epoch 1540/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 337310432.0000 - val_loss: 1492838400.0000\n",
      "Epoch 1541/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 352821600.0000 - val_loss: 1539373440.0000\n",
      "Epoch 1542/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 359217696.0000 - val_loss: 1495640192.0000\n",
      "Epoch 1543/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 332183328.0000 - val_loss: 1468592128.0000\n",
      "Epoch 1544/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 348849408.0000 - val_loss: 1507416192.0000\n",
      "Epoch 1545/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 341465984.0000 - val_loss: 1467960576.0000\n",
      "Epoch 1546/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 338649024.0000 - val_loss: 1746751872.0000\n",
      "Epoch 1547/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 339665888.0000 - val_loss: 1500036480.0000\n",
      "Epoch 1548/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 336194208.0000 - val_loss: 1478525184.0000\n",
      "Epoch 1549/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 333208928.0000 - val_loss: 1455668992.0000\n",
      "Epoch 1550/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 328562624.0000 - val_loss: 1460138240.0000\n",
      "Epoch 1551/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 330902016.0000 - val_loss: 1472937856.0000\n",
      "Epoch 1552/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 350970560.0000 - val_loss: 1502292224.0000\n",
      "Epoch 1553/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 354520224.0000 - val_loss: 1470537856.0000\n",
      "Epoch 1554/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 319708832.0000 - val_loss: 1494722048.0000\n",
      "Epoch 1555/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 346257216.0000 - val_loss: 1500587264.0000\n",
      "Epoch 1556/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 346051136.0000 - val_loss: 1489122816.0000\n",
      "Epoch 1557/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 335592896.0000 - val_loss: 1559511936.0000\n",
      "Epoch 1558/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 352146816.0000 - val_loss: 1468366464.0000\n",
      "Epoch 1559/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 320848192.0000 - val_loss: 1504080000.0000\n",
      "Epoch 1560/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 329969504.0000 - val_loss: 1482580864.0000\n",
      "Epoch 1561/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 351355232.0000 - val_loss: 1492326144.0000\n",
      "Epoch 1562/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 327663616.0000 - val_loss: 1493596928.0000\n",
      "Epoch 1563/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 348348064.0000 - val_loss: 1517455872.0000\n",
      "Epoch 1564/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 331552544.0000 - val_loss: 1525528320.0000\n",
      "Epoch 1565/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 357101664.0000 - val_loss: 1495718016.0000\n",
      "Epoch 1566/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 341003968.0000 - val_loss: 1466312448.0000\n",
      "Epoch 1567/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 333810880.0000 - val_loss: 1507812224.0000\n",
      "Epoch 1568/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 345172000.0000 - val_loss: 1491812096.0000\n",
      "Epoch 1569/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 339801344.0000 - val_loss: 1500134528.0000\n",
      "Epoch 1570/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 349937952.0000 - val_loss: 1486304000.0000\n",
      "Epoch 1571/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 337333344.0000 - val_loss: 1477329664.0000\n",
      "Epoch 1572/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 332034464.0000 - val_loss: 1479609088.0000\n",
      "Epoch 1573/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 334194048.0000 - val_loss: 1471500032.0000\n",
      "Epoch 1574/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 344029376.0000 - val_loss: 1505258112.0000\n",
      "Epoch 1575/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 335553440.0000 - val_loss: 1466978048.0000\n",
      "Epoch 1576/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 326767776.0000 - val_loss: 1464250112.0000\n",
      "Epoch 1577/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 343072384.0000 - val_loss: 1485251712.0000\n",
      "Epoch 1578/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 331559040.0000 - val_loss: 1492538368.0000\n",
      "Epoch 1579/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 356421632.0000 - val_loss: 1475742976.0000\n",
      "Epoch 1580/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 323809696.0000 - val_loss: 1513358976.0000\n",
      "Epoch 1581/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 342042816.0000 - val_loss: 1481670272.0000\n",
      "Epoch 1582/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 350324256.0000 - val_loss: 1472307072.0000\n",
      "Epoch 1583/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 335368320.0000 - val_loss: 1484207744.0000\n",
      "Epoch 1584/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 341212480.0000 - val_loss: 1470300032.0000\n",
      "Epoch 1585/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 338903520.0000 - val_loss: 1453348352.0000\n",
      "Epoch 1586/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 325393664.0000 - val_loss: 1470157568.0000\n",
      "Epoch 1587/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 346836000.0000 - val_loss: 1471334656.0000\n",
      "Epoch 1588/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 334528960.0000 - val_loss: 1522500096.0000\n",
      "Epoch 1589/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 332581536.0000 - val_loss: 1472017792.0000\n",
      "Epoch 1590/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 339077312.0000 - val_loss: 1708838016.0000\n",
      "Epoch 1591/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 347942112.0000 - val_loss: 1511736832.0000\n",
      "Epoch 1592/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 335771808.0000 - val_loss: 1473240576.0000\n",
      "Epoch 1593/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 341894912.0000 - val_loss: 1482065792.0000\n",
      "Epoch 1594/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 314647968.0000 - val_loss: 1461147648.0000\n",
      "Epoch 1595/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 333497248.0000 - val_loss: 1484097280.0000\n",
      "Epoch 1596/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 356374400.0000 - val_loss: 1472791552.0000\n",
      "Epoch 1597/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 318844416.0000 - val_loss: 1559433472.0000\n",
      "Epoch 1598/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 325548704.0000 - val_loss: 1454604928.0000\n",
      "Epoch 1599/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 328728928.0000 - val_loss: 1460410496.0000\n",
      "Epoch 1600/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 324088960.0000 - val_loss: 1479378176.0000\n",
      "Epoch 1601/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 338082976.0000 - val_loss: 1481266944.0000\n",
      "Epoch 1602/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 326618976.0000 - val_loss: 1554517632.0000\n",
      "Epoch 1603/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 321171712.0000 - val_loss: 1459720064.0000\n",
      "Epoch 1604/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 343293696.0000 - val_loss: 1498410880.0000\n",
      "Epoch 1605/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 336437984.0000 - val_loss: 1701676544.0000\n",
      "Epoch 1606/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 341294848.0000 - val_loss: 1515092352.0000\n",
      "Epoch 1607/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 328273952.0000 - val_loss: 1506001024.0000\n",
      "Epoch 1608/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 346164480.0000 - val_loss: 1578112512.0000\n",
      "Epoch 1609/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 341206880.0000 - val_loss: 1491794176.0000\n",
      "Epoch 1610/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 327238272.0000 - val_loss: 1539891328.0000\n",
      "Epoch 1611/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 356928064.0000 - val_loss: 1473963392.0000\n",
      "Epoch 1612/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 334594752.0000 - val_loss: 1474690560.0000\n",
      "Epoch 1613/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 331625856.0000 - val_loss: 1466438272.0000\n",
      "Epoch 1614/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 336602240.0000 - val_loss: 1571418752.0000\n",
      "Epoch 1615/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 334824640.0000 - val_loss: 1487869952.0000\n",
      "Epoch 1616/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 317936736.0000 - val_loss: 1486125696.0000\n",
      "Epoch 1617/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 319377088.0000 - val_loss: 1515445376.0000\n",
      "Epoch 1618/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 334977792.0000 - val_loss: 1567138304.0000\n",
      "Epoch 1619/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 334347680.0000 - val_loss: 1466630528.0000\n",
      "Epoch 1620/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 330233248.0000 - val_loss: 1477015552.0000\n",
      "Epoch 1621/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 328025376.0000 - val_loss: 1462208000.0000\n",
      "Epoch 1622/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 333614752.0000 - val_loss: 1470468864.0000\n",
      "Epoch 1623/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 322313120.0000 - val_loss: 1488881664.0000\n",
      "Epoch 1624/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 325785856.0000 - val_loss: 1505139840.0000\n",
      "Epoch 1625/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 323220480.0000 - val_loss: 1470623232.0000\n",
      "Epoch 1626/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 332927584.0000 - val_loss: 1467642880.0000\n",
      "Epoch 1627/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 334755168.0000 - val_loss: 1488134528.0000\n",
      "Epoch 1628/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 315846688.0000 - val_loss: 1472343168.0000\n",
      "Epoch 1629/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 321863232.0000 - val_loss: 1471882496.0000\n",
      "Epoch 1630/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 314088480.0000 - val_loss: 1493004032.0000\n",
      "Epoch 1631/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 328415616.0000 - val_loss: 1466679296.0000\n",
      "Epoch 1632/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 331007168.0000 - val_loss: 1483901696.0000\n",
      "Epoch 1633/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 351088832.0000 - val_loss: 1475018368.0000\n",
      "Epoch 1634/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 322625760.0000 - val_loss: 1491130496.0000\n",
      "Epoch 1635/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 353412032.0000 - val_loss: 1480278912.0000\n",
      "Epoch 1636/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 329966880.0000 - val_loss: 1476079616.0000\n",
      "Epoch 1637/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 315017088.0000 - val_loss: 1491962880.0000\n",
      "Epoch 1638/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 323374304.0000 - val_loss: 1486467968.0000\n",
      "Epoch 1639/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 326146144.0000 - val_loss: 1553541504.0000\n",
      "Epoch 1640/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 328712704.0000 - val_loss: 1521776640.0000\n",
      "Epoch 1641/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 318084864.0000 - val_loss: 1467840640.0000\n",
      "Epoch 1642/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 323100800.0000 - val_loss: 1632335488.0000\n",
      "Epoch 1643/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 328115488.0000 - val_loss: 1489158912.0000\n",
      "Epoch 1644/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 335851968.0000 - val_loss: 1487618176.0000\n",
      "Epoch 1645/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 336070112.0000 - val_loss: 1487963008.0000\n",
      "Epoch 1646/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 338201248.0000 - val_loss: 1493401216.0000\n",
      "Epoch 1647/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 342734528.0000 - val_loss: 1493656576.0000\n",
      "Epoch 1648/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 332087104.0000 - val_loss: 1477704704.0000\n",
      "Epoch 1649/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 332316672.0000 - val_loss: 1468263936.0000\n",
      "Epoch 1650/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 316572800.0000 - val_loss: 1501239936.0000\n",
      "Epoch 1651/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 325982144.0000 - val_loss: 1501185152.0000\n",
      "Epoch 1652/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 318072992.0000 - val_loss: 1494429568.0000\n",
      "Epoch 1653/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 322200160.0000 - val_loss: 1467193728.0000\n",
      "Epoch 1654/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 324675360.0000 - val_loss: 1514642688.0000\n",
      "Epoch 1655/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 321499552.0000 - val_loss: 1535860992.0000\n",
      "Epoch 1656/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 311724768.0000 - val_loss: 1471597568.0000\n",
      "Epoch 1657/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 321539232.0000 - val_loss: 1485911424.0000\n",
      "Epoch 1658/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 326200480.0000 - val_loss: 1494605824.0000\n",
      "Epoch 1659/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 327183488.0000 - val_loss: 1485260416.0000\n",
      "Epoch 1660/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 341599584.0000 - val_loss: 1480921856.0000\n",
      "Epoch 1661/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 314987936.0000 - val_loss: 1559084032.0000\n",
      "Epoch 1662/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 311315584.0000 - val_loss: 1481406592.0000\n",
      "Epoch 1663/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 325113248.0000 - val_loss: 1490040320.0000\n",
      "Epoch 1664/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 314899456.0000 - val_loss: 1482147968.0000\n",
      "Epoch 1665/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 326912928.0000 - val_loss: 1481709184.0000\n",
      "Epoch 1666/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 317003008.0000 - val_loss: 1479874688.0000\n",
      "Epoch 1667/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 318065536.0000 - val_loss: 1506459264.0000\n",
      "Epoch 1668/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 326527424.0000 - val_loss: 1476742400.0000\n",
      "Epoch 1669/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 310533600.0000 - val_loss: 1502373760.0000\n",
      "Epoch 1670/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 325796832.0000 - val_loss: 1541014272.0000\n",
      "Epoch 1671/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 317060128.0000 - val_loss: 1488541184.0000\n",
      "Epoch 1672/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 312372640.0000 - val_loss: 1472139008.0000\n",
      "Epoch 1673/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 328390592.0000 - val_loss: 1480061184.0000\n",
      "Epoch 1674/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 312610048.0000 - val_loss: 1510044672.0000\n",
      "Epoch 1675/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 333557728.0000 - val_loss: 1478339200.0000\n",
      "Epoch 1676/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 300897696.0000 - val_loss: 1486272000.0000\n",
      "Epoch 1677/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 309281152.0000 - val_loss: 1553744256.0000\n",
      "Epoch 1678/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 312762912.0000 - val_loss: 1515770496.0000\n",
      "Epoch 1679/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 306457312.0000 - val_loss: 1475248512.0000\n",
      "Epoch 1680/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 320779904.0000 - val_loss: 1525626240.0000\n",
      "Epoch 1681/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 323994336.0000 - val_loss: 1459850880.0000\n",
      "Epoch 1682/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 317198880.0000 - val_loss: 1488053376.0000\n",
      "Epoch 1683/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 314467392.0000 - val_loss: 1497797632.0000\n",
      "Epoch 1684/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 333467840.0000 - val_loss: 1488117760.0000\n",
      "Epoch 1685/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 324728992.0000 - val_loss: 1488651904.0000\n",
      "Epoch 1686/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 310724480.0000 - val_loss: 1493150848.0000\n",
      "Epoch 1687/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 319684608.0000 - val_loss: 1476130944.0000\n",
      "Epoch 1688/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 317445824.0000 - val_loss: 1532725376.0000\n",
      "Epoch 1689/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 333406304.0000 - val_loss: 1497675520.0000\n",
      "Epoch 1690/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 328716448.0000 - val_loss: 1508303104.0000\n",
      "Epoch 1691/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 323478560.0000 - val_loss: 1516558464.0000\n",
      "Epoch 1692/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 336557664.0000 - val_loss: 1480461440.0000\n",
      "Epoch 1693/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 303356160.0000 - val_loss: 1476111104.0000\n",
      "Epoch 1694/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 308202464.0000 - val_loss: 1492663552.0000\n",
      "Epoch 1695/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 334366848.0000 - val_loss: 1477740032.0000\n",
      "Epoch 1696/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 308221056.0000 - val_loss: 1462395776.0000\n",
      "Epoch 1697/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 306316448.0000 - val_loss: 1473821056.0000\n",
      "Epoch 1698/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 340668896.0000 - val_loss: 1486549120.0000\n",
      "Epoch 1699/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 301395936.0000 - val_loss: 1476282752.0000\n",
      "Epoch 1700/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 314957056.0000 - val_loss: 1466920064.0000\n",
      "Epoch 1701/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 312717152.0000 - val_loss: 1476615040.0000\n",
      "Epoch 1702/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 317944320.0000 - val_loss: 1471301760.0000\n",
      "Epoch 1703/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 322177376.0000 - val_loss: 1466351232.0000\n",
      "Epoch 1704/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 314474400.0000 - val_loss: 1469844608.0000\n",
      "Epoch 1705/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 313126688.0000 - val_loss: 1511968640.0000\n",
      "Epoch 1706/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 310339552.0000 - val_loss: 1572115456.0000\n",
      "Epoch 1707/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 318161728.0000 - val_loss: 1530214656.0000\n",
      "Epoch 1708/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 327084000.0000 - val_loss: 1462689152.0000\n",
      "Epoch 1709/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 310552800.0000 - val_loss: 1502739968.0000\n",
      "Epoch 1710/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 312623456.0000 - val_loss: 1514643072.0000\n",
      "Epoch 1711/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 325993760.0000 - val_loss: 1487227008.0000\n",
      "Epoch 1712/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 308782464.0000 - val_loss: 1461679488.0000\n",
      "Epoch 1713/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 314797568.0000 - val_loss: 1533994496.0000\n",
      "Epoch 1714/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 345100160.0000 - val_loss: 1507197056.0000\n",
      "Epoch 1715/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 310618176.0000 - val_loss: 1468360576.0000\n",
      "Epoch 1716/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 295994656.0000 - val_loss: 1468798208.0000\n",
      "Epoch 1717/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 309649568.0000 - val_loss: 1463273728.0000\n",
      "Epoch 1718/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 312459584.0000 - val_loss: 1474485632.0000\n",
      "Epoch 1719/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 316744320.0000 - val_loss: 1465339264.0000\n",
      "Epoch 1720/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 309031136.0000 - val_loss: 1476504448.0000\n",
      "Epoch 1721/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 321178240.0000 - val_loss: 1563833856.0000\n",
      "Epoch 1722/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 329839488.0000 - val_loss: 1470306688.0000\n",
      "Epoch 1723/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 308015424.0000 - val_loss: 1460135424.0000\n",
      "Epoch 1724/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 315566432.0000 - val_loss: 1505170432.0000\n",
      "Epoch 1725/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 323913760.0000 - val_loss: 1556503168.0000\n",
      "Epoch 1726/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 307909152.0000 - val_loss: 1497524992.0000\n",
      "Epoch 1727/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 318148256.0000 - val_loss: 1612599040.0000\n",
      "Epoch 1728/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 325484640.0000 - val_loss: 1481375744.0000\n",
      "Epoch 1729/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 336907200.0000 - val_loss: 1472496512.0000\n",
      "Epoch 1730/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 317830208.0000 - val_loss: 1535484800.0000\n",
      "Epoch 1731/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 320657024.0000 - val_loss: 1478270080.0000\n",
      "Epoch 1732/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 309900512.0000 - val_loss: 1458705536.0000\n",
      "Epoch 1733/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 305894432.0000 - val_loss: 1507740672.0000\n",
      "Epoch 1734/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 320495552.0000 - val_loss: 1522503424.0000\n",
      "Epoch 1735/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 309259360.0000 - val_loss: 1487532032.0000\n",
      "Epoch 1736/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 307458240.0000 - val_loss: 1470197504.0000\n",
      "Epoch 1737/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 312438016.0000 - val_loss: 1522527104.0000\n",
      "Epoch 1738/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 306654528.0000 - val_loss: 1480315904.0000\n",
      "Epoch 1739/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 317605408.0000 - val_loss: 1569328384.0000\n",
      "Epoch 1740/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 297838272.0000 - val_loss: 1473998464.0000\n",
      "Epoch 1741/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 314177344.0000 - val_loss: 1524166784.0000\n",
      "Epoch 1742/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 340201632.0000 - val_loss: 1471565440.0000\n",
      "Epoch 1743/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 301244512.0000 - val_loss: 1484743552.0000\n",
      "Epoch 1744/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 307301664.0000 - val_loss: 1479575680.0000\n",
      "Epoch 1745/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 307878592.0000 - val_loss: 1464147072.0000\n",
      "Epoch 1746/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 319443552.0000 - val_loss: 1486305536.0000\n",
      "Epoch 1747/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 319240000.0000 - val_loss: 1503642752.0000\n",
      "Epoch 1748/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 289731456.0000 - val_loss: 1474179584.0000\n",
      "Epoch 1749/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 294692448.0000 - val_loss: 1468349568.0000\n",
      "Epoch 1750/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 310998944.0000 - val_loss: 1497648256.0000\n",
      "Epoch 1751/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 306603072.0000 - val_loss: 1479920384.0000\n",
      "Epoch 1752/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 307593536.0000 - val_loss: 1493975424.0000\n",
      "Epoch 1753/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 295803584.0000 - val_loss: 1482954880.0000\n",
      "Epoch 1754/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 296128512.0000 - val_loss: 1474715904.0000\n",
      "Epoch 1755/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 321332896.0000 - val_loss: 1519581568.0000\n",
      "Epoch 1756/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 320044640.0000 - val_loss: 1482887040.0000\n",
      "Epoch 1757/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 303353760.0000 - val_loss: 1490123264.0000\n",
      "Epoch 1758/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 304932672.0000 - val_loss: 1475201152.0000\n",
      "Epoch 1759/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 296711232.0000 - val_loss: 1476799872.0000\n",
      "Epoch 1760/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 315909120.0000 - val_loss: 1467011072.0000\n",
      "Epoch 1761/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 318339392.0000 - val_loss: 1514853376.0000\n",
      "Epoch 1762/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 300721504.0000 - val_loss: 1548673280.0000\n",
      "Epoch 1763/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 327412640.0000 - val_loss: 1470547712.0000\n",
      "Epoch 1764/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 298185056.0000 - val_loss: 1494908160.0000\n",
      "Epoch 1765/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 345386816.0000 - val_loss: 1475725440.0000\n",
      "Epoch 1766/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 311293824.0000 - val_loss: 1471237376.0000\n",
      "Epoch 1767/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 312170720.0000 - val_loss: 1485915264.0000\n",
      "Epoch 1768/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 288638368.0000 - val_loss: 1469897344.0000\n",
      "Epoch 1769/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 313896128.0000 - val_loss: 1626515712.0000\n",
      "Epoch 1770/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 313817344.0000 - val_loss: 1622333952.0000\n",
      "Epoch 1771/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 311555456.0000 - val_loss: 1504087552.0000\n",
      "Epoch 1772/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 328853504.0000 - val_loss: 1495103616.0000\n",
      "Epoch 1773/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 320467168.0000 - val_loss: 1622164224.0000\n",
      "Epoch 1774/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 320388032.0000 - val_loss: 1548866688.0000\n",
      "Epoch 1775/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 304237024.0000 - val_loss: 1466010624.0000\n",
      "Epoch 1776/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 330960544.0000 - val_loss: 1525579264.0000\n",
      "Epoch 1777/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 287584928.0000 - val_loss: 1526304896.0000\n",
      "Epoch 1778/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 289018336.0000 - val_loss: 1571381632.0000\n",
      "Epoch 1779/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 299562464.0000 - val_loss: 1475973120.0000\n",
      "Epoch 1780/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 305591584.0000 - val_loss: 1606919040.0000\n",
      "Epoch 1781/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 297455872.0000 - val_loss: 1465073408.0000\n",
      "Epoch 1782/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 303905888.0000 - val_loss: 1470633600.0000\n",
      "Epoch 1783/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 302435392.0000 - val_loss: 1495475712.0000\n",
      "Epoch 1784/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 288791232.0000 - val_loss: 1499723648.0000\n",
      "Epoch 1785/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 303684032.0000 - val_loss: 1557731840.0000\n",
      "Epoch 1786/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 321914144.0000 - val_loss: 1484583680.0000\n",
      "Epoch 1787/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 296066688.0000 - val_loss: 1486284160.0000\n",
      "Epoch 1788/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 295443296.0000 - val_loss: 1492477440.0000\n",
      "Epoch 1789/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 327356864.0000 - val_loss: 1477593728.0000\n",
      "Epoch 1790/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 300365824.0000 - val_loss: 1466182656.0000\n",
      "Epoch 1791/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 307373792.0000 - val_loss: 1478638208.0000\n",
      "Epoch 1792/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 291593536.0000 - val_loss: 1476992640.0000\n",
      "Epoch 1793/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 306961952.0000 - val_loss: 1467186048.0000\n",
      "Epoch 1794/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 297167040.0000 - val_loss: 1483712768.0000\n",
      "Epoch 1795/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 292918784.0000 - val_loss: 1488360320.0000\n",
      "Epoch 1796/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 303900032.0000 - val_loss: 1487746688.0000\n",
      "Epoch 1797/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 298420704.0000 - val_loss: 1537494144.0000\n",
      "Epoch 1798/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 304271936.0000 - val_loss: 1481310848.0000\n",
      "Epoch 1799/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 300856672.0000 - val_loss: 1494242048.0000\n",
      "Epoch 1800/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 289325184.0000 - val_loss: 1486185472.0000\n",
      "Epoch 1801/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 306501216.0000 - val_loss: 1486242304.0000\n",
      "Epoch 1802/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 299788992.0000 - val_loss: 1496044160.0000\n",
      "Epoch 1803/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 295474336.0000 - val_loss: 1486248320.0000\n",
      "Epoch 1804/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 303296576.0000 - val_loss: 1557882752.0000\n",
      "Epoch 1805/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 302669760.0000 - val_loss: 1478013056.0000\n",
      "Epoch 1806/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 304832512.0000 - val_loss: 1523923200.0000\n",
      "Epoch 1807/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 292833344.0000 - val_loss: 1501614464.0000\n",
      "Epoch 1808/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 314050400.0000 - val_loss: 1522173568.0000\n",
      "Epoch 1809/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 307985248.0000 - val_loss: 1488093056.0000\n",
      "Epoch 1810/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 301893760.0000 - val_loss: 1476823552.0000\n",
      "Epoch 1811/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 301100640.0000 - val_loss: 1481381888.0000\n",
      "Epoch 1812/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 306340928.0000 - val_loss: 1486651776.0000\n",
      "Epoch 1813/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 313867232.0000 - val_loss: 1536070400.0000\n",
      "Epoch 1814/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 302804768.0000 - val_loss: 1467559680.0000\n",
      "Epoch 1815/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 288622176.0000 - val_loss: 1601564544.0000\n",
      "Epoch 1816/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 298046560.0000 - val_loss: 1481154816.0000\n",
      "Epoch 1817/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 291082976.0000 - val_loss: 1462155904.0000\n",
      "Epoch 1818/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 290151264.0000 - val_loss: 1471985280.0000\n",
      "Epoch 1819/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 290223712.0000 - val_loss: 1732349952.0000\n",
      "Epoch 1820/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 293302112.0000 - val_loss: 1454330880.0000\n",
      "Epoch 1821/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 334689344.0000 - val_loss: 1505878784.0000\n",
      "Epoch 1822/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 312534944.0000 - val_loss: 1517843456.0000\n",
      "Epoch 1823/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 309189024.0000 - val_loss: 1521701760.0000\n",
      "Epoch 1824/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 291644448.0000 - val_loss: 1470453760.0000\n",
      "Epoch 1825/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 334119488.0000 - val_loss: 1480041088.0000\n",
      "Epoch 1826/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 295170400.0000 - val_loss: 1507438464.0000\n",
      "Epoch 1827/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 296492704.0000 - val_loss: 1468383232.0000\n",
      "Epoch 1828/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 321617184.0000 - val_loss: 1569532544.0000\n",
      "Epoch 1829/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 291872224.0000 - val_loss: 1478508544.0000\n",
      "Epoch 1830/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 302464160.0000 - val_loss: 1464036608.0000\n",
      "Epoch 1831/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 310022624.0000 - val_loss: 1644427648.0000\n",
      "Epoch 1832/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 321124896.0000 - val_loss: 1466081920.0000\n",
      "Epoch 1833/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 286260928.0000 - val_loss: 1505123328.0000\n",
      "Epoch 1834/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 299707616.0000 - val_loss: 1481154048.0000\n",
      "Epoch 1835/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 311204000.0000 - val_loss: 1462142976.0000\n",
      "Epoch 1836/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 292235072.0000 - val_loss: 1459538176.0000\n",
      "Epoch 1837/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 290374112.0000 - val_loss: 1488616448.0000\n",
      "Epoch 1838/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 302408384.0000 - val_loss: 1468374144.0000\n",
      "Epoch 1839/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 292955072.0000 - val_loss: 1592710400.0000\n",
      "Epoch 1840/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 285730400.0000 - val_loss: 1494058368.0000\n",
      "Epoch 1841/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 305260160.0000 - val_loss: 1550413440.0000\n",
      "Epoch 1842/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 288252096.0000 - val_loss: 1571277184.0000\n",
      "Epoch 1843/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 288714560.0000 - val_loss: 1475113856.0000\n",
      "Epoch 1844/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 290071872.0000 - val_loss: 1483193216.0000\n",
      "Epoch 1845/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 317246304.0000 - val_loss: 1476889856.0000\n",
      "Epoch 1846/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 299238496.0000 - val_loss: 1492737536.0000\n",
      "Epoch 1847/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 305646240.0000 - val_loss: 1490259840.0000\n",
      "Epoch 1848/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 291001632.0000 - val_loss: 1578469376.0000\n",
      "Epoch 1849/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 298502912.0000 - val_loss: 1466865664.0000\n",
      "Epoch 1850/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 301567040.0000 - val_loss: 1464522752.0000\n",
      "Epoch 1851/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 290403232.0000 - val_loss: 1446304256.0000\n",
      "Epoch 1852/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 302913984.0000 - val_loss: 1474182656.0000\n",
      "Epoch 1853/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 294671296.0000 - val_loss: 1474877568.0000\n",
      "Epoch 1854/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 287265088.0000 - val_loss: 1491197696.0000\n",
      "Epoch 1855/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 297636192.0000 - val_loss: 1465326720.0000\n",
      "Epoch 1856/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 296839712.0000 - val_loss: 1466678144.0000\n",
      "Epoch 1857/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 302568256.0000 - val_loss: 1463670144.0000\n",
      "Epoch 1858/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 328696800.0000 - val_loss: 1489178496.0000\n",
      "Epoch 1859/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 288165024.0000 - val_loss: 1560545408.0000\n",
      "Epoch 1860/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 297776256.0000 - val_loss: 1462923520.0000\n",
      "Epoch 1861/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 292562752.0000 - val_loss: 1461555072.0000\n",
      "Epoch 1862/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 292102720.0000 - val_loss: 1458029568.0000\n",
      "Epoch 1863/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 290508352.0000 - val_loss: 1455796608.0000\n",
      "Epoch 1864/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 286075872.0000 - val_loss: 1495513344.0000\n",
      "Epoch 1865/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 285576160.0000 - val_loss: 1476087936.0000\n",
      "Epoch 1866/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 285655776.0000 - val_loss: 1588510976.0000\n",
      "Epoch 1867/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 292698560.0000 - val_loss: 1466636288.0000\n",
      "Epoch 1868/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 300476000.0000 - val_loss: 1532641792.0000\n",
      "Epoch 1869/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 304567552.0000 - val_loss: 1511705856.0000\n",
      "Epoch 1870/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 299962112.0000 - val_loss: 1500193024.0000\n",
      "Epoch 1871/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 285572832.0000 - val_loss: 1453401856.0000\n",
      "Epoch 1872/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 290901600.0000 - val_loss: 1461281792.0000\n",
      "Epoch 1873/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 309882016.0000 - val_loss: 1482354816.0000\n",
      "Epoch 1874/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 298526176.0000 - val_loss: 1464313472.0000\n",
      "Epoch 1875/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 290048576.0000 - val_loss: 1474997376.0000\n",
      "Epoch 1876/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 298737984.0000 - val_loss: 1494569856.0000\n",
      "Epoch 1877/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 314654272.0000 - val_loss: 1444509952.0000\n",
      "Epoch 1878/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 331006848.0000 - val_loss: 1591435520.0000\n",
      "Epoch 1879/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 300639808.0000 - val_loss: 1472386688.0000\n",
      "Epoch 1880/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 308293024.0000 - val_loss: 1452543232.0000\n",
      "Epoch 1881/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 294695872.0000 - val_loss: 1449555328.0000\n",
      "Epoch 1882/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 292803264.0000 - val_loss: 1470647424.0000\n",
      "Epoch 1883/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 287327232.0000 - val_loss: 1466438656.0000\n",
      "Epoch 1884/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 303726304.0000 - val_loss: 1466776448.0000\n",
      "Epoch 1885/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 297304896.0000 - val_loss: 1517786368.0000\n",
      "Epoch 1886/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 293386976.0000 - val_loss: 1452786816.0000\n",
      "Epoch 1887/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 283861440.0000 - val_loss: 1458692992.0000\n",
      "Epoch 1888/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 298691008.0000 - val_loss: 1551532800.0000\n",
      "Epoch 1889/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 296957184.0000 - val_loss: 1459667584.0000\n",
      "Epoch 1890/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 302813472.0000 - val_loss: 1499677312.0000\n",
      "Epoch 1891/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 284028768.0000 - val_loss: 1460976128.0000\n",
      "Epoch 1892/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 287302848.0000 - val_loss: 1460549376.0000\n",
      "Epoch 1893/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 288525824.0000 - val_loss: 1441484544.0000\n",
      "Epoch 1894/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 290659712.0000 - val_loss: 1456700672.0000\n",
      "Epoch 1895/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 282547424.0000 - val_loss: 1499698432.0000\n",
      "Epoch 1896/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 282303680.0000 - val_loss: 1470788096.0000\n",
      "Epoch 1897/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 298083712.0000 - val_loss: 1467262976.0000\n",
      "Epoch 1898/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 316425600.0000 - val_loss: 1462326656.0000\n",
      "Epoch 1899/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 288112928.0000 - val_loss: 1453450624.0000\n",
      "Epoch 1900/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 274404000.0000 - val_loss: 1444291328.0000\n",
      "Epoch 1901/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 279739040.0000 - val_loss: 1468698496.0000\n",
      "Epoch 1902/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 290914400.0000 - val_loss: 1458062080.0000\n",
      "Epoch 1903/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 299878464.0000 - val_loss: 1476282752.0000\n",
      "Epoch 1904/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 319705600.0000 - val_loss: 1487479808.0000\n",
      "Epoch 1905/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 286897792.0000 - val_loss: 1490756992.0000\n",
      "Epoch 1906/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 290185888.0000 - val_loss: 1445272192.0000\n",
      "Epoch 1907/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 305490848.0000 - val_loss: 1524024320.0000\n",
      "Epoch 1908/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 286454848.0000 - val_loss: 1465349632.0000\n",
      "Epoch 1909/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 319139776.0000 - val_loss: 1465141504.0000\n",
      "Epoch 1910/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 270869280.0000 - val_loss: 1490992128.0000\n",
      "Epoch 1911/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 309118144.0000 - val_loss: 1459176576.0000\n",
      "Epoch 1912/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 294037952.0000 - val_loss: 1458513280.0000\n",
      "Epoch 1913/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 291386528.0000 - val_loss: 1453861248.0000\n",
      "Epoch 1914/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 285166432.0000 - val_loss: 1451678208.0000\n",
      "Epoch 1915/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 286730176.0000 - val_loss: 1476081408.0000\n",
      "Epoch 1916/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 281641056.0000 - val_loss: 1453573248.0000\n",
      "Epoch 1917/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 298745376.0000 - val_loss: 1477666176.0000\n",
      "Epoch 1918/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 281404672.0000 - val_loss: 1456327552.0000\n",
      "Epoch 1919/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 294712192.0000 - val_loss: 1477592320.0000\n",
      "Epoch 1920/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 288846208.0000 - val_loss: 1478942720.0000\n",
      "Epoch 1921/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 282266016.0000 - val_loss: 1444025344.0000\n",
      "Epoch 1922/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 293232576.0000 - val_loss: 1457984640.0000\n",
      "Epoch 1923/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 288560608.0000 - val_loss: 1554263296.0000\n",
      "Epoch 1924/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 270738464.0000 - val_loss: 1528608896.0000\n",
      "Epoch 1925/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 287682912.0000 - val_loss: 1452229760.0000\n",
      "Epoch 1926/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 349848672.0000 - val_loss: 1483031424.0000\n",
      "Epoch 1927/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 280776992.0000 - val_loss: 1492403968.0000\n",
      "Epoch 1928/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 276185152.0000 - val_loss: 1588320512.0000\n",
      "Epoch 1929/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 297462368.0000 - val_loss: 1465622784.0000\n",
      "Epoch 1930/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 317230656.0000 - val_loss: 1457324416.0000\n",
      "Epoch 1931/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 278530464.0000 - val_loss: 1450902272.0000\n",
      "Epoch 1932/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 273564256.0000 - val_loss: 1483654144.0000\n",
      "Epoch 1933/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 284457120.0000 - val_loss: 1479729280.0000\n",
      "Epoch 1934/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 282101472.0000 - val_loss: 1485564032.0000\n",
      "Epoch 1935/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 300420640.0000 - val_loss: 1529848192.0000\n",
      "Epoch 1936/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 313127872.0000 - val_loss: 1512158208.0000\n",
      "Epoch 1937/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 289149216.0000 - val_loss: 1455115008.0000\n",
      "Epoch 1938/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 273213216.0000 - val_loss: 1481545984.0000\n",
      "Epoch 1939/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 294230912.0000 - val_loss: 1453609856.0000\n",
      "Epoch 1940/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 282130528.0000 - val_loss: 1468942720.0000\n",
      "Epoch 1941/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 277568288.0000 - val_loss: 1551320192.0000\n",
      "Epoch 1942/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 283752512.0000 - val_loss: 1454105600.0000\n",
      "Epoch 1943/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 279114528.0000 - val_loss: 1435088000.0000\n",
      "Epoch 1944/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 275026656.0000 - val_loss: 1470794112.0000\n",
      "Epoch 1945/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 285694080.0000 - val_loss: 1450147200.0000\n",
      "Epoch 1946/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 283864896.0000 - val_loss: 1462204544.0000\n",
      "Epoch 1947/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 288679264.0000 - val_loss: 1486430976.0000\n",
      "Epoch 1948/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 287330368.0000 - val_loss: 1466055808.0000\n",
      "Epoch 1949/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 293768960.0000 - val_loss: 1579811968.0000\n",
      "Epoch 1950/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 300694112.0000 - val_loss: 1464011648.0000\n",
      "Epoch 1951/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 280021568.0000 - val_loss: 1457229696.0000\n",
      "Epoch 1952/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 276473152.0000 - val_loss: 1512524800.0000\n",
      "Epoch 1953/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 294383296.0000 - val_loss: 1462427776.0000\n",
      "Epoch 1954/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 274581632.0000 - val_loss: 1445225600.0000\n",
      "Epoch 1955/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 279971360.0000 - val_loss: 1496041856.0000\n",
      "Epoch 1956/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 281298336.0000 - val_loss: 1595021440.0000\n",
      "Epoch 1957/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 273858976.0000 - val_loss: 1487615872.0000\n",
      "Epoch 1958/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 278931744.0000 - val_loss: 1471171584.0000\n",
      "Epoch 1959/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 286555840.0000 - val_loss: 1468864640.0000\n",
      "Epoch 1960/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 293216512.0000 - val_loss: 1452836992.0000\n",
      "Epoch 1961/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 276087776.0000 - val_loss: 1449090048.0000\n",
      "Epoch 1962/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 290510752.0000 - val_loss: 1449465472.0000\n",
      "Epoch 1963/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 270674016.0000 - val_loss: 1486074624.0000\n",
      "Epoch 1964/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 280825504.0000 - val_loss: 1487483008.0000\n",
      "Epoch 1965/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 273710464.0000 - val_loss: 1457525248.0000\n",
      "Epoch 1966/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 283400352.0000 - val_loss: 1500687488.0000\n",
      "Epoch 1967/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 277278304.0000 - val_loss: 1465256704.0000\n",
      "Epoch 1968/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 291435872.0000 - val_loss: 1444923392.0000\n",
      "Epoch 1969/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 285344064.0000 - val_loss: 1457425280.0000\n",
      "Epoch 1970/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 267933936.0000 - val_loss: 1449968384.0000\n",
      "Epoch 1971/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 270177504.0000 - val_loss: 1449280384.0000\n",
      "Epoch 1972/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 302365152.0000 - val_loss: 1464264960.0000\n",
      "Epoch 1973/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 288141568.0000 - val_loss: 1448553216.0000\n",
      "Epoch 1974/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 274783136.0000 - val_loss: 1459138048.0000\n",
      "Epoch 1975/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 290835936.0000 - val_loss: 1499933312.0000\n",
      "Epoch 1976/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 299223584.0000 - val_loss: 1570048640.0000\n",
      "Epoch 1977/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 287893440.0000 - val_loss: 1453011456.0000\n",
      "Epoch 1978/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 274503072.0000 - val_loss: 1464369280.0000\n",
      "Epoch 1979/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 297176448.0000 - val_loss: 1459410688.0000\n",
      "Epoch 1980/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 283141824.0000 - val_loss: 1449386496.0000\n",
      "Epoch 1981/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 305183872.0000 - val_loss: 1492854784.0000\n",
      "Epoch 1982/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 275614720.0000 - val_loss: 1440560768.0000\n",
      "Epoch 1983/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 279895840.0000 - val_loss: 1486853760.0000\n",
      "Epoch 1984/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 289398144.0000 - val_loss: 1555806464.0000\n",
      "Epoch 1985/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 301616128.0000 - val_loss: 1458531456.0000\n",
      "Epoch 1986/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 277481088.0000 - val_loss: 1449145600.0000\n",
      "Epoch 1987/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 266384768.0000 - val_loss: 1468358656.0000\n",
      "Epoch 1988/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 280137824.0000 - val_loss: 1496695296.0000\n",
      "Epoch 1989/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 264258880.0000 - val_loss: 1446542592.0000\n",
      "Epoch 1990/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 271085856.0000 - val_loss: 1455325440.0000\n",
      "Epoch 1991/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 266367376.0000 - val_loss: 1455829760.0000\n",
      "Epoch 1992/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 282302944.0000 - val_loss: 1431682816.0000\n",
      "Epoch 1993/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 298220352.0000 - val_loss: 1465958400.0000\n",
      "Epoch 1994/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 292231552.0000 - val_loss: 1443506944.0000\n",
      "Epoch 1995/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 272498144.0000 - val_loss: 1438542976.0000\n",
      "Epoch 1996/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 285313248.0000 - val_loss: 1457650048.0000\n",
      "Epoch 1997/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 298496672.0000 - val_loss: 1445965440.0000\n",
      "Epoch 1998/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 279392768.0000 - val_loss: 1460915840.0000\n",
      "Epoch 1999/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 281293216.0000 - val_loss: 1455086208.0000\n",
      "Epoch 2000/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 274597440.0000 - val_loss: 1596902528.0000\n"
     ]
    }
   ],
   "source": [
    "#keras.layers.Dense(units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)\n",
    "#classifier.add(Dense(6, activation='relu', kernel_initializer='glorot_uniform',input_dim=11))\n",
    "\n",
    "\n",
    "# Initialising the Artifical Neural Network\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(50, kernel_initializer = 'he_uniform',activation='relu',input_dim = 174))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(50, kernel_initializer = 'he_uniform',activation='relu'))\n",
    "\n",
    "# Adding the third hidden layer\n",
    "classifier.add(Dense(50, kernel_initializer = 'he_uniform',activation='relu'))\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(1, kernel_initializer = 'he_uniform'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer='Adamax')\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "model_history=classifier.fit(X_train.values, Y_train.values,validation_split=0.20, batch_size = 10, epochs = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3206cdc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 717us/step\n"
     ]
    }
   ],
   "source": [
    "Y_pred=classifier.predict(df_Test.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fc71487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create Sample Submission file and Submit using ANN\n",
    "pred_df=pd.DataFrame(Y_pred) #Converting to DF\n",
    "submission_df=pd.read_csv('Project/sample_submission.csv') #Reading website's sample as csv\n",
    "datasets=pd.concat([submission_df['Id'],pred_df],axis=1) #Taking the ID from the submission after we deleted it at the beggning\n",
    "datasets.columns=['Id','SalePrice']\n",
    "datasets.to_csv('sample_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b1ec775c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create Sample Submission file and Submit using ANN\n",
    "pred_df=pd.DataFrame(Y_pred) #Converting to DF\n",
    "submission_df=pd.read_csv('Project/sample_submission.csv') #Reading website's sample as csv\n",
    "datasets=pd.concat([submission_df['Id'],pred_df],axis=1) #Taking the ID from the submission after we deleted it at the beggning\n",
    "datasets.columns=['Id','SalePrice']\n",
    "datasets.to_csv('sample_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0d39df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
