{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de0d812d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno #Heatmap\n",
    "import sklearn\n",
    "import xgboost #ML algo\n",
    "from sklearn.ensemble import RandomForestRegressor #ML algo\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn import linear_model #ML algo\n",
    "import pickle \n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LeakyReLU,PReLU,ELU\n",
    "from keras.layers import Dropout\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53440f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Project_data/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2003ca83",
   "metadata": {},
   "source": [
    "# NULL Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f71a4c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8244873e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(df.isnull(),yticklabels=False,cbar=False,cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e39e8abe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x864 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "msno.heatmap(df) #corrlations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c57002b",
   "metadata": {},
   "source": [
    "# Imputation the missing values\n",
    "Basically, here if I had a Null observations over than 50% I would drop the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "085e1afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Alley'],axis=1,inplace=True)\n",
    "df.drop(['GarageYrBlt'],axis=1,inplace=True)\n",
    "df.drop(['PoolQC','Fence','MiscFeature'],axis=1,inplace=True)\n",
    "df.drop(['Id'],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb392bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LotFrontage']=df['LotFrontage'].fillna(df['LotFrontage'].mean())\n",
    "df['BsmtCond']=df['BsmtCond'].fillna(df['BsmtCond'].mode()[0])#mode of this column\n",
    "df['BsmtQual']=df['BsmtQual'].fillna(df['BsmtQual'].mode()[0])\n",
    "df['FireplaceQu']=df['FireplaceQu'].fillna(df['FireplaceQu'].mode()[0])\n",
    "df['GarageType']=df['GarageType'].fillna(df['GarageType'].mode()[0])\n",
    "df['GarageFinish']=df['GarageFinish'].fillna(df['GarageFinish'].mode()[0])\n",
    "df['GarageQual']=df['GarageQual'].fillna(df['GarageQual'].mode()[0])\n",
    "df['GarageCond']=df['GarageCond'].fillna(df['GarageCond'].mode()[0])\n",
    "df['MasVnrType']=df['MasVnrType'].fillna(df['MasVnrType'].mode()[0])\n",
    "df['MasVnrArea']=df['MasVnrArea'].fillna(df['MasVnrArea'].mode()[0])\n",
    "df['BsmtExposure']=df['BsmtExposure'].fillna(df['BsmtExposure'].mode()[0])\n",
    "df['BsmtFinType2']=df['BsmtFinType2'].fillna(df['BsmtFinType2'].mode()[0])\n",
    "df.dropna(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36c5e314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSSubClass       0\n",
       "MSZoning         0\n",
       "LotFrontage      0\n",
       "LotArea          0\n",
       "Street           0\n",
       "LotShape         0\n",
       "LandContour      0\n",
       "Utilities        0\n",
       "LotConfig        0\n",
       "LandSlope        0\n",
       "Neighborhood     0\n",
       "Condition1       0\n",
       "Condition2       0\n",
       "BldgType         0\n",
       "HouseStyle       0\n",
       "OverallQual      0\n",
       "OverallCond      0\n",
       "YearBuilt        0\n",
       "YearRemodAdd     0\n",
       "RoofStyle        0\n",
       "RoofMatl         0\n",
       "Exterior1st      0\n",
       "Exterior2nd      0\n",
       "MasVnrType       0\n",
       "MasVnrArea       0\n",
       "ExterQual        0\n",
       "ExterCond        0\n",
       "Foundation       0\n",
       "BsmtQual         0\n",
       "BsmtCond         0\n",
       "BsmtExposure     0\n",
       "BsmtFinType1     0\n",
       "BsmtFinSF1       0\n",
       "BsmtFinType2     0\n",
       "BsmtFinSF2       0\n",
       "BsmtUnfSF        0\n",
       "TotalBsmtSF      0\n",
       "Heating          0\n",
       "HeatingQC        0\n",
       "CentralAir       0\n",
       "Electrical       0\n",
       "1stFlrSF         0\n",
       "2ndFlrSF         0\n",
       "LowQualFinSF     0\n",
       "GrLivArea        0\n",
       "BsmtFullBath     0\n",
       "BsmtHalfBath     0\n",
       "FullBath         0\n",
       "HalfBath         0\n",
       "BedroomAbvGr     0\n",
       "KitchenAbvGr     0\n",
       "KitchenQual      0\n",
       "TotRmsAbvGrd     0\n",
       "Functional       0\n",
       "Fireplaces       0\n",
       "FireplaceQu      0\n",
       "GarageType       0\n",
       "GarageFinish     0\n",
       "GarageCars       0\n",
       "GarageArea       0\n",
       "GarageQual       0\n",
       "GarageCond       0\n",
       "PavedDrive       0\n",
       "WoodDeckSF       0\n",
       "OpenPorchSF      0\n",
       "EnclosedPorch    0\n",
       "3SsnPorch        0\n",
       "ScreenPorch      0\n",
       "PoolArea         0\n",
       "MiscVal          0\n",
       "MoSold           0\n",
       "YrSold           0\n",
       "SaleType         0\n",
       "SaleCondition    0\n",
       "SalePrice        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a02fd946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1422, 75)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a141a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0          60       RL         65.0     8450   Pave      Reg         Lvl   \n",
       "1          20       RL         80.0     9600   Pave      Reg         Lvl   \n",
       "2          60       RL         68.0    11250   Pave      IR1         Lvl   \n",
       "3          70       RL         60.0     9550   Pave      IR1         Lvl   \n",
       "4          60       RL         84.0    14260   Pave      IR1         Lvl   \n",
       "\n",
       "  Utilities LotConfig LandSlope  ... EnclosedPorch 3SsnPorch ScreenPorch  \\\n",
       "0    AllPub    Inside       Gtl  ...             0         0           0   \n",
       "1    AllPub       FR2       Gtl  ...             0         0           0   \n",
       "2    AllPub    Inside       Gtl  ...             0         0           0   \n",
       "3    AllPub    Corner       Gtl  ...           272         0           0   \n",
       "4    AllPub       FR2       Gtl  ...             0         0           0   \n",
       "\n",
       "  PoolArea MiscVal  MoSold  YrSold  SaleType  SaleCondition SalePrice  \n",
       "0        0       0       2    2008        WD         Normal    208500  \n",
       "1        0       0       5    2007        WD         Normal    181500  \n",
       "2        0       0       9    2008        WD         Normal    223500  \n",
       "3        0       0       2    2006        WD        Abnorml    140000  \n",
       "4        0       0      12    2008        WD         Normal    250000  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11ec5e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 39 categorical feature\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['MSZoning',\n",
       " 'Street',\n",
       " 'LotShape',\n",
       " 'LandContour',\n",
       " 'Utilities',\n",
       " 'LotConfig',\n",
       " 'LandSlope',\n",
       " 'Neighborhood',\n",
       " 'Condition1',\n",
       " 'Condition2',\n",
       " 'BldgType',\n",
       " 'HouseStyle',\n",
       " 'RoofStyle',\n",
       " 'RoofMatl',\n",
       " 'Exterior1st',\n",
       " 'Exterior2nd',\n",
       " 'MasVnrType',\n",
       " 'ExterQual',\n",
       " 'ExterCond',\n",
       " 'Foundation',\n",
       " 'BsmtQual',\n",
       " 'BsmtCond',\n",
       " 'BsmtExposure',\n",
       " 'BsmtFinType1',\n",
       " 'BsmtFinType2',\n",
       " 'Heating',\n",
       " 'HeatingQC',\n",
       " 'CentralAir',\n",
       " 'Electrical',\n",
       " 'KitchenQual',\n",
       " 'Functional',\n",
       " 'FireplaceQu',\n",
       " 'GarageType',\n",
       " 'GarageFinish',\n",
       " 'GarageQual',\n",
       " 'GarageCond',\n",
       " 'PavedDrive',\n",
       " 'SaleType',\n",
       " 'SaleCondition']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Assigning categorical features to a variable\n",
    "categorical_columns=df.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f'There is {len(categorical_columns)} categorical feature')\n",
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc847b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_data=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63bd6f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df=pd.read_csv('Project_data/handledtestdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01c672c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 75)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_prices=pd.concat([df,concat_df],axis=0) #horizontal concatenation\n",
    "house_prices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8a2bb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function converting categorical to numerical values\n",
    "def category_onehot_multcols(multcolumns):\n",
    "    final_df=house_prices\n",
    "    i=0\n",
    "    for fields in multcolumns:\n",
    "        \n",
    "        print(fields)\n",
    "        df1=pd.get_dummies(house_prices[fields],drop_first=True)\n",
    "        \n",
    "        house_prices.drop([fields],axis=1,inplace=True)\n",
    "        if i==0:\n",
    "            final_df=df1.copy()\n",
    "        else:\n",
    "            \n",
    "            final_df=pd.concat([final_df,df1],axis=1)\n",
    "        i=i+1\n",
    "       \n",
    "        \n",
    "    final_df=pd.concat([house_prices,final_df],axis=1)\n",
    "        \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9534065a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSZoning\n",
      "Street\n",
      "LotShape\n",
      "LandContour\n",
      "Utilities\n",
      "LotConfig\n",
      "LandSlope\n",
      "Neighborhood\n",
      "Condition1\n",
      "Condition2\n",
      "BldgType\n",
      "HouseStyle\n",
      "RoofStyle\n",
      "RoofMatl\n",
      "Exterior1st\n",
      "Exterior2nd\n",
      "MasVnrType\n",
      "ExterQual\n",
      "ExterCond\n",
      "Foundation\n",
      "BsmtQual\n",
      "BsmtCond\n",
      "BsmtExposure\n",
      "BsmtFinType1\n",
      "BsmtFinType2\n",
      "Heating\n",
      "HeatingQC\n",
      "CentralAir\n",
      "Electrical\n",
      "KitchenQual\n",
      "Functional\n",
      "FireplaceQu\n",
      "GarageType\n",
      "GarageFinish\n",
      "GarageQual\n",
      "GarageCond\n",
      "PavedDrive\n",
      "SaleType\n",
      "SaleCondition\n"
     ]
    }
   ],
   "source": [
    "house_prices=category_onehot_multcols(categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6fc7e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 235)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_prices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d78e963",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df =house_prices.loc[:,~house_prices.columns.duplicated()] #removing duplicates columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d1b5323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2881, 175)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4556c5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Train=final_df.iloc[:1422,:] #The number of observations in train data\n",
    "df_Test=final_df.iloc[1422:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff8d65e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>ConLI</th>\n",
       "      <th>ConLw</th>\n",
       "      <th>New</th>\n",
       "      <th>Oth</th>\n",
       "      <th>WD</th>\n",
       "      <th>AdjLand</th>\n",
       "      <th>Alloca</th>\n",
       "      <th>Family</th>\n",
       "      <th>Normal</th>\n",
       "      <th>Partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0          60         65.0     8450            7            5       2003   \n",
       "1          20         80.0     9600            6            8       1976   \n",
       "2          60         68.0    11250            7            5       2001   \n",
       "3          70         60.0     9550            7            5       1915   \n",
       "4          60         84.0    14260            8            5       2000   \n",
       "\n",
       "   YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  ConLI  ConLw  New  \\\n",
       "0          2003       196.0       706.0         0.0  ...      0      0    0   \n",
       "1          1976         0.0       978.0         0.0  ...      0      0    0   \n",
       "2          2002       162.0       486.0         0.0  ...      0      0    0   \n",
       "3          1970         0.0       216.0         0.0  ...      0      0    0   \n",
       "4          2000       350.0       655.0         0.0  ...      0      0    0   \n",
       "\n",
       "   Oth  WD  AdjLand  Alloca  Family  Normal  Partial  \n",
       "0    0   1        0       0       0       1        0  \n",
       "1    0   1        0       0       0       1        0  \n",
       "2    0   1        0       0       0       1        0  \n",
       "3    0   1        0       0       0       0        0  \n",
       "4    0   1        0       0       0       1        0  \n",
       "\n",
       "[5 rows x 175 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a857e422",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ameen\\AppData\\Local\\Temp\\ipykernel_12788\\191225162.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_Test.drop(['SalePrice'],axis=1,inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#Dropping the saleprice column because its values are NaN in test data anyway\n",
    "df_Test.drop(['SalePrice'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a4084542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 174)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a945ad5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=df_Train.drop(['SalePrice'],axis=1)\n",
    "Y_train=df_Train['SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92df8ae6",
   "metadata": {},
   "source": [
    "# Prediciton and choosing the proper Algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e22b9df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBRegressor\n",
    "classifier=xgboost.XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "599a422f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "             importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "             learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "             max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "             missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100, n_jobs=0,\n",
       "             num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=0.5, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "             importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "             learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "             max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "             missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=100, n_jobs=0,\n",
       "             num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "             importance_type=None, interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n",
       "             max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n",
       "             missing=nan, monotone_constraints='()', n_estimators=100, n_jobs=0,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, ...)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc7f6d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving as a pickle, so we won't train it again and again\n",
    "filename = 'Project_data/finalized_model.pkl'\n",
    "pickle.dump(classifier, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3ee4074",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([127646.5 , 144463.1 , 204446.92, ..., 153905.22, 105750.84,\n",
       "       233470.75], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred=classifier.predict(df_Test)\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e01b732e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df=pd.DataFrame(Y_pred) #Converting to DF\n",
    "submission_df=pd.read_csv('Project_data/sample_submission.csv') #Reading website's sample as csv\n",
    "datasets=pd.concat([submission_df['Id'],pred_df],axis=1) #Taking the ID from the submission after we deleted it at the beggning\n",
    "datasets.columns=['Id','SalePrice']\n",
    "datasets.to_csv('sample_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab61a6c6",
   "metadata": {},
   "source": [
    "# First Result\n",
    "Here we can see our first sumbit and its result scoring 0.143\n",
    "![First result](Results/XGBRegressor.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7b6f2651",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Regressor\n",
    "regressor = RandomForestRegressor(n_estimators = 100, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "62f570be",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = regressor.fit(X_train,Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c087ac83",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = regressor.predict(df_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ef7aa2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create Sample Submission file and Submit using ANN\n",
    "pred_df=pd.DataFrame(Y_pred) #Converting to DF\n",
    "submission_df=pd.read_csv('Project_data/sample_submission.csv') #Reading website's sample as csv\n",
    "datasets=pd.concat([submission_df['Id'],pred_df],axis=1) #Taking the ID from the submission after we deleted it at the beggning\n",
    "datasets.columns=['Id','SalePrice']\n",
    "datasets.to_csv('sample_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0bbba7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "reg = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "afea1a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = reg.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "82486548",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = reg.predict(df_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3ae2a339",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create Sample Submission file and Submit using ANN\n",
    "pred_df=pd.DataFrame(Y_pred) #Converting to DF\n",
    "submission_df=pd.read_csv('Project_data/sample_submission.csv') #Reading website's sample as csv\n",
    "datasets=pd.concat([submission_df['Id'],pred_df],axis=1) #Taking the ID from the submission after we deleted it at the beggning\n",
    "datasets.columns=['Id','SalePrice']\n",
    "datasets.to_csv('sample_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533385d6",
   "metadata": {},
   "source": [
    "# ML Results\n",
    "Here are the main results of the ML algorthims that have been applied above\n",
    "![ML results](Results/ML.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4523f2ed",
   "metadata": {},
   "source": [
    "# Improvments\n",
    "Imporving XGB results by hyper parameter optimization and randomized search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fad52049",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor=xgboost.XGBRegressor()\n",
    "booster=['gbtree','gblinear']\n",
    "base_score=[0.25,0.5,0.75,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0c3681a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hyper Parameter Optimization\n",
    "\n",
    "n_estimators = [100, 500, 900, 1100, 1500]\n",
    "max_depth = [2, 3, 5, 10, 15]\n",
    "booster=['gbtree','gblinear']\n",
    "learning_rate=[0.025,0.1,0.15,0.20]\n",
    "min_child_weight=[1,2,3,4]\n",
    "\n",
    "# Define the grid of hyperparameters to search\n",
    "hyperparameter_grid = {\n",
    "    'n_estimators': n_estimators,\n",
    "    'max_depth':max_depth,\n",
    "    'learning_rate':learning_rate,\n",
    "    'min_child_weight':min_child_weight,\n",
    "    'booster':booster,\n",
    "    'base_score':base_score\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6928fee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the random search with 4-fold cross validation\n",
    "random_cv = sklearn.model_selection.RandomizedSearchCV(estimator=regressor,\n",
    "            param_distributions=hyperparameter_grid,\n",
    "            cv=5, n_iter=50,\n",
    "            scoring = 'neg_mean_absolute_error',n_jobs = 4,\n",
    "            verbose = 5, \n",
    "            return_train_score = True,\n",
    "            random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "98683ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          callbacks=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None,\n",
       "                                          early_stopping_rounds=None,\n",
       "                                          enable_categorical=False,\n",
       "                                          eval_metric=None, gamma=None,\n",
       "                                          gpu_id=None, grow_policy=None,\n",
       "                                          importance_type=None,\n",
       "                                          interaction_constraints=None,\n",
       "                                          learning_rate=None, max_bin=None,\n",
       "                                          m...\n",
       "                                          reg_alpha=None, reg_lambda=None, ...),\n",
       "                   n_iter=50, n_jobs=4,\n",
       "                   param_distributions={&#x27;base_score&#x27;: [0.25, 0.5, 0.75, 1],\n",
       "                                        &#x27;booster&#x27;: [&#x27;gbtree&#x27;, &#x27;gblinear&#x27;],\n",
       "                                        &#x27;learning_rate&#x27;: [0.025, 0.1, 0.15,\n",
       "                                                          0.2],\n",
       "                                        &#x27;max_depth&#x27;: [2, 3, 5, 10, 15],\n",
       "                                        &#x27;min_child_weight&#x27;: [1, 2, 3, 4],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 500, 900, 1100,\n",
       "                                                         1500]},\n",
       "                   random_state=42, return_train_score=True,\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;, verbose=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          callbacks=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None,\n",
       "                                          early_stopping_rounds=None,\n",
       "                                          enable_categorical=False,\n",
       "                                          eval_metric=None, gamma=None,\n",
       "                                          gpu_id=None, grow_policy=None,\n",
       "                                          importance_type=None,\n",
       "                                          interaction_constraints=None,\n",
       "                                          learning_rate=None, max_bin=None,\n",
       "                                          m...\n",
       "                                          reg_alpha=None, reg_lambda=None, ...),\n",
       "                   n_iter=50, n_jobs=4,\n",
       "                   param_distributions={&#x27;base_score&#x27;: [0.25, 0.5, 0.75, 1],\n",
       "                                        &#x27;booster&#x27;: [&#x27;gbtree&#x27;, &#x27;gblinear&#x27;],\n",
       "                                        &#x27;learning_rate&#x27;: [0.025, 0.1, 0.15,\n",
       "                                                          0.2],\n",
       "                                        &#x27;max_depth&#x27;: [2, 3, 5, 10, 15],\n",
       "                                        &#x27;min_child_weight&#x27;: [1, 2, 3, 4],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 500, 900, 1100,\n",
       "                                                         1500]},\n",
       "                   random_state=42, return_train_score=True,\n",
       "                   scoring=&#x27;neg_mean_absolute_error&#x27;, verbose=5)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, gamma=None,\n",
       "             gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "             num_parallel_tree=None, predictor=None, random_state=None,\n",
       "             reg_alpha=None, reg_lambda=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, gamma=None,\n",
       "             gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "             max_leaves=None, min_child_weight=None, missing=nan,\n",
       "             monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "             num_parallel_tree=None, predictor=None, random_state=None,\n",
       "             reg_alpha=None, reg_lambda=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          callbacks=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None,\n",
       "                                          early_stopping_rounds=None,\n",
       "                                          enable_categorical=False,\n",
       "                                          eval_metric=None, gamma=None,\n",
       "                                          gpu_id=None, grow_policy=None,\n",
       "                                          importance_type=None,\n",
       "                                          interaction_constraints=None,\n",
       "                                          learning_rate=None, max_bin=None,\n",
       "                                          m...\n",
       "                                          reg_alpha=None, reg_lambda=None, ...),\n",
       "                   n_iter=50, n_jobs=4,\n",
       "                   param_distributions={'base_score': [0.25, 0.5, 0.75, 1],\n",
       "                                        'booster': ['gbtree', 'gblinear'],\n",
       "                                        'learning_rate': [0.025, 0.1, 0.15,\n",
       "                                                          0.2],\n",
       "                                        'max_depth': [2, 3, 5, 10, 15],\n",
       "                                        'min_child_weight': [1, 2, 3, 4],\n",
       "                                        'n_estimators': [100, 500, 900, 1100,\n",
       "                                                         1500]},\n",
       "                   random_state=42, return_train_score=True,\n",
       "                   scoring='neg_mean_absolute_error', verbose=5)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_cv.fit(X_train,Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e3b3525e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_esti=random_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c3d2ed21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=0.25, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "             importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "             learning_rate=0.1, max_bin=256, max_cat_to_onehot=4,\n",
       "             max_delta_step=0, max_depth=2, max_leaves=0, min_child_weight=1,\n",
       "             missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=900, n_jobs=0,\n",
       "             num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=0.25, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "             importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "             learning_rate=0.1, max_bin=256, max_cat_to_onehot=4,\n",
       "             max_delta_step=0, max_depth=2, max_leaves=0, min_child_weight=1,\n",
       "             missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=900, n_jobs=0,\n",
       "             num_parallel_tree=1, predictor=&#x27;auto&#x27;, random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=0.25, booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "             importance_type=None, interaction_constraints='',\n",
       "             learning_rate=0.1, max_bin=256, max_cat_to_onehot=4,\n",
       "             max_delta_step=0, max_depth=2, max_leaves=0, min_child_weight=1,\n",
       "             missing=nan, monotone_constraints='()', n_estimators=900, n_jobs=0,\n",
       "             num_parallel_tree=1, predictor='auto', random_state=0, reg_alpha=0,\n",
       "             reg_lambda=1, ...)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_esti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8d12d3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor=xgboost.XGBRegressor(base_score=0.25, booster='gbtree',callbacks=None, colsample_bylevel=1,colsample_bynode=1,\n",
    "       colsample_bytree=1,early_stopping_rounds=None, enable_categorical=False,\n",
    "                              eval_metric=None,  gamma=0,gpu_id=-1,grow_policy='depthwise',importance_type=None,interaction_constraints='',\n",
    "                               learning_rate=0.1,max_bin=256, max_cat_to_onehot=4, max_delta_step=0,\n",
    "       max_depth=2,max_leaves=0, min_child_weight=1,monotone_constraints='()', n_estimators=900,\n",
    "       n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "       silent=True, subsample=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4e8b1c79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:59:33] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/objective/regression_obj.cu:203: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[16:59:33] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(base_score=0.25, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "             importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "             learning_rate=0.1, max_bin=256, max_cat_to_onehot=4,\n",
       "             max_delta_step=0, max_depth=2, max_leaves=0, min_child_weight=1,\n",
       "             missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=900, n_jobs=1,\n",
       "             nthread=1, num_parallel_tree=1, objective=&#x27;reg:linear&#x27;,\n",
       "             predictor=&#x27;auto&#x27;, random_state=0, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=0.25, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy=&#x27;depthwise&#x27;,\n",
       "             importance_type=None, interaction_constraints=&#x27;&#x27;,\n",
       "             learning_rate=0.1, max_bin=256, max_cat_to_onehot=4,\n",
       "             max_delta_step=0, max_depth=2, max_leaves=0, min_child_weight=1,\n",
       "             missing=nan, monotone_constraints=&#x27;()&#x27;, n_estimators=900, n_jobs=1,\n",
       "             nthread=1, num_parallel_tree=1, objective=&#x27;reg:linear&#x27;,\n",
       "             predictor=&#x27;auto&#x27;, random_state=0, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(base_score=0.25, booster='gbtree', callbacks=None,\n",
       "             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "             early_stopping_rounds=None, enable_categorical=False,\n",
       "             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n",
       "             importance_type=None, interaction_constraints='',\n",
       "             learning_rate=0.1, max_bin=256, max_cat_to_onehot=4,\n",
       "             max_delta_step=0, max_depth=2, max_leaves=0, min_child_weight=1,\n",
       "             missing=nan, monotone_constraints='()', n_estimators=900, n_jobs=1,\n",
       "             nthread=1, num_parallel_tree=1, objective='reg:linear',\n",
       "             predictor='auto', random_state=0, ...)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "927e2ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'finalized_model.pkl'\n",
    "pickle.dump(classifier, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "86ea7d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = regressor.predict(df_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "92aa7d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df=pd.DataFrame(Y_pred) #Converting to DF\n",
    "submission_df=pd.read_csv('Project_data/sample_submission.csv') #Reading website's sample as csv\n",
    "datasets=pd.concat([submission_df['Id'],pred_df],axis=1) #Taking the ID from the submission after we deleted it at the beggning\n",
    "datasets.columns=['Id','SalePrice']\n",
    "datasets.to_csv('sample_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625f4e2d",
   "metadata": {},
   "source": [
    "# Artifical Neural Network\n",
    "Using ANN as well to imporve the precision of the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8ee22a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "114/114 [==============================] - 1s 2ms/step - loss: 35231068160.0000 - val_loss: 28340922368.0000\n",
      "Epoch 2/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 16063160320.0000 - val_loss: 8699286528.0000\n",
      "Epoch 3/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 7325543936.0000 - val_loss: 5637751296.0000\n",
      "Epoch 4/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 6109664768.0000 - val_loss: 5244301312.0000\n",
      "Epoch 5/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 5698206720.0000 - val_loss: 5069890048.0000\n",
      "Epoch 6/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 5425005568.0000 - val_loss: 4964805120.0000\n",
      "Epoch 7/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 5160585728.0000 - val_loss: 4863338496.0000\n",
      "Epoch 8/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 4930681856.0000 - val_loss: 4769006592.0000\n",
      "Epoch 9/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 4709648384.0000 - val_loss: 4681617408.0000\n",
      "Epoch 10/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 4501511680.0000 - val_loss: 4596557824.0000\n",
      "Epoch 11/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 4308263424.0000 - val_loss: 4513755136.0000\n",
      "Epoch 12/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 4139278592.0000 - val_loss: 4428951552.0000\n",
      "Epoch 13/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 3954651392.0000 - val_loss: 4341655552.0000\n",
      "Epoch 14/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 3796240640.0000 - val_loss: 4272425216.0000\n",
      "Epoch 15/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 3668214272.0000 - val_loss: 4197373440.0000\n",
      "Epoch 16/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 3522062848.0000 - val_loss: 4134363136.0000\n",
      "Epoch 17/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 3380782848.0000 - val_loss: 4046250240.0000\n",
      "Epoch 18/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 3255152128.0000 - val_loss: 3963322368.0000\n",
      "Epoch 19/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 3103327232.0000 - val_loss: 3905527552.0000\n",
      "Epoch 20/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 2993828352.0000 - val_loss: 3808254208.0000\n",
      "Epoch 21/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 2873559040.0000 - val_loss: 3732029440.0000\n",
      "Epoch 22/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 2748863232.0000 - val_loss: 3674559232.0000\n",
      "Epoch 23/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 2641064448.0000 - val_loss: 3643084800.0000\n",
      "Epoch 24/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 2530377472.0000 - val_loss: 3512404224.0000\n",
      "Epoch 25/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 2405443840.0000 - val_loss: 3479886592.0000\n",
      "Epoch 26/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 2306492928.0000 - val_loss: 3390369280.0000\n",
      "Epoch 27/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 2210108160.0000 - val_loss: 3333088000.0000\n",
      "Epoch 28/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 2132737920.0000 - val_loss: 3278388480.0000\n",
      "Epoch 29/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 2038363264.0000 - val_loss: 3295074048.0000\n",
      "Epoch 30/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1958809600.0000 - val_loss: 3255150848.0000\n",
      "Epoch 31/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1878537472.0000 - val_loss: 3277694976.0000\n",
      "Epoch 32/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1815514240.0000 - val_loss: 3207298048.0000\n",
      "Epoch 33/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1768534912.0000 - val_loss: 3241243904.0000\n",
      "Epoch 34/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1727287680.0000 - val_loss: 3216027392.0000\n",
      "Epoch 35/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1693689728.0000 - val_loss: 3272048640.0000\n",
      "Epoch 36/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1665372416.0000 - val_loss: 3354769152.0000\n",
      "Epoch 37/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1650393344.0000 - val_loss: 3381916416.0000\n",
      "Epoch 38/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1615522176.0000 - val_loss: 3273372160.0000\n",
      "Epoch 39/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1615801216.0000 - val_loss: 3367220480.0000\n",
      "Epoch 40/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1610748800.0000 - val_loss: 3355147520.0000\n",
      "Epoch 41/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1613074304.0000 - val_loss: 3526749952.0000\n",
      "Epoch 42/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1605971328.0000 - val_loss: 3446277632.0000\n",
      "Epoch 43/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1595867392.0000 - val_loss: 3404355328.0000\n",
      "Epoch 44/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1591857408.0000 - val_loss: 3434679552.0000\n",
      "Epoch 45/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1586246784.0000 - val_loss: 3366229248.0000\n",
      "Epoch 46/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1596108416.0000 - val_loss: 3474787328.0000\n",
      "Epoch 47/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1580818176.0000 - val_loss: 3370060288.0000\n",
      "Epoch 48/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1576810368.0000 - val_loss: 3411000832.0000\n",
      "Epoch 49/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1574689280.0000 - val_loss: 3382902528.0000\n",
      "Epoch 50/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1575013888.0000 - val_loss: 3452550656.0000\n",
      "Epoch 51/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1571824384.0000 - val_loss: 3506673664.0000\n",
      "Epoch 52/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1552754048.0000 - val_loss: 3354137088.0000\n",
      "Epoch 53/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1556422528.0000 - val_loss: 3548418304.0000\n",
      "Epoch 54/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1566029056.0000 - val_loss: 3385043968.0000\n",
      "Epoch 55/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1558952960.0000 - val_loss: 3429820672.0000\n",
      "Epoch 56/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1569525376.0000 - val_loss: 3390686464.0000\n",
      "Epoch 57/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1554909312.0000 - val_loss: 3400715520.0000\n",
      "Epoch 58/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1541541888.0000 - val_loss: 3329647616.0000\n",
      "Epoch 59/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1551153664.0000 - val_loss: 3389914112.0000\n",
      "Epoch 60/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1553360512.0000 - val_loss: 3414464512.0000\n",
      "Epoch 61/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1536886656.0000 - val_loss: 3501441024.0000\n",
      "Epoch 62/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1536570368.0000 - val_loss: 3458218752.0000\n",
      "Epoch 63/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1536198016.0000 - val_loss: 3473132032.0000\n",
      "Epoch 64/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1524061952.0000 - val_loss: 3507318016.0000\n",
      "Epoch 65/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1537692672.0000 - val_loss: 3357760768.0000\n",
      "Epoch 66/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1528145920.0000 - val_loss: 3419680512.0000\n",
      "Epoch 67/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1518553856.0000 - val_loss: 3317422080.0000\n",
      "Epoch 68/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1524718080.0000 - val_loss: 3402862080.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1528498688.0000 - val_loss: 3398163712.0000\n",
      "Epoch 70/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1525514624.0000 - val_loss: 3331622912.0000\n",
      "Epoch 71/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1512727424.0000 - val_loss: 3345656064.0000\n",
      "Epoch 72/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1516230272.0000 - val_loss: 3444244224.0000\n",
      "Epoch 73/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1517529216.0000 - val_loss: 3397200896.0000\n",
      "Epoch 74/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1513115264.0000 - val_loss: 3462404864.0000\n",
      "Epoch 75/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1506126720.0000 - val_loss: 3406097920.0000\n",
      "Epoch 76/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1502285440.0000 - val_loss: 3396726016.0000\n",
      "Epoch 77/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1502357888.0000 - val_loss: 3348518144.0000\n",
      "Epoch 78/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1496462720.0000 - val_loss: 3362456832.0000\n",
      "Epoch 79/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1500721280.0000 - val_loss: 3408728832.0000\n",
      "Epoch 80/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1506931072.0000 - val_loss: 3423586560.0000\n",
      "Epoch 81/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1495016960.0000 - val_loss: 3398369280.0000\n",
      "Epoch 82/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1487828480.0000 - val_loss: 3443723776.0000\n",
      "Epoch 83/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1508256512.0000 - val_loss: 3407215616.0000\n",
      "Epoch 84/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1491410688.0000 - val_loss: 3363792384.0000\n",
      "Epoch 85/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1490525056.0000 - val_loss: 3329799424.0000\n",
      "Epoch 86/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1490863488.0000 - val_loss: 3354567936.0000\n",
      "Epoch 87/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1500598912.0000 - val_loss: 3471843072.0000\n",
      "Epoch 88/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1481732352.0000 - val_loss: 3416786944.0000\n",
      "Epoch 89/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1484990464.0000 - val_loss: 3356127488.0000\n",
      "Epoch 90/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1478258560.0000 - val_loss: 3352748288.0000\n",
      "Epoch 91/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1470212480.0000 - val_loss: 3471171328.0000\n",
      "Epoch 92/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1486299008.0000 - val_loss: 3375896576.0000\n",
      "Epoch 93/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1483666944.0000 - val_loss: 3414852864.0000\n",
      "Epoch 94/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1471031424.0000 - val_loss: 3437179136.0000\n",
      "Epoch 95/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1482947712.0000 - val_loss: 3510022144.0000\n",
      "Epoch 96/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1476297472.0000 - val_loss: 3414485248.0000\n",
      "Epoch 97/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1462168960.0000 - val_loss: 3408017152.0000\n",
      "Epoch 98/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1470356992.0000 - val_loss: 3394927872.0000\n",
      "Epoch 99/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1467479808.0000 - val_loss: 3359314176.0000\n",
      "Epoch 100/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1460273280.0000 - val_loss: 3391056384.0000\n",
      "Epoch 101/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1455756544.0000 - val_loss: 3383797760.0000\n",
      "Epoch 102/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1452537984.0000 - val_loss: 3337844992.0000\n",
      "Epoch 103/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1450438528.0000 - val_loss: 3303867904.0000\n",
      "Epoch 104/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1460982656.0000 - val_loss: 3543968000.0000\n",
      "Epoch 105/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1462338432.0000 - val_loss: 3372559360.0000\n",
      "Epoch 106/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1444132992.0000 - val_loss: 3365404416.0000\n",
      "Epoch 107/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1446499072.0000 - val_loss: 3373632256.0000\n",
      "Epoch 108/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1442118016.0000 - val_loss: 3379324416.0000\n",
      "Epoch 109/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1443716736.0000 - val_loss: 3360890112.0000\n",
      "Epoch 110/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1448508416.0000 - val_loss: 3384374528.0000\n",
      "Epoch 111/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1444069120.0000 - val_loss: 3369090816.0000\n",
      "Epoch 112/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1441165184.0000 - val_loss: 3384286208.0000\n",
      "Epoch 113/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1434474624.0000 - val_loss: 3334520064.0000\n",
      "Epoch 114/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1438557696.0000 - val_loss: 3446977536.0000\n",
      "Epoch 115/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1428925440.0000 - val_loss: 3496273408.0000\n",
      "Epoch 116/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1438605568.0000 - val_loss: 3357818624.0000\n",
      "Epoch 117/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1442216960.0000 - val_loss: 3372957440.0000\n",
      "Epoch 118/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1425299584.0000 - val_loss: 3354119680.0000\n",
      "Epoch 119/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1428614912.0000 - val_loss: 3474905088.0000\n",
      "Epoch 120/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1424483200.0000 - val_loss: 3353123328.0000\n",
      "Epoch 121/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1425511424.0000 - val_loss: 3402275584.0000\n",
      "Epoch 122/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1420097280.0000 - val_loss: 3434914560.0000\n",
      "Epoch 123/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1419777536.0000 - val_loss: 3312439040.0000\n",
      "Epoch 124/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1423974784.0000 - val_loss: 3429812992.0000\n",
      "Epoch 125/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1415506560.0000 - val_loss: 3469281536.0000\n",
      "Epoch 126/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1414506112.0000 - val_loss: 3382944512.0000\n",
      "Epoch 127/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1417203200.0000 - val_loss: 3385348096.0000\n",
      "Epoch 128/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1409980032.0000 - val_loss: 3385771008.0000\n",
      "Epoch 129/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1410759808.0000 - val_loss: 3342109952.0000\n",
      "Epoch 130/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1412244096.0000 - val_loss: 3408713984.0000\n",
      "Epoch 131/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1399338240.0000 - val_loss: 3308251136.0000\n",
      "Epoch 132/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1408485632.0000 - val_loss: 3347085824.0000\n",
      "Epoch 133/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1420478080.0000 - val_loss: 3382881280.0000\n",
      "Epoch 134/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1398381056.0000 - val_loss: 3420494080.0000\n",
      "Epoch 135/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1397780992.0000 - val_loss: 3365019648.0000\n",
      "Epoch 136/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 1404820608.0000 - val_loss: 3420774656.0000\n",
      "Epoch 137/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1386673536.0000 - val_loss: 3345494528.0000\n",
      "Epoch 138/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1385448064.0000 - val_loss: 3432960512.0000\n",
      "Epoch 139/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1390137472.0000 - val_loss: 3369110784.0000\n",
      "Epoch 140/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1394634496.0000 - val_loss: 3307261696.0000\n",
      "Epoch 141/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1394055680.0000 - val_loss: 3303185152.0000\n",
      "Epoch 142/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1385116288.0000 - val_loss: 3404316160.0000\n",
      "Epoch 143/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1383651840.0000 - val_loss: 3318200576.0000\n",
      "Epoch 144/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1384873344.0000 - val_loss: 3343660288.0000\n",
      "Epoch 145/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1395365888.0000 - val_loss: 3415834880.0000\n",
      "Epoch 146/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1377891328.0000 - val_loss: 3368103680.0000\n",
      "Epoch 147/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1378628864.0000 - val_loss: 3365571072.0000\n",
      "Epoch 148/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1372613248.0000 - val_loss: 3443835136.0000\n",
      "Epoch 149/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1382863488.0000 - val_loss: 3408726016.0000\n",
      "Epoch 150/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1360887552.0000 - val_loss: 3507834368.0000\n",
      "Epoch 151/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1390548352.0000 - val_loss: 3407469568.0000\n",
      "Epoch 152/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1382011008.0000 - val_loss: 3378495488.0000\n",
      "Epoch 153/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1369382144.0000 - val_loss: 3393051648.0000\n",
      "Epoch 154/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1368012800.0000 - val_loss: 3486804480.0000\n",
      "Epoch 155/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1365523328.0000 - val_loss: 3413172736.0000\n",
      "Epoch 156/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1364828288.0000 - val_loss: 3280884736.0000\n",
      "Epoch 157/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1367455232.0000 - val_loss: 3299200256.0000\n",
      "Epoch 158/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1362906752.0000 - val_loss: 3359030272.0000\n",
      "Epoch 159/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1359397632.0000 - val_loss: 3389525248.0000\n",
      "Epoch 160/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1356080256.0000 - val_loss: 3325338624.0000\n",
      "Epoch 161/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1361152000.0000 - val_loss: 3426710784.0000\n",
      "Epoch 162/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1352693888.0000 - val_loss: 3357461760.0000\n",
      "Epoch 163/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1354926592.0000 - val_loss: 3313874688.0000\n",
      "Epoch 164/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1352468352.0000 - val_loss: 3442288384.0000\n",
      "Epoch 165/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1366686208.0000 - val_loss: 3405495296.0000\n",
      "Epoch 166/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1356299520.0000 - val_loss: 3324176384.0000\n",
      "Epoch 167/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1350487552.0000 - val_loss: 3300911616.0000\n",
      "Epoch 168/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1343411968.0000 - val_loss: 3407496448.0000\n",
      "Epoch 169/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1348762752.0000 - val_loss: 3301067264.0000\n",
      "Epoch 170/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1330431744.0000 - val_loss: 3530325504.0000\n",
      "Epoch 171/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1344462464.0000 - val_loss: 3287594752.0000\n",
      "Epoch 172/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1344856192.0000 - val_loss: 3353297664.0000\n",
      "Epoch 173/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1350929152.0000 - val_loss: 3310277376.0000\n",
      "Epoch 174/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1341335808.0000 - val_loss: 3237498368.0000\n",
      "Epoch 175/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1337870720.0000 - val_loss: 3334075136.0000\n",
      "Epoch 176/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1330360576.0000 - val_loss: 3317678592.0000\n",
      "Epoch 177/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1321426432.0000 - val_loss: 3239048192.0000\n",
      "Epoch 178/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1340130304.0000 - val_loss: 3345173504.0000\n",
      "Epoch 179/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1340850432.0000 - val_loss: 3310583296.0000\n",
      "Epoch 180/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1334861952.0000 - val_loss: 3313303808.0000\n",
      "Epoch 181/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1320008448.0000 - val_loss: 3284889856.0000\n",
      "Epoch 182/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1336019072.0000 - val_loss: 3317708800.0000\n",
      "Epoch 183/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1321738112.0000 - val_loss: 3278731520.0000\n",
      "Epoch 184/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1326094720.0000 - val_loss: 3394647040.0000\n",
      "Epoch 185/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1325613568.0000 - val_loss: 3310633472.0000\n",
      "Epoch 186/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1319388928.0000 - val_loss: 3225337856.0000\n",
      "Epoch 187/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1318718464.0000 - val_loss: 3274887680.0000\n",
      "Epoch 188/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1311492736.0000 - val_loss: 3255428352.0000\n",
      "Epoch 189/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1313462912.0000 - val_loss: 3262426112.0000\n",
      "Epoch 190/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1307734528.0000 - val_loss: 3340187904.0000\n",
      "Epoch 191/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1308250496.0000 - val_loss: 3361968384.0000\n",
      "Epoch 192/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1311058816.0000 - val_loss: 3228648192.0000\n",
      "Epoch 193/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1304611840.0000 - val_loss: 3192829696.0000\n",
      "Epoch 194/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1309420544.0000 - val_loss: 3335288832.0000\n",
      "Epoch 195/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1315716352.0000 - val_loss: 3287027968.0000\n",
      "Epoch 196/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1304811392.0000 - val_loss: 3233335552.0000\n",
      "Epoch 197/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1298851456.0000 - val_loss: 3312572416.0000\n",
      "Epoch 198/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1299645184.0000 - val_loss: 3396427776.0000\n",
      "Epoch 199/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 1300032000.0000 - val_loss: 3209338624.0000\n",
      "Epoch 200/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1308162688.0000 - val_loss: 3265357056.0000\n",
      "Epoch 201/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1297721088.0000 - val_loss: 3285096960.0000\n",
      "Epoch 202/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1296160000.0000 - val_loss: 3252057600.0000\n",
      "Epoch 203/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 1297743232.0000 - val_loss: 3257401344.0000\n",
      "Epoch 204/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1293548544.0000 - val_loss: 3206170880.0000\n",
      "Epoch 205/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1296825728.0000 - val_loss: 3173942016.0000\n",
      "Epoch 206/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1297661568.0000 - val_loss: 3134750720.0000\n",
      "Epoch 207/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1284455168.0000 - val_loss: 3230053376.0000\n",
      "Epoch 208/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1274730112.0000 - val_loss: 3142745344.0000\n",
      "Epoch 209/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1289546112.0000 - val_loss: 3187422976.0000\n",
      "Epoch 210/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1292110848.0000 - val_loss: 3139926272.0000\n",
      "Epoch 211/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1290373632.0000 - val_loss: 3113133056.0000\n",
      "Epoch 212/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1301706240.0000 - val_loss: 3142023424.0000\n",
      "Epoch 213/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1272622976.0000 - val_loss: 3266889984.0000\n",
      "Epoch 214/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1269582720.0000 - val_loss: 3276815104.0000\n",
      "Epoch 215/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1273442304.0000 - val_loss: 3164564736.0000\n",
      "Epoch 216/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1271081600.0000 - val_loss: 3137559296.0000\n",
      "Epoch 217/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1264289536.0000 - val_loss: 3260933376.0000\n",
      "Epoch 218/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1268087936.0000 - val_loss: 3169096448.0000\n",
      "Epoch 219/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1263223424.0000 - val_loss: 3193409024.0000\n",
      "Epoch 220/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1265038336.0000 - val_loss: 3140594688.0000\n",
      "Epoch 221/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1260891264.0000 - val_loss: 3152986368.0000\n",
      "Epoch 222/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1268956672.0000 - val_loss: 3117546496.0000\n",
      "Epoch 223/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1260827392.0000 - val_loss: 3109492480.0000\n",
      "Epoch 224/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1266848896.0000 - val_loss: 3098499584.0000\n",
      "Epoch 225/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1258052224.0000 - val_loss: 3094235392.0000\n",
      "Epoch 226/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1263854464.0000 - val_loss: 3149541120.0000\n",
      "Epoch 227/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1254126848.0000 - val_loss: 3271992064.0000\n",
      "Epoch 228/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1269836672.0000 - val_loss: 3200849152.0000\n",
      "Epoch 229/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1256454656.0000 - val_loss: 3243279872.0000\n",
      "Epoch 230/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1245379456.0000 - val_loss: 3062848768.0000\n",
      "Epoch 231/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1251230720.0000 - val_loss: 3235920128.0000\n",
      "Epoch 232/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1257716992.0000 - val_loss: 3106660096.0000\n",
      "Epoch 233/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1247050368.0000 - val_loss: 3128571904.0000\n",
      "Epoch 234/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1244153344.0000 - val_loss: 3093452544.0000\n",
      "Epoch 235/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1245383680.0000 - val_loss: 3039936512.0000\n",
      "Epoch 236/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1255186432.0000 - val_loss: 3152058880.0000\n",
      "Epoch 237/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1240548480.0000 - val_loss: 3163776256.0000\n",
      "Epoch 238/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1251114112.0000 - val_loss: 3169461760.0000\n",
      "Epoch 239/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1244392320.0000 - val_loss: 3057118208.0000\n",
      "Epoch 240/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1244447872.0000 - val_loss: 3137227264.0000\n",
      "Epoch 241/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1244359808.0000 - val_loss: 3109521152.0000\n",
      "Epoch 242/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1234805120.0000 - val_loss: 3042526208.0000\n",
      "Epoch 243/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1229731712.0000 - val_loss: 3019314176.0000\n",
      "Epoch 244/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1236512128.0000 - val_loss: 3131040256.0000\n",
      "Epoch 245/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1234744192.0000 - val_loss: 3065119488.0000\n",
      "Epoch 246/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1233336064.0000 - val_loss: 3033639936.0000\n",
      "Epoch 247/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1234801408.0000 - val_loss: 3109716736.0000\n",
      "Epoch 248/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1234921728.0000 - val_loss: 3070130432.0000\n",
      "Epoch 249/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1223807360.0000 - val_loss: 3048108800.0000\n",
      "Epoch 250/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1224832512.0000 - val_loss: 3097595648.0000\n",
      "Epoch 251/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1230938880.0000 - val_loss: 3068998400.0000\n",
      "Epoch 252/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1218316032.0000 - val_loss: 3092882432.0000\n",
      "Epoch 253/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1217512576.0000 - val_loss: 3011817984.0000\n",
      "Epoch 254/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1227308928.0000 - val_loss: 3049671680.0000\n",
      "Epoch 255/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1230349696.0000 - val_loss: 3050451712.0000\n",
      "Epoch 256/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1225992448.0000 - val_loss: 3134619392.0000\n",
      "Epoch 257/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1226200960.0000 - val_loss: 3144104448.0000\n",
      "Epoch 258/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1217627520.0000 - val_loss: 3088343808.0000\n",
      "Epoch 259/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1224439936.0000 - val_loss: 3016763904.0000\n",
      "Epoch 260/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1212237440.0000 - val_loss: 3106755072.0000\n",
      "Epoch 261/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1214680832.0000 - val_loss: 3176101888.0000\n",
      "Epoch 262/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1229738368.0000 - val_loss: 3072613888.0000\n",
      "Epoch 263/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1202085120.0000 - val_loss: 3132157440.0000\n",
      "Epoch 264/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1212263168.0000 - val_loss: 3004091136.0000\n",
      "Epoch 265/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1211852800.0000 - val_loss: 3115437056.0000\n",
      "Epoch 266/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1200717952.0000 - val_loss: 2971137024.0000\n",
      "Epoch 267/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1204846592.0000 - val_loss: 3009640192.0000\n",
      "Epoch 268/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1200813440.0000 - val_loss: 3061708800.0000\n",
      "Epoch 269/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1211491328.0000 - val_loss: 3039549440.0000\n",
      "Epoch 270/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 1203327744.0000 - val_loss: 3021888256.0000\n",
      "Epoch 271/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1201015040.0000 - val_loss: 3026401280.0000\n",
      "Epoch 272/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1197776896.0000 - val_loss: 3073122304.0000\n",
      "Epoch 273/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1196908672.0000 - val_loss: 2940484352.0000\n",
      "Epoch 274/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1196905344.0000 - val_loss: 2971416064.0000\n",
      "Epoch 275/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1197462656.0000 - val_loss: 2992559872.0000\n",
      "Epoch 276/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1198453504.0000 - val_loss: 2996659456.0000\n",
      "Epoch 277/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1190181888.0000 - val_loss: 3047567616.0000\n",
      "Epoch 278/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1185062528.0000 - val_loss: 3003378688.0000\n",
      "Epoch 279/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1188636928.0000 - val_loss: 2942737920.0000\n",
      "Epoch 280/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1199109632.0000 - val_loss: 2996762112.0000\n",
      "Epoch 281/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1184976384.0000 - val_loss: 3001485824.0000\n",
      "Epoch 282/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1184155392.0000 - val_loss: 2968256768.0000\n",
      "Epoch 283/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1181980928.0000 - val_loss: 2927719424.0000\n",
      "Epoch 284/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1183353344.0000 - val_loss: 3002662144.0000\n",
      "Epoch 285/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1182413184.0000 - val_loss: 2954898432.0000\n",
      "Epoch 286/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1182170240.0000 - val_loss: 3009487616.0000\n",
      "Epoch 287/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1191384832.0000 - val_loss: 2964494336.0000\n",
      "Epoch 288/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1176129152.0000 - val_loss: 2992010240.0000\n",
      "Epoch 289/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1173092096.0000 - val_loss: 3033882880.0000\n",
      "Epoch 290/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1186616832.0000 - val_loss: 3049141504.0000\n",
      "Epoch 291/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1193446528.0000 - val_loss: 3041552384.0000\n",
      "Epoch 292/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1176534144.0000 - val_loss: 3042299136.0000\n",
      "Epoch 293/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1179090304.0000 - val_loss: 2930870528.0000\n",
      "Epoch 294/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1184256896.0000 - val_loss: 2940549120.0000\n",
      "Epoch 295/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1175988352.0000 - val_loss: 2941075200.0000\n",
      "Epoch 296/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1168355072.0000 - val_loss: 3061400064.0000\n",
      "Epoch 297/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1166119808.0000 - val_loss: 2969309952.0000\n",
      "Epoch 298/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1177049216.0000 - val_loss: 3041126400.0000\n",
      "Epoch 299/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1161194368.0000 - val_loss: 2893956864.0000\n",
      "Epoch 300/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1170952448.0000 - val_loss: 2936515584.0000\n",
      "Epoch 301/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1166195968.0000 - val_loss: 2948434176.0000\n",
      "Epoch 302/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1168086272.0000 - val_loss: 2920814336.0000\n",
      "Epoch 303/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1158103808.0000 - val_loss: 2987056384.0000\n",
      "Epoch 304/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1162851968.0000 - val_loss: 2882716672.0000\n",
      "Epoch 305/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1167587584.0000 - val_loss: 2893932288.0000\n",
      "Epoch 306/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1156748160.0000 - val_loss: 2956478464.0000\n",
      "Epoch 307/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1152748672.0000 - val_loss: 2877020672.0000\n",
      "Epoch 308/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1150532736.0000 - val_loss: 2996449792.0000\n",
      "Epoch 309/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1164215040.0000 - val_loss: 2868200704.0000\n",
      "Epoch 310/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1153829760.0000 - val_loss: 2912743936.0000\n",
      "Epoch 311/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1143803008.0000 - val_loss: 2980934656.0000\n",
      "Epoch 312/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1148453888.0000 - val_loss: 2862420992.0000\n",
      "Epoch 313/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1147466624.0000 - val_loss: 2927408896.0000\n",
      "Epoch 314/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1145308288.0000 - val_loss: 2952954112.0000\n",
      "Epoch 315/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1160416896.0000 - val_loss: 3002713344.0000\n",
      "Epoch 316/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1148998784.0000 - val_loss: 2927617536.0000\n",
      "Epoch 317/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1151257088.0000 - val_loss: 2885223168.0000\n",
      "Epoch 318/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1150604288.0000 - val_loss: 2869671168.0000\n",
      "Epoch 319/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1131462784.0000 - val_loss: 3013728768.0000\n",
      "Epoch 320/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1141369088.0000 - val_loss: 2862667520.0000\n",
      "Epoch 321/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1141941504.0000 - val_loss: 2848528128.0000\n",
      "Epoch 322/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1133959296.0000 - val_loss: 2844587776.0000\n",
      "Epoch 323/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1122535808.0000 - val_loss: 2965683712.0000\n",
      "Epoch 324/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1136221056.0000 - val_loss: 2986422784.0000\n",
      "Epoch 325/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1149117184.0000 - val_loss: 2944734976.0000\n",
      "Epoch 326/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1128104064.0000 - val_loss: 2872912640.0000\n",
      "Epoch 327/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1128682240.0000 - val_loss: 2911791104.0000\n",
      "Epoch 328/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1131902208.0000 - val_loss: 2900082176.0000\n",
      "Epoch 329/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1145347840.0000 - val_loss: 2886177536.0000\n",
      "Epoch 330/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1129693952.0000 - val_loss: 3078912256.0000\n",
      "Epoch 331/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1139329408.0000 - val_loss: 2876638720.0000\n",
      "Epoch 332/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1130118784.0000 - val_loss: 2824288768.0000\n",
      "Epoch 333/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1116491904.0000 - val_loss: 2920283136.0000\n",
      "Epoch 334/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1129157760.0000 - val_loss: 2908948736.0000\n",
      "Epoch 335/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1125805440.0000 - val_loss: 2861357056.0000\n",
      "Epoch 336/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1118039552.0000 - val_loss: 2836748800.0000\n",
      "Epoch 337/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 1111671040.0000 - val_loss: 2950494976.0000\n",
      "Epoch 338/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1123438080.0000 - val_loss: 2889466112.0000\n",
      "Epoch 339/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1118772736.0000 - val_loss: 2809351424.0000\n",
      "Epoch 340/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1117126016.0000 - val_loss: 2889188352.0000\n",
      "Epoch 341/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1119716736.0000 - val_loss: 2802912000.0000\n",
      "Epoch 342/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1124610176.0000 - val_loss: 2806353152.0000\n",
      "Epoch 343/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1111903232.0000 - val_loss: 2825373184.0000\n",
      "Epoch 344/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1111171712.0000 - val_loss: 2811439872.0000\n",
      "Epoch 345/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1113245056.0000 - val_loss: 2808130816.0000\n",
      "Epoch 346/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1105943424.0000 - val_loss: 2777050624.0000\n",
      "Epoch 347/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1107251712.0000 - val_loss: 2841701376.0000\n",
      "Epoch 348/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1101827072.0000 - val_loss: 2739093248.0000\n",
      "Epoch 349/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1109437056.0000 - val_loss: 2909863168.0000\n",
      "Epoch 350/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1109676416.0000 - val_loss: 2772257024.0000\n",
      "Epoch 351/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1104895744.0000 - val_loss: 2958622208.0000\n",
      "Epoch 352/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1120488704.0000 - val_loss: 2791064320.0000\n",
      "Epoch 353/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1101003136.0000 - val_loss: 2785122048.0000\n",
      "Epoch 354/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1100166016.0000 - val_loss: 2839789824.0000\n",
      "Epoch 355/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1101742976.0000 - val_loss: 2791065344.0000\n",
      "Epoch 356/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1099032448.0000 - val_loss: 2816398848.0000\n",
      "Epoch 357/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1101399808.0000 - val_loss: 2853888256.0000\n",
      "Epoch 358/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1102892928.0000 - val_loss: 2740952832.0000\n",
      "Epoch 359/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1096281856.0000 - val_loss: 2760980224.0000\n",
      "Epoch 360/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1109404032.0000 - val_loss: 2776120576.0000\n",
      "Epoch 361/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1095569664.0000 - val_loss: 2884426240.0000\n",
      "Epoch 362/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1098313472.0000 - val_loss: 2807203840.0000\n",
      "Epoch 363/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1088682240.0000 - val_loss: 2780519168.0000\n",
      "Epoch 364/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1089933952.0000 - val_loss: 2776727552.0000\n",
      "Epoch 365/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1091690368.0000 - val_loss: 2760888320.0000\n",
      "Epoch 366/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1077516544.0000 - val_loss: 2721160704.0000\n",
      "Epoch 367/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1092951936.0000 - val_loss: 2777017088.0000\n",
      "Epoch 368/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1100469632.0000 - val_loss: 2816915712.0000\n",
      "Epoch 369/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1087158784.0000 - val_loss: 2832217088.0000\n",
      "Epoch 370/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1079471232.0000 - val_loss: 2737910784.0000\n",
      "Epoch 371/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1075853440.0000 - val_loss: 2776425472.0000\n",
      "Epoch 372/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1079353472.0000 - val_loss: 2790182912.0000\n",
      "Epoch 373/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1082735232.0000 - val_loss: 2739498752.0000\n",
      "Epoch 374/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1086419200.0000 - val_loss: 2776022784.0000\n",
      "Epoch 375/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1075205632.0000 - val_loss: 2840798720.0000\n",
      "Epoch 376/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1081135488.0000 - val_loss: 2693547008.0000\n",
      "Epoch 377/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1081340416.0000 - val_loss: 2729277696.0000\n",
      "Epoch 378/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1073607616.0000 - val_loss: 2776930048.0000\n",
      "Epoch 379/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1086590976.0000 - val_loss: 2789179904.0000\n",
      "Epoch 380/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1084099328.0000 - val_loss: 2711700224.0000\n",
      "Epoch 381/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1065009216.0000 - val_loss: 2763186176.0000\n",
      "Epoch 382/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1071764544.0000 - val_loss: 2665925632.0000\n",
      "Epoch 383/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1058093632.0000 - val_loss: 2687820288.0000\n",
      "Epoch 384/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1076201728.0000 - val_loss: 2729202944.0000\n",
      "Epoch 385/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1058797632.0000 - val_loss: 2680554752.0000\n",
      "Epoch 386/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1061547840.0000 - val_loss: 2678740480.0000\n",
      "Epoch 387/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1070610752.0000 - val_loss: 2687791104.0000\n",
      "Epoch 388/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1064329792.0000 - val_loss: 2670470144.0000\n",
      "Epoch 389/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1063282368.0000 - val_loss: 2757780480.0000\n",
      "Epoch 390/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1061405056.0000 - val_loss: 2665956608.0000\n",
      "Epoch 391/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1056396032.0000 - val_loss: 2665128960.0000\n",
      "Epoch 392/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1057870336.0000 - val_loss: 2706140928.0000\n",
      "Epoch 393/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1063341824.0000 - val_loss: 2638069760.0000\n",
      "Epoch 394/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1055463680.0000 - val_loss: 2707273472.0000\n",
      "Epoch 395/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1066589440.0000 - val_loss: 2621732608.0000\n",
      "Epoch 396/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1052670912.0000 - val_loss: 2681062144.0000\n",
      "Epoch 397/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1056871808.0000 - val_loss: 2683999488.0000\n",
      "Epoch 398/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1046277568.0000 - val_loss: 2617459712.0000\n",
      "Epoch 399/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1044813760.0000 - val_loss: 2670292480.0000\n",
      "Epoch 400/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1049249792.0000 - val_loss: 2660626176.0000\n",
      "Epoch 401/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1055123136.0000 - val_loss: 2601861888.0000\n",
      "Epoch 402/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1044492032.0000 - val_loss: 2611629312.0000\n",
      "Epoch 403/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1046061888.0000 - val_loss: 2631669248.0000\n",
      "Epoch 404/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 1039671488.0000 - val_loss: 2618106368.0000\n",
      "Epoch 405/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1031898048.0000 - val_loss: 2631049216.0000\n",
      "Epoch 406/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1051321600.0000 - val_loss: 2666934784.0000\n",
      "Epoch 407/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1039618944.0000 - val_loss: 2674391040.0000\n",
      "Epoch 408/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1046669952.0000 - val_loss: 2664616448.0000\n",
      "Epoch 409/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1034334016.0000 - val_loss: 2595244800.0000\n",
      "Epoch 410/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1045460352.0000 - val_loss: 2560929280.0000\n",
      "Epoch 411/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1047172928.0000 - val_loss: 2573378816.0000\n",
      "Epoch 412/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1036674944.0000 - val_loss: 2571566592.0000\n",
      "Epoch 413/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1032579712.0000 - val_loss: 2593029120.0000\n",
      "Epoch 414/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1039120960.0000 - val_loss: 2593533696.0000\n",
      "Epoch 415/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1029807552.0000 - val_loss: 2577119488.0000\n",
      "Epoch 416/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1025635392.0000 - val_loss: 2659143936.0000\n",
      "Epoch 417/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1037640512.0000 - val_loss: 2647693056.0000\n",
      "Epoch 418/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1026693184.0000 - val_loss: 2614073600.0000\n",
      "Epoch 419/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1034221696.0000 - val_loss: 2559137280.0000\n",
      "Epoch 420/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1019659456.0000 - val_loss: 2569710592.0000\n",
      "Epoch 421/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1029643776.0000 - val_loss: 2586423808.0000\n",
      "Epoch 422/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1010506816.0000 - val_loss: 2582320384.0000\n",
      "Epoch 423/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1019676416.0000 - val_loss: 2604664320.0000\n",
      "Epoch 424/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1023413760.0000 - val_loss: 2594158336.0000\n",
      "Epoch 425/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1023336064.0000 - val_loss: 2545956864.0000\n",
      "Epoch 426/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1024079232.0000 - val_loss: 2563977728.0000\n",
      "Epoch 427/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1013318912.0000 - val_loss: 2567035136.0000\n",
      "Epoch 428/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1012332224.0000 - val_loss: 2568318976.0000\n",
      "Epoch 429/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1018347712.0000 - val_loss: 2538865408.0000\n",
      "Epoch 430/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1015018112.0000 - val_loss: 2612698112.0000\n",
      "Epoch 431/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1020700416.0000 - val_loss: 2545068800.0000\n",
      "Epoch 432/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1013232896.0000 - val_loss: 2656073728.0000\n",
      "Epoch 433/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1021185728.0000 - val_loss: 2554833920.0000\n",
      "Epoch 434/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1004864448.0000 - val_loss: 2752229888.0000\n",
      "Epoch 435/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1012167360.0000 - val_loss: 2520577280.0000\n",
      "Epoch 436/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1007069760.0000 - val_loss: 2513771776.0000\n",
      "Epoch 437/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1007952000.0000 - val_loss: 2527540992.0000\n",
      "Epoch 438/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1008638784.0000 - val_loss: 2498110976.0000\n",
      "Epoch 439/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1005239040.0000 - val_loss: 2553115392.0000\n",
      "Epoch 440/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1008697280.0000 - val_loss: 2521467904.0000\n",
      "Epoch 441/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 998740480.0000 - val_loss: 2481059584.0000\n",
      "Epoch 442/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1020669760.0000 - val_loss: 2497532416.0000\n",
      "Epoch 443/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 995767488.0000 - val_loss: 2469668352.0000\n",
      "Epoch 444/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1012120000.0000 - val_loss: 2574489600.0000\n",
      "Epoch 445/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1007364032.0000 - val_loss: 2482446592.0000\n",
      "Epoch 446/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 996720832.0000 - val_loss: 2507672832.0000\n",
      "Epoch 447/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 998905472.0000 - val_loss: 2467788544.0000\n",
      "Epoch 448/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 992626944.0000 - val_loss: 2582281216.0000\n",
      "Epoch 449/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 989531712.0000 - val_loss: 2446293504.0000\n",
      "Epoch 450/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 987819904.0000 - val_loss: 2524976384.0000\n",
      "Epoch 451/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 995631552.0000 - val_loss: 2448530432.0000\n",
      "Epoch 452/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 988123456.0000 - val_loss: 2491353856.0000\n",
      "Epoch 453/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 982055424.0000 - val_loss: 2473389824.0000\n",
      "Epoch 454/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 991518400.0000 - val_loss: 2418439936.0000\n",
      "Epoch 455/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 994948672.0000 - val_loss: 2440812544.0000\n",
      "Epoch 456/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 979517760.0000 - val_loss: 2466864384.0000\n",
      "Epoch 457/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 1000108992.0000 - val_loss: 2463829760.0000\n",
      "Epoch 458/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 980937920.0000 - val_loss: 2482143488.0000\n",
      "Epoch 459/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 975901248.0000 - val_loss: 2513862144.0000\n",
      "Epoch 460/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 983966400.0000 - val_loss: 2440352512.0000\n",
      "Epoch 461/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 981045312.0000 - val_loss: 2428722944.0000\n",
      "Epoch 462/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 975878784.0000 - val_loss: 2505732864.0000\n",
      "Epoch 463/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 975198528.0000 - val_loss: 2482761984.0000\n",
      "Epoch 464/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 976467136.0000 - val_loss: 2475984384.0000\n",
      "Epoch 465/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 988511104.0000 - val_loss: 2490739712.0000\n",
      "Epoch 466/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 975760512.0000 - val_loss: 2429199360.0000\n",
      "Epoch 467/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 977235008.0000 - val_loss: 2438990336.0000\n",
      "Epoch 468/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 978617536.0000 - val_loss: 2389519104.0000\n",
      "Epoch 469/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 980365888.0000 - val_loss: 2568805120.0000\n",
      "Epoch 470/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 994277504.0000 - val_loss: 2386852096.0000\n",
      "Epoch 471/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 964594368.0000 - val_loss: 2394722304.0000\n",
      "Epoch 472/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 971734464.0000 - val_loss: 2376879104.0000\n",
      "Epoch 473/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 953062080.0000 - val_loss: 2392817664.0000\n",
      "Epoch 474/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 971047552.0000 - val_loss: 2397248512.0000\n",
      "Epoch 475/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 960654848.0000 - val_loss: 2404064256.0000\n",
      "Epoch 476/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 970602432.0000 - val_loss: 2426715648.0000\n",
      "Epoch 477/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 960934912.0000 - val_loss: 2353954304.0000\n",
      "Epoch 478/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 953373440.0000 - val_loss: 2429372672.0000\n",
      "Epoch 479/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 958499328.0000 - val_loss: 2449760512.0000\n",
      "Epoch 480/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 967525760.0000 - val_loss: 2438193152.0000\n",
      "Epoch 481/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 951862272.0000 - val_loss: 2417525504.0000\n",
      "Epoch 482/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 952369024.0000 - val_loss: 2360934144.0000\n",
      "Epoch 483/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 955352832.0000 - val_loss: 2340623104.0000\n",
      "Epoch 484/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 951191424.0000 - val_loss: 2422778880.0000\n",
      "Epoch 485/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 948079808.0000 - val_loss: 2320963840.0000\n",
      "Epoch 486/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 941789376.0000 - val_loss: 2433613568.0000\n",
      "Epoch 487/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 946007552.0000 - val_loss: 2383823360.0000\n",
      "Epoch 488/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 940235648.0000 - val_loss: 2432358400.0000\n",
      "Epoch 489/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 939665088.0000 - val_loss: 2432587008.0000\n",
      "Epoch 490/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 941897984.0000 - val_loss: 2368799232.0000\n",
      "Epoch 491/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 939468928.0000 - val_loss: 2351360512.0000\n",
      "Epoch 492/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 954617728.0000 - val_loss: 2316193024.0000\n",
      "Epoch 493/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 940848512.0000 - val_loss: 2404127488.0000\n",
      "Epoch 494/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 934400000.0000 - val_loss: 2300247040.0000\n",
      "Epoch 495/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 936718336.0000 - val_loss: 2367273216.0000\n",
      "Epoch 496/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 934903488.0000 - val_loss: 2302313472.0000\n",
      "Epoch 497/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 935922560.0000 - val_loss: 2368769280.0000\n",
      "Epoch 498/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 934649408.0000 - val_loss: 2405576960.0000\n",
      "Epoch 499/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 928067776.0000 - val_loss: 2294269184.0000\n",
      "Epoch 500/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 924593216.0000 - val_loss: 2361226752.0000\n",
      "Epoch 501/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 923905664.0000 - val_loss: 2291396608.0000\n",
      "Epoch 502/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 934123008.0000 - val_loss: 2331748608.0000\n",
      "Epoch 503/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 919109888.0000 - val_loss: 2273203200.0000\n",
      "Epoch 504/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 920191488.0000 - val_loss: 2413308416.0000\n",
      "Epoch 505/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 941399872.0000 - val_loss: 2366246144.0000\n",
      "Epoch 506/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 897029568.0000 - val_loss: 2294586624.0000\n",
      "Epoch 507/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 942072448.0000 - val_loss: 2277848320.0000\n",
      "Epoch 508/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 919006400.0000 - val_loss: 2270231296.0000\n",
      "Epoch 509/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 916977536.0000 - val_loss: 2310697728.0000\n",
      "Epoch 510/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 935751680.0000 - val_loss: 2302880256.0000\n",
      "Epoch 511/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 910920000.0000 - val_loss: 2304850176.0000\n",
      "Epoch 512/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 919078144.0000 - val_loss: 2272849152.0000\n",
      "Epoch 513/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 918352768.0000 - val_loss: 2291682048.0000\n",
      "Epoch 514/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 930080256.0000 - val_loss: 2282095872.0000\n",
      "Epoch 515/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 923750336.0000 - val_loss: 2281051648.0000\n",
      "Epoch 516/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 901029632.0000 - val_loss: 2271700992.0000\n",
      "Epoch 517/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 907594880.0000 - val_loss: 2276069376.0000\n",
      "Epoch 518/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 911436672.0000 - val_loss: 2260334080.0000\n",
      "Epoch 519/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 902629248.0000 - val_loss: 2251188736.0000\n",
      "Epoch 520/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 909283008.0000 - val_loss: 2259773696.0000\n",
      "Epoch 521/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 913082816.0000 - val_loss: 2295189504.0000\n",
      "Epoch 522/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 894594560.0000 - val_loss: 2236024064.0000\n",
      "Epoch 523/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 902420352.0000 - val_loss: 2234191616.0000\n",
      "Epoch 524/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 893046208.0000 - val_loss: 2227341824.0000\n",
      "Epoch 525/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 897242048.0000 - val_loss: 2226563072.0000\n",
      "Epoch 526/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 899471424.0000 - val_loss: 2295470592.0000\n",
      "Epoch 527/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 884475520.0000 - val_loss: 2238173184.0000\n",
      "Epoch 528/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 902208320.0000 - val_loss: 2221933056.0000\n",
      "Epoch 529/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 883347456.0000 - val_loss: 2220504064.0000\n",
      "Epoch 530/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 903560384.0000 - val_loss: 2274999552.0000\n",
      "Epoch 531/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 885005952.0000 - val_loss: 2300012032.0000\n",
      "Epoch 532/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 886701440.0000 - val_loss: 2210664704.0000\n",
      "Epoch 533/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 882976704.0000 - val_loss: 2213714944.0000\n",
      "Epoch 534/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 885562688.0000 - val_loss: 2256488960.0000\n",
      "Epoch 535/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 878003776.0000 - val_loss: 2233623552.0000\n",
      "Epoch 536/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 902075904.0000 - val_loss: 2197632512.0000\n",
      "Epoch 537/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 891479808.0000 - val_loss: 2211671552.0000\n",
      "Epoch 538/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 878416128.0000 - val_loss: 2188225536.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 539/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 887749760.0000 - val_loss: 2214368000.0000\n",
      "Epoch 540/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 879495744.0000 - val_loss: 2184537600.0000\n",
      "Epoch 541/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 876678848.0000 - val_loss: 2176259328.0000\n",
      "Epoch 542/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 881774400.0000 - val_loss: 2240840704.0000\n",
      "Epoch 543/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 875174912.0000 - val_loss: 2195068672.0000\n",
      "Epoch 544/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 878680256.0000 - val_loss: 2160148992.0000\n",
      "Epoch 545/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 862917760.0000 - val_loss: 2258365440.0000\n",
      "Epoch 546/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 893387392.0000 - val_loss: 2127245440.0000\n",
      "Epoch 547/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 866331456.0000 - val_loss: 2211194624.0000\n",
      "Epoch 548/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 875365120.0000 - val_loss: 2177118464.0000\n",
      "Epoch 549/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 858499648.0000 - val_loss: 2157783040.0000\n",
      "Epoch 550/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 867165760.0000 - val_loss: 2163044608.0000\n",
      "Epoch 551/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 863254976.0000 - val_loss: 2140852608.0000\n",
      "Epoch 552/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 871632448.0000 - val_loss: 2134484352.0000\n",
      "Epoch 553/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 865658880.0000 - val_loss: 2167337472.0000\n",
      "Epoch 554/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 865073984.0000 - val_loss: 2122219904.0000\n",
      "Epoch 555/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 852676864.0000 - val_loss: 2172901888.0000\n",
      "Epoch 556/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 860770304.0000 - val_loss: 2272938752.0000\n",
      "Epoch 557/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 859174528.0000 - val_loss: 2156354048.0000\n",
      "Epoch 558/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 862049664.0000 - val_loss: 2107595904.0000\n",
      "Epoch 559/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 845005248.0000 - val_loss: 2067457024.0000\n",
      "Epoch 560/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 856468416.0000 - val_loss: 2108052352.0000\n",
      "Epoch 561/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 840755840.0000 - val_loss: 2122804224.0000\n",
      "Epoch 562/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 857617536.0000 - val_loss: 2101141632.0000\n",
      "Epoch 563/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 862271808.0000 - val_loss: 2119769216.0000\n",
      "Epoch 564/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 830591104.0000 - val_loss: 2102628992.0000\n",
      "Epoch 565/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 845022848.0000 - val_loss: 2131432832.0000\n",
      "Epoch 566/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 850313024.0000 - val_loss: 2142644992.0000\n",
      "Epoch 567/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 838392256.0000 - val_loss: 2059703168.0000\n",
      "Epoch 568/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 838765568.0000 - val_loss: 2107719808.0000\n",
      "Epoch 569/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 835590144.0000 - val_loss: 2098256896.0000\n",
      "Epoch 570/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 837041920.0000 - val_loss: 2039081856.0000\n",
      "Epoch 571/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 861570816.0000 - val_loss: 2065356928.0000\n",
      "Epoch 572/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 833211072.0000 - val_loss: 2057267968.0000\n",
      "Epoch 573/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 829483968.0000 - val_loss: 2115609216.0000\n",
      "Epoch 574/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 828596288.0000 - val_loss: 2244170496.0000\n",
      "Epoch 575/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 823040448.0000 - val_loss: 2037975296.0000\n",
      "Epoch 576/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 821592320.0000 - val_loss: 2132506496.0000\n",
      "Epoch 577/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 829749696.0000 - val_loss: 2075625856.0000\n",
      "Epoch 578/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 828850880.0000 - val_loss: 2034471040.0000\n",
      "Epoch 579/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 823390528.0000 - val_loss: 2064952192.0000\n",
      "Epoch 580/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 823524480.0000 - val_loss: 2048634496.0000\n",
      "Epoch 581/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 821204032.0000 - val_loss: 2214812160.0000\n",
      "Epoch 582/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 811835008.0000 - val_loss: 2041023488.0000\n",
      "Epoch 583/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 811945536.0000 - val_loss: 2054171392.0000\n",
      "Epoch 584/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 798271552.0000 - val_loss: 2053961216.0000\n",
      "Epoch 585/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 816431552.0000 - val_loss: 2066288512.0000\n",
      "Epoch 586/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 811934144.0000 - val_loss: 2028484480.0000\n",
      "Epoch 587/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 806588032.0000 - val_loss: 2049281024.0000\n",
      "Epoch 588/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 814488000.0000 - val_loss: 2023902080.0000\n",
      "Epoch 589/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 810194112.0000 - val_loss: 2046987776.0000\n",
      "Epoch 590/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 802919168.0000 - val_loss: 1991742720.0000\n",
      "Epoch 591/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 803828672.0000 - val_loss: 1999075456.0000\n",
      "Epoch 592/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 815772224.0000 - val_loss: 2047978112.0000\n",
      "Epoch 593/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 808593472.0000 - val_loss: 2057035648.0000\n",
      "Epoch 594/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 803461376.0000 - val_loss: 1987580672.0000\n",
      "Epoch 595/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 804051840.0000 - val_loss: 2005700480.0000\n",
      "Epoch 596/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 801746816.0000 - val_loss: 2072361856.0000\n",
      "Epoch 597/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 800146880.0000 - val_loss: 1989197440.0000\n",
      "Epoch 598/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 810678464.0000 - val_loss: 1988968448.0000\n",
      "Epoch 599/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 786754048.0000 - val_loss: 1962033792.0000\n",
      "Epoch 600/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 794541696.0000 - val_loss: 2041844736.0000\n",
      "Epoch 601/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 805997952.0000 - val_loss: 1957450624.0000\n",
      "Epoch 602/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 794277632.0000 - val_loss: 2093770752.0000\n",
      "Epoch 603/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 796070080.0000 - val_loss: 1982198400.0000\n",
      "Epoch 604/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 780526912.0000 - val_loss: 1968278528.0000\n",
      "Epoch 605/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 787570688.0000 - val_loss: 1955994112.0000\n",
      "Epoch 606/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 786512192.0000 - val_loss: 1937990144.0000\n",
      "Epoch 607/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 794115136.0000 - val_loss: 1964863104.0000\n",
      "Epoch 608/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 794320832.0000 - val_loss: 2007014912.0000\n",
      "Epoch 609/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 775061568.0000 - val_loss: 2083498880.0000\n",
      "Epoch 610/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 788606080.0000 - val_loss: 1978807040.0000\n",
      "Epoch 611/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 769114240.0000 - val_loss: 1960830720.0000\n",
      "Epoch 612/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 781901632.0000 - val_loss: 1999578752.0000\n",
      "Epoch 613/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 771896768.0000 - val_loss: 1920326912.0000\n",
      "Epoch 614/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 780960576.0000 - val_loss: 1921844608.0000\n",
      "Epoch 615/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 786262784.0000 - val_loss: 1922891776.0000\n",
      "Epoch 616/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 790222208.0000 - val_loss: 1921387008.0000\n",
      "Epoch 617/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 774633152.0000 - val_loss: 1927403008.0000\n",
      "Epoch 618/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 760053760.0000 - val_loss: 1901567232.0000\n",
      "Epoch 619/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 762585152.0000 - val_loss: 1904393984.0000\n",
      "Epoch 620/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 760885632.0000 - val_loss: 1982360064.0000\n",
      "Epoch 621/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 768241856.0000 - val_loss: 1883900928.0000\n",
      "Epoch 622/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 762306368.0000 - val_loss: 1921787776.0000\n",
      "Epoch 623/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 753356288.0000 - val_loss: 1910000256.0000\n",
      "Epoch 624/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 750453952.0000 - val_loss: 1953070976.0000\n",
      "Epoch 625/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 756819904.0000 - val_loss: 1865886080.0000\n",
      "Epoch 626/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 746392768.0000 - val_loss: 2010252928.0000\n",
      "Epoch 627/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 754001472.0000 - val_loss: 1887550464.0000\n",
      "Epoch 628/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 760845120.0000 - val_loss: 1859516672.0000\n",
      "Epoch 629/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 759597312.0000 - val_loss: 1850638592.0000\n",
      "Epoch 630/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 757548288.0000 - val_loss: 1884815872.0000\n",
      "Epoch 631/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 764272256.0000 - val_loss: 1854870400.0000\n",
      "Epoch 632/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 750186688.0000 - val_loss: 1846974464.0000\n",
      "Epoch 633/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 737030784.0000 - val_loss: 1844670464.0000\n",
      "Epoch 634/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 732425024.0000 - val_loss: 1939545984.0000\n",
      "Epoch 635/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 743385856.0000 - val_loss: 1859666816.0000\n",
      "Epoch 636/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 744726848.0000 - val_loss: 1846072448.0000\n",
      "Epoch 637/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 742793280.0000 - val_loss: 1857927296.0000\n",
      "Epoch 638/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 731041728.0000 - val_loss: 1802173440.0000\n",
      "Epoch 639/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 733221760.0000 - val_loss: 1837800192.0000\n",
      "Epoch 640/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 734088320.0000 - val_loss: 1817440640.0000\n",
      "Epoch 641/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 723596032.0000 - val_loss: 1856500480.0000\n",
      "Epoch 642/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 735398976.0000 - val_loss: 1825474688.0000\n",
      "Epoch 643/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 751412864.0000 - val_loss: 1820352256.0000\n",
      "Epoch 644/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 723539136.0000 - val_loss: 1827121024.0000\n",
      "Epoch 645/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 715941248.0000 - val_loss: 1820580480.0000\n",
      "Epoch 646/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 728839168.0000 - val_loss: 1795136128.0000\n",
      "Epoch 647/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 733300032.0000 - val_loss: 1823256064.0000\n",
      "Epoch 648/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 718350144.0000 - val_loss: 1958202368.0000\n",
      "Epoch 649/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 709096512.0000 - val_loss: 1795168512.0000\n",
      "Epoch 650/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 718787136.0000 - val_loss: 1824680832.0000\n",
      "Epoch 651/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 711745344.0000 - val_loss: 1818997888.0000\n",
      "Epoch 652/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 717411008.0000 - val_loss: 1815106432.0000\n",
      "Epoch 653/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 716115072.0000 - val_loss: 1828935936.0000\n",
      "Epoch 654/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 713576768.0000 - val_loss: 1873090304.0000\n",
      "Epoch 655/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 699849984.0000 - val_loss: 1870668032.0000\n",
      "Epoch 656/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 712071808.0000 - val_loss: 1771411584.0000\n",
      "Epoch 657/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 714660992.0000 - val_loss: 1906476672.0000\n",
      "Epoch 658/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 711206656.0000 - val_loss: 1808092416.0000\n",
      "Epoch 659/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 697963264.0000 - val_loss: 1830028032.0000\n",
      "Epoch 660/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 706435136.0000 - val_loss: 1766355456.0000\n",
      "Epoch 661/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 700524672.0000 - val_loss: 1743915136.0000\n",
      "Epoch 662/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 716823616.0000 - val_loss: 1882266368.0000\n",
      "Epoch 663/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 711245440.0000 - val_loss: 1804055680.0000\n",
      "Epoch 664/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 689278144.0000 - val_loss: 1835900288.0000\n",
      "Epoch 665/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 704957120.0000 - val_loss: 1777679232.0000\n",
      "Epoch 666/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 702329728.0000 - val_loss: 1727495680.0000\n",
      "Epoch 667/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 704823296.0000 - val_loss: 1741212928.0000\n",
      "Epoch 668/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 703879168.0000 - val_loss: 1724514688.0000\n",
      "Epoch 669/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 708654848.0000 - val_loss: 1747842176.0000\n",
      "Epoch 670/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 700373952.0000 - val_loss: 1729484928.0000\n",
      "Epoch 671/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 683863808.0000 - val_loss: 1748583680.0000\n",
      "Epoch 672/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 693183936.0000 - val_loss: 1738993024.0000\n",
      "Epoch 673/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 697850880.0000 - val_loss: 1736812672.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 674/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 689164864.0000 - val_loss: 1721244416.0000\n",
      "Epoch 675/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 687927488.0000 - val_loss: 1771486848.0000\n",
      "Epoch 676/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 682398784.0000 - val_loss: 1694497024.0000\n",
      "Epoch 677/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 687342016.0000 - val_loss: 1700064128.0000\n",
      "Epoch 678/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 679289600.0000 - val_loss: 1669715072.0000\n",
      "Epoch 679/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 677822720.0000 - val_loss: 1699044224.0000\n",
      "Epoch 680/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 695506368.0000 - val_loss: 1824514176.0000\n",
      "Epoch 681/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 679939008.0000 - val_loss: 1724953856.0000\n",
      "Epoch 682/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 681020160.0000 - val_loss: 1705647360.0000\n",
      "Epoch 683/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 673294528.0000 - val_loss: 1696276352.0000\n",
      "Epoch 684/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 679208000.0000 - val_loss: 1706042112.0000\n",
      "Epoch 685/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 693755008.0000 - val_loss: 1784958976.0000\n",
      "Epoch 686/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 668232704.0000 - val_loss: 1702803712.0000\n",
      "Epoch 687/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 664988288.0000 - val_loss: 1704807424.0000\n",
      "Epoch 688/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 671504512.0000 - val_loss: 1685936640.0000\n",
      "Epoch 689/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 665605312.0000 - val_loss: 1654485632.0000\n",
      "Epoch 690/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 671164928.0000 - val_loss: 1719888384.0000\n",
      "Epoch 691/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 671560576.0000 - val_loss: 1677337984.0000\n",
      "Epoch 692/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 664683520.0000 - val_loss: 1763902976.0000\n",
      "Epoch 693/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 666448448.0000 - val_loss: 1675749248.0000\n",
      "Epoch 694/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 652996352.0000 - val_loss: 1672048256.0000\n",
      "Epoch 695/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 676913856.0000 - val_loss: 1673607808.0000\n",
      "Epoch 696/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 670450752.0000 - val_loss: 1714986240.0000\n",
      "Epoch 697/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 662427712.0000 - val_loss: 1706527616.0000\n",
      "Epoch 698/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 660873152.0000 - val_loss: 1704363264.0000\n",
      "Epoch 699/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 645623232.0000 - val_loss: 1664905472.0000\n",
      "Epoch 700/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 660867008.0000 - val_loss: 1700820608.0000\n",
      "Epoch 701/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 645646208.0000 - val_loss: 1646014592.0000\n",
      "Epoch 702/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 652526272.0000 - val_loss: 1669040640.0000\n",
      "Epoch 703/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 670001280.0000 - val_loss: 1760012288.0000\n",
      "Epoch 704/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 646671808.0000 - val_loss: 1635951488.0000\n",
      "Epoch 705/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 659427776.0000 - val_loss: 1621952896.0000\n",
      "Epoch 706/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 642709952.0000 - val_loss: 1631808000.0000\n",
      "Epoch 707/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 643231808.0000 - val_loss: 1657444736.0000\n",
      "Epoch 708/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 647977792.0000 - val_loss: 1924824192.0000\n",
      "Epoch 709/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 662161984.0000 - val_loss: 1632910080.0000\n",
      "Epoch 710/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 643688512.0000 - val_loss: 1591094016.0000\n",
      "Epoch 711/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 643704192.0000 - val_loss: 1583016064.0000\n",
      "Epoch 712/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 631054400.0000 - val_loss: 1615585664.0000\n",
      "Epoch 713/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 652982272.0000 - val_loss: 1612338688.0000\n",
      "Epoch 714/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 642008000.0000 - val_loss: 1626814464.0000\n",
      "Epoch 715/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 637291456.0000 - val_loss: 1601173760.0000\n",
      "Epoch 716/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 627029504.0000 - val_loss: 1769934208.0000\n",
      "Epoch 717/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 638533888.0000 - val_loss: 1626462848.0000\n",
      "Epoch 718/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 634480192.0000 - val_loss: 1637117824.0000\n",
      "Epoch 719/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 631999232.0000 - val_loss: 1615669504.0000\n",
      "Epoch 720/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 683281920.0000 - val_loss: 1566874240.0000\n",
      "Epoch 721/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 619969984.0000 - val_loss: 1690294272.0000\n",
      "Epoch 722/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 636679808.0000 - val_loss: 1550298752.0000\n",
      "Epoch 723/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 626442304.0000 - val_loss: 1663241600.0000\n",
      "Epoch 724/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 614825600.0000 - val_loss: 1586723968.0000\n",
      "Epoch 725/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 636179456.0000 - val_loss: 1584839040.0000\n",
      "Epoch 726/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 628605952.0000 - val_loss: 1558000512.0000\n",
      "Epoch 727/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 617395392.0000 - val_loss: 1616947968.0000\n",
      "Epoch 728/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 622261760.0000 - val_loss: 1570339968.0000\n",
      "Epoch 729/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 631084736.0000 - val_loss: 1610221056.0000\n",
      "Epoch 730/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 610932736.0000 - val_loss: 1640564864.0000\n",
      "Epoch 731/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 619236480.0000 - val_loss: 1564210048.0000\n",
      "Epoch 732/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 622806144.0000 - val_loss: 1551189376.0000\n",
      "Epoch 733/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 617443392.0000 - val_loss: 1585968768.0000\n",
      "Epoch 734/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 616947904.0000 - val_loss: 1552396800.0000\n",
      "Epoch 735/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 630605056.0000 - val_loss: 1597983872.0000\n",
      "Epoch 736/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 622648000.0000 - val_loss: 1582404864.0000\n",
      "Epoch 737/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 645415424.0000 - val_loss: 1567062528.0000\n",
      "Epoch 738/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 601624448.0000 - val_loss: 1538438144.0000\n",
      "Epoch 739/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 608685120.0000 - val_loss: 1546354432.0000\n",
      "Epoch 740/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 613424768.0000 - val_loss: 1649262208.0000\n",
      "Epoch 741/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 619698944.0000 - val_loss: 1518465920.0000\n",
      "Epoch 742/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 599643328.0000 - val_loss: 1648768256.0000\n",
      "Epoch 743/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 607308992.0000 - val_loss: 1491671168.0000\n",
      "Epoch 744/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 610629312.0000 - val_loss: 1516336000.0000\n",
      "Epoch 745/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 597297728.0000 - val_loss: 1547450112.0000\n",
      "Epoch 746/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 596266624.0000 - val_loss: 1555600128.0000\n",
      "Epoch 747/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 594767360.0000 - val_loss: 1536559360.0000\n",
      "Epoch 748/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 607666688.0000 - val_loss: 1525865344.0000\n",
      "Epoch 749/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 600830848.0000 - val_loss: 1488639232.0000\n",
      "Epoch 750/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 632515200.0000 - val_loss: 1509353856.0000\n",
      "Epoch 751/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 587443008.0000 - val_loss: 1515294208.0000\n",
      "Epoch 752/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 594006400.0000 - val_loss: 1528289408.0000\n",
      "Epoch 753/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 596029760.0000 - val_loss: 1487077760.0000\n",
      "Epoch 754/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 602912128.0000 - val_loss: 1516405376.0000\n",
      "Epoch 755/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 601610368.0000 - val_loss: 1489603968.0000\n",
      "Epoch 756/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 585635008.0000 - val_loss: 1501729152.0000\n",
      "Epoch 757/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 601417600.0000 - val_loss: 1504758656.0000\n",
      "Epoch 758/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 582693696.0000 - val_loss: 1471004288.0000\n",
      "Epoch 759/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 592984512.0000 - val_loss: 1462463616.0000\n",
      "Epoch 760/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 599854016.0000 - val_loss: 1497044608.0000\n",
      "Epoch 761/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 592096064.0000 - val_loss: 1489544192.0000\n",
      "Epoch 762/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 578718016.0000 - val_loss: 1472940800.0000\n",
      "Epoch 763/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 577421440.0000 - val_loss: 1493164672.0000\n",
      "Epoch 764/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 590376320.0000 - val_loss: 1452915584.0000\n",
      "Epoch 765/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 572759744.0000 - val_loss: 1553569792.0000\n",
      "Epoch 766/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 585972992.0000 - val_loss: 1454483840.0000\n",
      "Epoch 767/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 586677824.0000 - val_loss: 1542968064.0000\n",
      "Epoch 768/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 578254912.0000 - val_loss: 1537504512.0000\n",
      "Epoch 769/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 577644864.0000 - val_loss: 1457932544.0000\n",
      "Epoch 770/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 585335040.0000 - val_loss: 1459009152.0000\n",
      "Epoch 771/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 578907648.0000 - val_loss: 1453532928.0000\n",
      "Epoch 772/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 586065344.0000 - val_loss: 1452606336.0000\n",
      "Epoch 773/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 560381760.0000 - val_loss: 1438064768.0000\n",
      "Epoch 774/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 560867392.0000 - val_loss: 1486109568.0000\n",
      "Epoch 775/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 572815168.0000 - val_loss: 1424134784.0000\n",
      "Epoch 776/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 581527616.0000 - val_loss: 1428390784.0000\n",
      "Epoch 777/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 565338240.0000 - val_loss: 1487619584.0000\n",
      "Epoch 778/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 568059520.0000 - val_loss: 1432097024.0000\n",
      "Epoch 779/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 565048320.0000 - val_loss: 1532038656.0000\n",
      "Epoch 780/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 561562048.0000 - val_loss: 1582715008.0000\n",
      "Epoch 781/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 585381376.0000 - val_loss: 1439062016.0000\n",
      "Epoch 782/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 552596032.0000 - val_loss: 1435506560.0000\n",
      "Epoch 783/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 570451840.0000 - val_loss: 1494652288.0000\n",
      "Epoch 784/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 561253504.0000 - val_loss: 1452886144.0000\n",
      "Epoch 785/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 581114496.0000 - val_loss: 1433839744.0000\n",
      "Epoch 786/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 554086784.0000 - val_loss: 1417407360.0000\n",
      "Epoch 787/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 552748352.0000 - val_loss: 1412389248.0000\n",
      "Epoch 788/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 595698880.0000 - val_loss: 1451649152.0000\n",
      "Epoch 789/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 570300160.0000 - val_loss: 1421281920.0000\n",
      "Epoch 790/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 551153600.0000 - val_loss: 1427278592.0000\n",
      "Epoch 791/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 550619328.0000 - val_loss: 1510413056.0000\n",
      "Epoch 792/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 562419136.0000 - val_loss: 1424300160.0000\n",
      "Epoch 793/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 554107456.0000 - val_loss: 1451120640.0000\n",
      "Epoch 794/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 548060736.0000 - val_loss: 1414521472.0000\n",
      "Epoch 795/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 545000256.0000 - val_loss: 1387695488.0000\n",
      "Epoch 796/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 539996608.0000 - val_loss: 1461395456.0000\n",
      "Epoch 797/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 547453824.0000 - val_loss: 1403273472.0000\n",
      "Epoch 798/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 561913600.0000 - val_loss: 1422456832.0000\n",
      "Epoch 799/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 548053504.0000 - val_loss: 1411659136.0000\n",
      "Epoch 800/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 557467840.0000 - val_loss: 1519085696.0000\n",
      "Epoch 801/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 536291008.0000 - val_loss: 1401118464.0000\n",
      "Epoch 802/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 546313728.0000 - val_loss: 1445879424.0000\n",
      "Epoch 803/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 556365760.0000 - val_loss: 1395307008.0000\n",
      "Epoch 804/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 545064000.0000 - val_loss: 1423352576.0000\n",
      "Epoch 805/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 539926912.0000 - val_loss: 1516789504.0000\n",
      "Epoch 806/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 543786432.0000 - val_loss: 1383605504.0000\n",
      "Epoch 807/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 558441600.0000 - val_loss: 1406707968.0000\n",
      "Epoch 808/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 561035456.0000 - val_loss: 1401841152.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 809/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 537785920.0000 - val_loss: 1411996288.0000\n",
      "Epoch 810/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 534641312.0000 - val_loss: 1419195136.0000\n",
      "Epoch 811/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 539027584.0000 - val_loss: 1404633984.0000\n",
      "Epoch 812/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 543887744.0000 - val_loss: 1362764800.0000\n",
      "Epoch 813/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 518804192.0000 - val_loss: 1443249792.0000\n",
      "Epoch 814/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 539714304.0000 - val_loss: 1397845760.0000\n",
      "Epoch 815/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 564577984.0000 - val_loss: 1370964480.0000\n",
      "Epoch 816/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 538402880.0000 - val_loss: 1435039744.0000\n",
      "Epoch 817/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 548093568.0000 - val_loss: 1404525312.0000\n",
      "Epoch 818/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 525457152.0000 - val_loss: 1441644672.0000\n",
      "Epoch 819/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 526096480.0000 - val_loss: 1445207296.0000\n",
      "Epoch 820/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 539152960.0000 - val_loss: 1392046720.0000\n",
      "Epoch 821/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 528238944.0000 - val_loss: 1378615168.0000\n",
      "Epoch 822/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 525154944.0000 - val_loss: 1382954752.0000\n",
      "Epoch 823/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 550983040.0000 - val_loss: 1372126976.0000\n",
      "Epoch 824/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 536134496.0000 - val_loss: 1347077632.0000\n",
      "Epoch 825/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 520967520.0000 - val_loss: 1375724800.0000\n",
      "Epoch 826/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 546366592.0000 - val_loss: 1361300096.0000\n",
      "Epoch 827/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 529351040.0000 - val_loss: 1361015296.0000\n",
      "Epoch 828/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 521823616.0000 - val_loss: 1406447104.0000\n",
      "Epoch 829/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 532821632.0000 - val_loss: 1338894080.0000\n",
      "Epoch 830/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 522135904.0000 - val_loss: 1364234112.0000\n",
      "Epoch 831/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 520013472.0000 - val_loss: 1420778368.0000\n",
      "Epoch 832/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 528244032.0000 - val_loss: 1353549056.0000\n",
      "Epoch 833/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 532800480.0000 - val_loss: 1354103168.0000\n",
      "Epoch 834/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 515246048.0000 - val_loss: 1358924672.0000\n",
      "Epoch 835/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 549036032.0000 - val_loss: 1345515008.0000\n",
      "Epoch 836/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 561873408.0000 - val_loss: 1390821632.0000\n",
      "Epoch 837/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 520023904.0000 - val_loss: 1360374784.0000\n",
      "Epoch 838/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 516095072.0000 - val_loss: 1449087616.0000\n",
      "Epoch 839/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 520058592.0000 - val_loss: 1351828224.0000\n",
      "Epoch 840/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 525609888.0000 - val_loss: 1366861696.0000\n",
      "Epoch 841/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 515059648.0000 - val_loss: 1331138432.0000\n",
      "Epoch 842/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 510350720.0000 - val_loss: 1388352768.0000\n",
      "Epoch 843/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 509773408.0000 - val_loss: 1333305216.0000\n",
      "Epoch 844/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 544884672.0000 - val_loss: 1436310144.0000\n",
      "Epoch 845/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 537610880.0000 - val_loss: 1348931200.0000\n",
      "Epoch 846/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 516520384.0000 - val_loss: 1343290240.0000\n",
      "Epoch 847/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 501699072.0000 - val_loss: 1336107264.0000\n",
      "Epoch 848/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 517849056.0000 - val_loss: 1325894144.0000\n",
      "Epoch 849/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 509970272.0000 - val_loss: 1401357312.0000\n",
      "Epoch 850/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 520969056.0000 - val_loss: 1324004096.0000\n",
      "Epoch 851/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 518485856.0000 - val_loss: 1338713344.0000\n",
      "Epoch 852/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 512573472.0000 - val_loss: 1314857344.0000\n",
      "Epoch 853/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 499395904.0000 - val_loss: 1328832896.0000\n",
      "Epoch 854/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 502185984.0000 - val_loss: 1331450240.0000\n",
      "Epoch 855/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 511149280.0000 - val_loss: 1354952064.0000\n",
      "Epoch 856/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 544747776.0000 - val_loss: 1419644288.0000\n",
      "Epoch 857/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 514130912.0000 - val_loss: 1339122560.0000\n",
      "Epoch 858/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 494557696.0000 - val_loss: 1322004096.0000\n",
      "Epoch 859/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 505259040.0000 - val_loss: 1320831744.0000\n",
      "Epoch 860/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 513083200.0000 - val_loss: 1323515904.0000\n",
      "Epoch 861/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 509184160.0000 - val_loss: 1307105920.0000\n",
      "Epoch 862/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 503812224.0000 - val_loss: 1323217920.0000\n",
      "Epoch 863/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 503637472.0000 - val_loss: 1402551680.0000\n",
      "Epoch 864/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 498434528.0000 - val_loss: 1321051008.0000\n",
      "Epoch 865/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 497488320.0000 - val_loss: 1353758464.0000\n",
      "Epoch 866/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 508000672.0000 - val_loss: 1304618880.0000\n",
      "Epoch 867/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 490237760.0000 - val_loss: 1431768704.0000\n",
      "Epoch 868/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 515587744.0000 - val_loss: 1320228736.0000\n",
      "Epoch 869/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 524797760.0000 - val_loss: 1321321088.0000\n",
      "Epoch 870/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 482351584.0000 - val_loss: 1306788352.0000\n",
      "Epoch 871/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 512504384.0000 - val_loss: 1314008192.0000\n",
      "Epoch 872/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 492342400.0000 - val_loss: 1314585728.0000\n",
      "Epoch 873/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 503295392.0000 - val_loss: 1383294848.0000\n",
      "Epoch 874/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 502375872.0000 - val_loss: 1329354368.0000\n",
      "Epoch 875/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 498930976.0000 - val_loss: 1314977792.0000\n",
      "Epoch 876/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 498949216.0000 - val_loss: 1301614208.0000\n",
      "Epoch 877/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 485530848.0000 - val_loss: 1315326592.0000\n",
      "Epoch 878/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 491626688.0000 - val_loss: 1301866112.0000\n",
      "Epoch 879/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 489480416.0000 - val_loss: 1299145088.0000\n",
      "Epoch 880/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 494959104.0000 - val_loss: 1314085632.0000\n",
      "Epoch 881/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 497242560.0000 - val_loss: 1347071232.0000\n",
      "Epoch 882/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 483022784.0000 - val_loss: 1393188224.0000\n",
      "Epoch 883/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 492411744.0000 - val_loss: 1298785152.0000\n",
      "Epoch 884/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 497059424.0000 - val_loss: 1328417920.0000\n",
      "Epoch 885/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 486924192.0000 - val_loss: 1347875968.0000\n",
      "Epoch 886/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 490247776.0000 - val_loss: 1290335488.0000\n",
      "Epoch 887/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 490546080.0000 - val_loss: 1350990208.0000\n",
      "Epoch 888/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 475825984.0000 - val_loss: 1294733568.0000\n",
      "Epoch 889/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 489295168.0000 - val_loss: 1292601344.0000\n",
      "Epoch 890/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 503161088.0000 - val_loss: 1319626880.0000\n",
      "Epoch 891/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 505850432.0000 - val_loss: 1310690048.0000\n",
      "Epoch 892/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 498662784.0000 - val_loss: 1286219776.0000\n",
      "Epoch 893/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 481245952.0000 - val_loss: 1292918400.0000\n",
      "Epoch 894/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 522611488.0000 - val_loss: 1340198656.0000\n",
      "Epoch 895/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 482484992.0000 - val_loss: 1305656960.0000\n",
      "Epoch 896/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 493128544.0000 - val_loss: 1410918784.0000\n",
      "Epoch 897/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 493794784.0000 - val_loss: 1308698880.0000\n",
      "Epoch 898/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 471045280.0000 - val_loss: 1296096384.0000\n",
      "Epoch 899/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 489641408.0000 - val_loss: 1341086336.0000\n",
      "Epoch 900/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 490904224.0000 - val_loss: 1352393344.0000\n",
      "Epoch 901/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 489851744.0000 - val_loss: 1301534080.0000\n",
      "Epoch 902/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 476165088.0000 - val_loss: 1388862848.0000\n",
      "Epoch 903/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 480804512.0000 - val_loss: 1319611136.0000\n",
      "Epoch 904/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 472118112.0000 - val_loss: 1352833024.0000\n",
      "Epoch 905/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 482477280.0000 - val_loss: 1341363584.0000\n",
      "Epoch 906/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 483346944.0000 - val_loss: 1375089664.0000\n",
      "Epoch 907/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 485865120.0000 - val_loss: 1286988672.0000\n",
      "Epoch 908/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 468374208.0000 - val_loss: 1280511232.0000\n",
      "Epoch 909/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 480623232.0000 - val_loss: 1289372160.0000\n",
      "Epoch 910/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 473006528.0000 - val_loss: 1317753088.0000\n",
      "Epoch 911/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 475094592.0000 - val_loss: 1277120384.0000\n",
      "Epoch 912/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 476313440.0000 - val_loss: 1290829696.0000\n",
      "Epoch 913/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 482894976.0000 - val_loss: 1302363264.0000\n",
      "Epoch 914/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 462969504.0000 - val_loss: 1322698368.0000\n",
      "Epoch 915/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 470059648.0000 - val_loss: 1261152256.0000\n",
      "Epoch 916/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 470109952.0000 - val_loss: 1273883648.0000\n",
      "Epoch 917/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 468530208.0000 - val_loss: 1275667200.0000\n",
      "Epoch 918/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 481446944.0000 - val_loss: 1280870272.0000\n",
      "Epoch 919/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 462480160.0000 - val_loss: 1273142912.0000\n",
      "Epoch 920/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 477548640.0000 - val_loss: 1259479808.0000\n",
      "Epoch 921/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 471409152.0000 - val_loss: 1309786368.0000\n",
      "Epoch 922/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 466062144.0000 - val_loss: 1309661568.0000\n",
      "Epoch 923/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 485742240.0000 - val_loss: 1465016576.0000\n",
      "Epoch 924/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 475921728.0000 - val_loss: 1266669056.0000\n",
      "Epoch 925/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 459574976.0000 - val_loss: 1361359744.0000\n",
      "Epoch 926/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 478458912.0000 - val_loss: 1322636160.0000\n",
      "Epoch 927/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 480197568.0000 - val_loss: 1305354112.0000\n",
      "Epoch 928/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 489378176.0000 - val_loss: 1285154816.0000\n",
      "Epoch 929/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 455994016.0000 - val_loss: 1268627456.0000\n",
      "Epoch 930/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 469953696.0000 - val_loss: 1262942976.0000\n",
      "Epoch 931/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 461413312.0000 - val_loss: 1274683008.0000\n",
      "Epoch 932/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 454583968.0000 - val_loss: 1277655168.0000\n",
      "Epoch 933/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 474451424.0000 - val_loss: 1396813568.0000\n",
      "Epoch 934/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 460206304.0000 - val_loss: 1278485504.0000\n",
      "Epoch 935/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 463623584.0000 - val_loss: 1266473472.0000\n",
      "Epoch 936/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 470794560.0000 - val_loss: 1293161088.0000\n",
      "Epoch 937/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 464056512.0000 - val_loss: 1279244800.0000\n",
      "Epoch 938/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 456967648.0000 - val_loss: 1310272512.0000\n",
      "Epoch 939/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 498444672.0000 - val_loss: 1275792000.0000\n",
      "Epoch 940/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 466504384.0000 - val_loss: 1297116672.0000\n",
      "Epoch 941/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 456670656.0000 - val_loss: 1264415360.0000\n",
      "Epoch 942/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 463144384.0000 - val_loss: 1266351872.0000\n",
      "Epoch 943/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 458022656.0000 - val_loss: 1291173632.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 944/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 458455936.0000 - val_loss: 1267815296.0000\n",
      "Epoch 945/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 474920992.0000 - val_loss: 1272408704.0000\n",
      "Epoch 946/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 465445312.0000 - val_loss: 1261357824.0000\n",
      "Epoch 947/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 456339616.0000 - val_loss: 1298776576.0000\n",
      "Epoch 948/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 464862144.0000 - val_loss: 1286637184.0000\n",
      "Epoch 949/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 450673760.0000 - val_loss: 1254894720.0000\n",
      "Epoch 950/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 464420352.0000 - val_loss: 1275328896.0000\n",
      "Epoch 951/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 468954784.0000 - val_loss: 1258983296.0000\n",
      "Epoch 952/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 453580320.0000 - val_loss: 1255609728.0000\n",
      "Epoch 953/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 457177248.0000 - val_loss: 1260396928.0000\n",
      "Epoch 954/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 451914304.0000 - val_loss: 1273650944.0000\n",
      "Epoch 955/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 445990016.0000 - val_loss: 1244391424.0000\n",
      "Epoch 956/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 468121696.0000 - val_loss: 1388047232.0000\n",
      "Epoch 957/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 468823488.0000 - val_loss: 1243039872.0000\n",
      "Epoch 958/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 444867744.0000 - val_loss: 1262133760.0000\n",
      "Epoch 959/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 459196512.0000 - val_loss: 1265413504.0000\n",
      "Epoch 960/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 444756736.0000 - val_loss: 1233763200.0000\n",
      "Epoch 961/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 443146400.0000 - val_loss: 1301435392.0000\n",
      "Epoch 962/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 456024864.0000 - val_loss: 1311644928.0000\n",
      "Epoch 963/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 460680096.0000 - val_loss: 1327992704.0000\n",
      "Epoch 964/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 455080672.0000 - val_loss: 1242038784.0000\n",
      "Epoch 965/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 462495584.0000 - val_loss: 1235655424.0000\n",
      "Epoch 966/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 435733696.0000 - val_loss: 1268953344.0000\n",
      "Epoch 967/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 444303744.0000 - val_loss: 1242395776.0000\n",
      "Epoch 968/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 467667360.0000 - val_loss: 1257923200.0000\n",
      "Epoch 969/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 447548928.0000 - val_loss: 1233069824.0000\n",
      "Epoch 970/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 458334272.0000 - val_loss: 1259052160.0000\n",
      "Epoch 971/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 444118528.0000 - val_loss: 1250859136.0000\n",
      "Epoch 972/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 451894720.0000 - val_loss: 1233435392.0000\n",
      "Epoch 973/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 442835744.0000 - val_loss: 1267575296.0000\n",
      "Epoch 974/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 465273888.0000 - val_loss: 1257553664.0000\n",
      "Epoch 975/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 434664512.0000 - val_loss: 1250372864.0000\n",
      "Epoch 976/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 456197664.0000 - val_loss: 1252343680.0000\n",
      "Epoch 977/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 435280512.0000 - val_loss: 1225427840.0000\n",
      "Epoch 978/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 435308576.0000 - val_loss: 1226895104.0000\n",
      "Epoch 979/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 432218560.0000 - val_loss: 1232194560.0000\n",
      "Epoch 980/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 449961184.0000 - val_loss: 1235970304.0000\n",
      "Epoch 981/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 444736416.0000 - val_loss: 1243325184.0000\n",
      "Epoch 982/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 438178592.0000 - val_loss: 1250819328.0000\n",
      "Epoch 983/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 451372064.0000 - val_loss: 1232584832.0000\n",
      "Epoch 984/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 450346048.0000 - val_loss: 1228661888.0000\n",
      "Epoch 985/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 442154112.0000 - val_loss: 1307052032.0000\n",
      "Epoch 986/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 437628096.0000 - val_loss: 1241692800.0000\n",
      "Epoch 987/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 436437088.0000 - val_loss: 1276962432.0000\n",
      "Epoch 988/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 436581088.0000 - val_loss: 1247035776.0000\n",
      "Epoch 989/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 444764672.0000 - val_loss: 1274008192.0000\n",
      "Epoch 990/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 451880320.0000 - val_loss: 1240062720.0000\n",
      "Epoch 991/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 443268736.0000 - val_loss: 1286546688.0000\n",
      "Epoch 992/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 462312896.0000 - val_loss: 1237489792.0000\n",
      "Epoch 993/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 439291712.0000 - val_loss: 1358628608.0000\n",
      "Epoch 994/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 437470304.0000 - val_loss: 1251822976.0000\n",
      "Epoch 995/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 434523648.0000 - val_loss: 1259012608.0000\n",
      "Epoch 996/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 431687552.0000 - val_loss: 1245198592.0000\n",
      "Epoch 997/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 450398368.0000 - val_loss: 1241085568.0000\n",
      "Epoch 998/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 433805376.0000 - val_loss: 1246577536.0000\n",
      "Epoch 999/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 439538304.0000 - val_loss: 1236086912.0000\n",
      "Epoch 1000/2000\n",
      "114/114 [==============================] - 0s 2ms/step - loss: 433722048.0000 - val_loss: 1253500800.0000\n",
      "Epoch 1001/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 433020128.0000 - val_loss: 1241142272.0000\n",
      "Epoch 1002/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 438388992.0000 - val_loss: 1226521216.0000\n",
      "Epoch 1003/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 461402848.0000 - val_loss: 1223694848.0000\n",
      "Epoch 1004/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 432191360.0000 - val_loss: 1238476800.0000\n",
      "Epoch 1005/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 442703936.0000 - val_loss: 1237295360.0000\n",
      "Epoch 1006/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 428322336.0000 - val_loss: 1241524864.0000\n",
      "Epoch 1007/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 432764608.0000 - val_loss: 1239567744.0000\n",
      "Epoch 1008/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 428064480.0000 - val_loss: 1231874304.0000\n",
      "Epoch 1009/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 448024960.0000 - val_loss: 1271465600.0000\n",
      "Epoch 1010/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 442912864.0000 - val_loss: 1237902720.0000\n",
      "Epoch 1011/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 424540032.0000 - val_loss: 1254457856.0000\n",
      "Epoch 1012/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 440251456.0000 - val_loss: 1240416256.0000\n",
      "Epoch 1013/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 437523776.0000 - val_loss: 1321321088.0000\n",
      "Epoch 1014/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 439753216.0000 - val_loss: 1261717632.0000\n",
      "Epoch 1015/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 429284928.0000 - val_loss: 1231067520.0000\n",
      "Epoch 1016/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 420883936.0000 - val_loss: 1308630400.0000\n",
      "Epoch 1017/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 431964448.0000 - val_loss: 1232733312.0000\n",
      "Epoch 1018/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 430414624.0000 - val_loss: 1234351232.0000\n",
      "Epoch 1019/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 416624480.0000 - val_loss: 1234938880.0000\n",
      "Epoch 1020/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 416221888.0000 - val_loss: 1229865984.0000\n",
      "Epoch 1021/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 419462752.0000 - val_loss: 1257010432.0000\n",
      "Epoch 1022/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 433978176.0000 - val_loss: 1252743808.0000\n",
      "Epoch 1023/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 444350048.0000 - val_loss: 1253627264.0000\n",
      "Epoch 1024/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 414031456.0000 - val_loss: 1285040512.0000\n",
      "Epoch 1025/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 419831744.0000 - val_loss: 1267515008.0000\n",
      "Epoch 1026/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 417707008.0000 - val_loss: 1390424192.0000\n",
      "Epoch 1027/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 421902912.0000 - val_loss: 1251218816.0000\n",
      "Epoch 1028/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 422754624.0000 - val_loss: 1286750592.0000\n",
      "Epoch 1029/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 443468736.0000 - val_loss: 1224009600.0000\n",
      "Epoch 1030/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 435923232.0000 - val_loss: 1219116160.0000\n",
      "Epoch 1031/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 417851424.0000 - val_loss: 1218753792.0000\n",
      "Epoch 1032/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 420245344.0000 - val_loss: 1453108352.0000\n",
      "Epoch 1033/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 430079232.0000 - val_loss: 1278180736.0000\n",
      "Epoch 1034/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 430702240.0000 - val_loss: 1235700736.0000\n",
      "Epoch 1035/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 405705728.0000 - val_loss: 1251272192.0000\n",
      "Epoch 1036/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 416173056.0000 - val_loss: 1216458368.0000\n",
      "Epoch 1037/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 413401376.0000 - val_loss: 1235916288.0000\n",
      "Epoch 1038/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 415956832.0000 - val_loss: 1283399040.0000\n",
      "Epoch 1039/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 416754144.0000 - val_loss: 1452594560.0000\n",
      "Epoch 1040/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 440238496.0000 - val_loss: 1251001856.0000\n",
      "Epoch 1041/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 407349376.0000 - val_loss: 1216126976.0000\n",
      "Epoch 1042/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 410495616.0000 - val_loss: 1250044416.0000\n",
      "Epoch 1043/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 423817600.0000 - val_loss: 1220058496.0000\n",
      "Epoch 1044/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 418395136.0000 - val_loss: 1260756224.0000\n",
      "Epoch 1045/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 413428032.0000 - val_loss: 1263660928.0000\n",
      "Epoch 1046/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 402120480.0000 - val_loss: 1276812672.0000\n",
      "Epoch 1047/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 410156128.0000 - val_loss: 1242026496.0000\n",
      "Epoch 1048/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 409584640.0000 - val_loss: 1231043072.0000\n",
      "Epoch 1049/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 413719328.0000 - val_loss: 1281451520.0000\n",
      "Epoch 1050/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 444649728.0000 - val_loss: 1241710208.0000\n",
      "Epoch 1051/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 406549504.0000 - val_loss: 1212183296.0000\n",
      "Epoch 1052/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 427848992.0000 - val_loss: 1226295168.0000\n",
      "Epoch 1053/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 403588288.0000 - val_loss: 1210282112.0000\n",
      "Epoch 1054/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 420206592.0000 - val_loss: 1224848640.0000\n",
      "Epoch 1055/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 406595648.0000 - val_loss: 1232691456.0000\n",
      "Epoch 1056/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 406602208.0000 - val_loss: 1230887808.0000\n",
      "Epoch 1057/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 416790144.0000 - val_loss: 1235325312.0000\n",
      "Epoch 1058/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 420189152.0000 - val_loss: 1319179264.0000\n",
      "Epoch 1059/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 420161024.0000 - val_loss: 1212579840.0000\n",
      "Epoch 1060/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 416440192.0000 - val_loss: 1219910400.0000\n",
      "Epoch 1061/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 414560128.0000 - val_loss: 1226825600.0000\n",
      "Epoch 1062/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 430976160.0000 - val_loss: 1215305344.0000\n",
      "Epoch 1063/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 415993280.0000 - val_loss: 1258177664.0000\n",
      "Epoch 1064/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 420810816.0000 - val_loss: 1250121856.0000\n",
      "Epoch 1065/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 422234560.0000 - val_loss: 1228919168.0000\n",
      "Epoch 1066/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 418575552.0000 - val_loss: 1227335680.0000\n",
      "Epoch 1067/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 420376448.0000 - val_loss: 1248849024.0000\n",
      "Epoch 1068/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 407791296.0000 - val_loss: 1257499904.0000\n",
      "Epoch 1069/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 409328000.0000 - val_loss: 1251902336.0000\n",
      "Epoch 1070/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 407346688.0000 - val_loss: 1235683584.0000\n",
      "Epoch 1071/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 396734272.0000 - val_loss: 1236616576.0000\n",
      "Epoch 1072/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 409530848.0000 - val_loss: 1223463808.0000\n",
      "Epoch 1073/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 408968800.0000 - val_loss: 1225256832.0000\n",
      "Epoch 1074/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 423226272.0000 - val_loss: 1303892352.0000\n",
      "Epoch 1075/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 402978368.0000 - val_loss: 1272428288.0000\n",
      "Epoch 1076/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 396785568.0000 - val_loss: 1210103552.0000\n",
      "Epoch 1077/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 403307808.0000 - val_loss: 1235823744.0000\n",
      "Epoch 1078/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 415164416.0000 - val_loss: 1218800768.0000\n",
      "Epoch 1079/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 418857824.0000 - val_loss: 1226956928.0000\n",
      "Epoch 1080/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 407136576.0000 - val_loss: 1316057216.0000\n",
      "Epoch 1081/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 399401216.0000 - val_loss: 1240296448.0000\n",
      "Epoch 1082/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 413112512.0000 - val_loss: 1271906048.0000\n",
      "Epoch 1083/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 393877632.0000 - val_loss: 1223495552.0000\n",
      "Epoch 1084/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 397317152.0000 - val_loss: 1226131584.0000\n",
      "Epoch 1085/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 410611360.0000 - val_loss: 1232737280.0000\n",
      "Epoch 1086/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 385944128.0000 - val_loss: 1229655168.0000\n",
      "Epoch 1087/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 393002432.0000 - val_loss: 1241106688.0000\n",
      "Epoch 1088/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 415023296.0000 - val_loss: 1239359104.0000\n",
      "Epoch 1089/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 400058496.0000 - val_loss: 1328921472.0000\n",
      "Epoch 1090/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 411525344.0000 - val_loss: 1280559488.0000\n",
      "Epoch 1091/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 404455392.0000 - val_loss: 1282732416.0000\n",
      "Epoch 1092/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 398256864.0000 - val_loss: 1223103104.0000\n",
      "Epoch 1093/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 387177056.0000 - val_loss: 1216762880.0000\n",
      "Epoch 1094/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 402021536.0000 - val_loss: 1307297152.0000\n",
      "Epoch 1095/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 400327296.0000 - val_loss: 1214810880.0000\n",
      "Epoch 1096/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 422230816.0000 - val_loss: 1221970944.0000\n",
      "Epoch 1097/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 402700896.0000 - val_loss: 1232616576.0000\n",
      "Epoch 1098/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 426720288.0000 - val_loss: 1258931584.0000\n",
      "Epoch 1099/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 399184576.0000 - val_loss: 1207851136.0000\n",
      "Epoch 1100/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 402365856.0000 - val_loss: 1218168576.0000\n",
      "Epoch 1101/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 394409696.0000 - val_loss: 1208400000.0000\n",
      "Epoch 1102/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 406007680.0000 - val_loss: 1229105536.0000\n",
      "Epoch 1103/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 393259584.0000 - val_loss: 1260476672.0000\n",
      "Epoch 1104/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 395078176.0000 - val_loss: 1219406976.0000\n",
      "Epoch 1105/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 383527712.0000 - val_loss: 1285605632.0000\n",
      "Epoch 1106/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 387562240.0000 - val_loss: 1271020416.0000\n",
      "Epoch 1107/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 407509600.0000 - val_loss: 1210309888.0000\n",
      "Epoch 1108/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 380862624.0000 - val_loss: 1207514496.0000\n",
      "Epoch 1109/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 401626496.0000 - val_loss: 1277101824.0000\n",
      "Epoch 1110/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 406278752.0000 - val_loss: 1227403520.0000\n",
      "Epoch 1111/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 389890560.0000 - val_loss: 1221323008.0000\n",
      "Epoch 1112/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 383707040.0000 - val_loss: 1222784000.0000\n",
      "Epoch 1113/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 382345984.0000 - val_loss: 1229259008.0000\n",
      "Epoch 1114/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 393941088.0000 - val_loss: 1226684800.0000\n",
      "Epoch 1115/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 402990304.0000 - val_loss: 1352587136.0000\n",
      "Epoch 1116/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 452223680.0000 - val_loss: 1322906368.0000\n",
      "Epoch 1117/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 404773536.0000 - val_loss: 1246500608.0000\n",
      "Epoch 1118/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 408385216.0000 - val_loss: 1251570560.0000\n",
      "Epoch 1119/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 400253888.0000 - val_loss: 1240373504.0000\n",
      "Epoch 1120/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 405549760.0000 - val_loss: 1270738304.0000\n",
      "Epoch 1121/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 388911872.0000 - val_loss: 1207169792.0000\n",
      "Epoch 1122/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 388449088.0000 - val_loss: 1211422208.0000\n",
      "Epoch 1123/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 390416736.0000 - val_loss: 1239118720.0000\n",
      "Epoch 1124/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 385252000.0000 - val_loss: 1247996544.0000\n",
      "Epoch 1125/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 395316768.0000 - val_loss: 1336193792.0000\n",
      "Epoch 1126/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 399042368.0000 - val_loss: 1230222464.0000\n",
      "Epoch 1127/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 389321088.0000 - val_loss: 1350466048.0000\n",
      "Epoch 1128/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 408772576.0000 - val_loss: 1255222528.0000\n",
      "Epoch 1129/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 392786464.0000 - val_loss: 1232255488.0000\n",
      "Epoch 1130/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 408274080.0000 - val_loss: 1257636096.0000\n",
      "Epoch 1131/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 386974112.0000 - val_loss: 1237556096.0000\n",
      "Epoch 1132/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 392053056.0000 - val_loss: 1290635648.0000\n",
      "Epoch 1133/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 389258848.0000 - val_loss: 1252583296.0000\n",
      "Epoch 1134/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 386124352.0000 - val_loss: 1232932480.0000\n",
      "Epoch 1135/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 417852192.0000 - val_loss: 1216199552.0000\n",
      "Epoch 1136/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 381494272.0000 - val_loss: 1214881536.0000\n",
      "Epoch 1137/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 375866016.0000 - val_loss: 1201000192.0000\n",
      "Epoch 1138/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 380570464.0000 - val_loss: 1203614464.0000\n",
      "Epoch 1139/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 377833760.0000 - val_loss: 1200897920.0000\n",
      "Epoch 1140/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 392217792.0000 - val_loss: 1210204800.0000\n",
      "Epoch 1141/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 406222176.0000 - val_loss: 1200364288.0000\n",
      "Epoch 1142/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 385904832.0000 - val_loss: 1206960512.0000\n",
      "Epoch 1143/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 380893600.0000 - val_loss: 1198024448.0000\n",
      "Epoch 1144/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 378441440.0000 - val_loss: 1216797568.0000\n",
      "Epoch 1145/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 370463744.0000 - val_loss: 1213500160.0000\n",
      "Epoch 1146/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 390822336.0000 - val_loss: 1212281984.0000\n",
      "Epoch 1147/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 391758848.0000 - val_loss: 1216365440.0000\n",
      "Epoch 1148/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 372866656.0000 - val_loss: 1207406464.0000\n",
      "Epoch 1149/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 382991520.0000 - val_loss: 1247968768.0000\n",
      "Epoch 1150/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 384071200.0000 - val_loss: 1219505792.0000\n",
      "Epoch 1151/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 388978400.0000 - val_loss: 1313397760.0000\n",
      "Epoch 1152/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 382480544.0000 - val_loss: 1264571008.0000\n",
      "Epoch 1153/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 389461344.0000 - val_loss: 1231809536.0000\n",
      "Epoch 1154/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 397846336.0000 - val_loss: 1222742272.0000\n",
      "Epoch 1155/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 368429728.0000 - val_loss: 1223284736.0000\n",
      "Epoch 1156/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 378253344.0000 - val_loss: 1222155008.0000\n",
      "Epoch 1157/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 365634048.0000 - val_loss: 1201015680.0000\n",
      "Epoch 1158/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 382011936.0000 - val_loss: 1322891904.0000\n",
      "Epoch 1159/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 389925120.0000 - val_loss: 1387223424.0000\n",
      "Epoch 1160/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 367440800.0000 - val_loss: 1206121984.0000\n",
      "Epoch 1161/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 375328000.0000 - val_loss: 1218127232.0000\n",
      "Epoch 1162/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 364447872.0000 - val_loss: 1224187008.0000\n",
      "Epoch 1163/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 377575488.0000 - val_loss: 1261819520.0000\n",
      "Epoch 1164/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 381875872.0000 - val_loss: 1306994944.0000\n",
      "Epoch 1165/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 381342816.0000 - val_loss: 1272759424.0000\n",
      "Epoch 1166/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 381857056.0000 - val_loss: 1302222336.0000\n",
      "Epoch 1167/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 361308416.0000 - val_loss: 1263691392.0000\n",
      "Epoch 1168/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 372871520.0000 - val_loss: 1214431744.0000\n",
      "Epoch 1169/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 374901440.0000 - val_loss: 1201535616.0000\n",
      "Epoch 1170/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 365707808.0000 - val_loss: 1223401728.0000\n",
      "Epoch 1171/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 370455424.0000 - val_loss: 1239049856.0000\n",
      "Epoch 1172/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 371800096.0000 - val_loss: 1239102336.0000\n",
      "Epoch 1173/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 401995872.0000 - val_loss: 1211308416.0000\n",
      "Epoch 1174/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 393107968.0000 - val_loss: 1216050944.0000\n",
      "Epoch 1175/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 367049152.0000 - val_loss: 1216947584.0000\n",
      "Epoch 1176/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 362529056.0000 - val_loss: 1248036864.0000\n",
      "Epoch 1177/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 379642304.0000 - val_loss: 1214117504.0000\n",
      "Epoch 1178/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 358062144.0000 - val_loss: 1207960448.0000\n",
      "Epoch 1179/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 368306432.0000 - val_loss: 1234870528.0000\n",
      "Epoch 1180/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 384163072.0000 - val_loss: 1214969984.0000\n",
      "Epoch 1181/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 371306560.0000 - val_loss: 1314108288.0000\n",
      "Epoch 1182/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 381696992.0000 - val_loss: 1210732288.0000\n",
      "Epoch 1183/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 364963104.0000 - val_loss: 1202771072.0000\n",
      "Epoch 1184/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 419154688.0000 - val_loss: 1256614528.0000\n",
      "Epoch 1185/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 365919360.0000 - val_loss: 1225162752.0000\n",
      "Epoch 1186/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 361270240.0000 - val_loss: 1225358848.0000\n",
      "Epoch 1187/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 379394432.0000 - val_loss: 1232720384.0000\n",
      "Epoch 1188/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 371694624.0000 - val_loss: 1217213568.0000\n",
      "Epoch 1189/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 360826624.0000 - val_loss: 1212789504.0000\n",
      "Epoch 1190/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 365839328.0000 - val_loss: 1197692544.0000\n",
      "Epoch 1191/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 361199488.0000 - val_loss: 1204215296.0000\n",
      "Epoch 1192/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 374858432.0000 - val_loss: 1206212224.0000\n",
      "Epoch 1193/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 362434400.0000 - val_loss: 1218709760.0000\n",
      "Epoch 1194/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 372742912.0000 - val_loss: 1245744384.0000\n",
      "Epoch 1195/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 369451200.0000 - val_loss: 1215236736.0000\n",
      "Epoch 1196/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 363782976.0000 - val_loss: 1214410880.0000\n",
      "Epoch 1197/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 353496928.0000 - val_loss: 1213932928.0000\n",
      "Epoch 1198/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 363181024.0000 - val_loss: 1229670272.0000\n",
      "Epoch 1199/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 357523520.0000 - val_loss: 1302110848.0000\n",
      "Epoch 1200/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 367167136.0000 - val_loss: 1203460224.0000\n",
      "Epoch 1201/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 363008352.0000 - val_loss: 1231179008.0000\n",
      "Epoch 1202/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 366421728.0000 - val_loss: 1215508096.0000\n",
      "Epoch 1203/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 367892864.0000 - val_loss: 1203228800.0000\n",
      "Epoch 1204/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 358147712.0000 - val_loss: 1214722048.0000\n",
      "Epoch 1205/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 377323648.0000 - val_loss: 1231414784.0000\n",
      "Epoch 1206/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 363967232.0000 - val_loss: 1199483392.0000\n",
      "Epoch 1207/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 367508608.0000 - val_loss: 1216965760.0000\n",
      "Epoch 1208/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 363562432.0000 - val_loss: 1274703232.0000\n",
      "Epoch 1209/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 366331104.0000 - val_loss: 1224344192.0000\n",
      "Epoch 1210/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 364430752.0000 - val_loss: 1215518720.0000\n",
      "Epoch 1211/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 354650848.0000 - val_loss: 1214161792.0000\n",
      "Epoch 1212/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 372173120.0000 - val_loss: 1301326592.0000\n",
      "Epoch 1213/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 383031424.0000 - val_loss: 1219618560.0000\n",
      "Epoch 1214/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 351882400.0000 - val_loss: 1204518272.0000\n",
      "Epoch 1215/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 374368992.0000 - val_loss: 1214672768.0000\n",
      "Epoch 1216/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 359325920.0000 - val_loss: 1197621504.0000\n",
      "Epoch 1217/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 358336480.0000 - val_loss: 1228743552.0000\n",
      "Epoch 1218/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 373557024.0000 - val_loss: 1362847232.0000\n",
      "Epoch 1219/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 369117152.0000 - val_loss: 1195317632.0000\n",
      "Epoch 1220/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 352391104.0000 - val_loss: 1283242496.0000\n",
      "Epoch 1221/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 356117056.0000 - val_loss: 1220322304.0000\n",
      "Epoch 1222/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 356470016.0000 - val_loss: 1204518016.0000\n",
      "Epoch 1223/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 359981856.0000 - val_loss: 1208308096.0000\n",
      "Epoch 1224/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 357259968.0000 - val_loss: 1211903616.0000\n",
      "Epoch 1225/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 369918016.0000 - val_loss: 1214075904.0000\n",
      "Epoch 1226/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 351928864.0000 - val_loss: 1228321152.0000\n",
      "Epoch 1227/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 362122048.0000 - val_loss: 1201869696.0000\n",
      "Epoch 1228/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 357571072.0000 - val_loss: 1193656960.0000\n",
      "Epoch 1229/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 357466080.0000 - val_loss: 1185929088.0000\n",
      "Epoch 1230/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 353528192.0000 - val_loss: 1203050624.0000\n",
      "Epoch 1231/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 353916000.0000 - val_loss: 1196835712.0000\n",
      "Epoch 1232/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 361126080.0000 - val_loss: 1181402240.0000\n",
      "Epoch 1233/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 349988480.0000 - val_loss: 1239906432.0000\n",
      "Epoch 1234/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 366141888.0000 - val_loss: 1197900288.0000\n",
      "Epoch 1235/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 357922304.0000 - val_loss: 1224828672.0000\n",
      "Epoch 1236/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 353315552.0000 - val_loss: 1199141760.0000\n",
      "Epoch 1237/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 348900960.0000 - val_loss: 1189221504.0000\n",
      "Epoch 1238/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 352410688.0000 - val_loss: 1195161344.0000\n",
      "Epoch 1239/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 360585728.0000 - val_loss: 1283517440.0000\n",
      "Epoch 1240/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 372554912.0000 - val_loss: 1261743744.0000\n",
      "Epoch 1241/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 375958752.0000 - val_loss: 1238330240.0000\n",
      "Epoch 1242/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 351042208.0000 - val_loss: 1192175104.0000\n",
      "Epoch 1243/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 356786560.0000 - val_loss: 1247015936.0000\n",
      "Epoch 1244/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 356326272.0000 - val_loss: 1180082688.0000\n",
      "Epoch 1245/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 363829888.0000 - val_loss: 1197327872.0000\n",
      "Epoch 1246/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 354195872.0000 - val_loss: 1212462848.0000\n",
      "Epoch 1247/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 333195136.0000 - val_loss: 1258414720.0000\n",
      "Epoch 1248/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 376489152.0000 - val_loss: 1211596160.0000\n",
      "Epoch 1249/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 353367072.0000 - val_loss: 1254450688.0000\n",
      "Epoch 1250/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 351544800.0000 - val_loss: 1187086848.0000\n",
      "Epoch 1251/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 341317440.0000 - val_loss: 1278522752.0000\n",
      "Epoch 1252/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 373334272.0000 - val_loss: 1227129216.0000\n",
      "Epoch 1253/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 354613408.0000 - val_loss: 1235513472.0000\n",
      "Epoch 1254/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 348612224.0000 - val_loss: 1202434176.0000\n",
      "Epoch 1255/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 341412352.0000 - val_loss: 1184823168.0000\n",
      "Epoch 1256/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 354347776.0000 - val_loss: 1199500672.0000\n",
      "Epoch 1257/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 340119328.0000 - val_loss: 1260329088.0000\n",
      "Epoch 1258/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 356944256.0000 - val_loss: 1251435776.0000\n",
      "Epoch 1259/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 354073888.0000 - val_loss: 1200942592.0000\n",
      "Epoch 1260/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 336766240.0000 - val_loss: 1200784640.0000\n",
      "Epoch 1261/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 353187776.0000 - val_loss: 1263518848.0000\n",
      "Epoch 1262/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 338409280.0000 - val_loss: 1264462464.0000\n",
      "Epoch 1263/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 361217600.0000 - val_loss: 1196972544.0000\n",
      "Epoch 1264/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 342062208.0000 - val_loss: 1189413632.0000\n",
      "Epoch 1265/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 340055872.0000 - val_loss: 1207057920.0000\n",
      "Epoch 1266/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 352338976.0000 - val_loss: 1242456576.0000\n",
      "Epoch 1267/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 346829696.0000 - val_loss: 1234941056.0000\n",
      "Epoch 1268/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 358383648.0000 - val_loss: 1185662080.0000\n",
      "Epoch 1269/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 349515008.0000 - val_loss: 1199666432.0000\n",
      "Epoch 1270/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 347268160.0000 - val_loss: 1201904128.0000\n",
      "Epoch 1271/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 339883584.0000 - val_loss: 1194015488.0000\n",
      "Epoch 1272/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 343869024.0000 - val_loss: 1182910976.0000\n",
      "Epoch 1273/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 341781248.0000 - val_loss: 1191021568.0000\n",
      "Epoch 1274/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 354078944.0000 - val_loss: 1265203584.0000\n",
      "Epoch 1275/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 338882016.0000 - val_loss: 1192795008.0000\n",
      "Epoch 1276/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 336246240.0000 - val_loss: 1239617664.0000\n",
      "Epoch 1277/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 330951232.0000 - val_loss: 1215586944.0000\n",
      "Epoch 1278/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 353394624.0000 - val_loss: 1195335040.0000\n",
      "Epoch 1279/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 329137536.0000 - val_loss: 1169490176.0000\n",
      "Epoch 1280/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 333774208.0000 - val_loss: 1174536576.0000\n",
      "Epoch 1281/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 345060672.0000 - val_loss: 1182769664.0000\n",
      "Epoch 1282/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 335334784.0000 - val_loss: 1178653440.0000\n",
      "Epoch 1283/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 332050272.0000 - val_loss: 1194743552.0000\n",
      "Epoch 1284/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 342821280.0000 - val_loss: 1216392192.0000\n",
      "Epoch 1285/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 346960640.0000 - val_loss: 1222006912.0000\n",
      "Epoch 1286/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 345925344.0000 - val_loss: 1190373120.0000\n",
      "Epoch 1287/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 334651712.0000 - val_loss: 1192368384.0000\n",
      "Epoch 1288/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 352491616.0000 - val_loss: 1192082048.0000\n",
      "Epoch 1289/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 328963392.0000 - val_loss: 1254446848.0000\n",
      "Epoch 1290/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 326720896.0000 - val_loss: 1262262656.0000\n",
      "Epoch 1291/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 335376800.0000 - val_loss: 1208037760.0000\n",
      "Epoch 1292/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 335075616.0000 - val_loss: 1199620736.0000\n",
      "Epoch 1293/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 342718816.0000 - val_loss: 1178892032.0000\n",
      "Epoch 1294/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 336265792.0000 - val_loss: 1196276608.0000\n",
      "Epoch 1295/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 327223040.0000 - val_loss: 1168889344.0000\n",
      "Epoch 1296/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 337878592.0000 - val_loss: 1185598720.0000\n",
      "Epoch 1297/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 338157344.0000 - val_loss: 1202445056.0000\n",
      "Epoch 1298/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 333468832.0000 - val_loss: 1192586368.0000\n",
      "Epoch 1299/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 332543232.0000 - val_loss: 1201996800.0000\n",
      "Epoch 1300/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 339560000.0000 - val_loss: 1199939328.0000\n",
      "Epoch 1301/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 332711264.0000 - val_loss: 1181958400.0000\n",
      "Epoch 1302/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 336242240.0000 - val_loss: 1182164992.0000\n",
      "Epoch 1303/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 366009600.0000 - val_loss: 1217214592.0000\n",
      "Epoch 1304/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 331055168.0000 - val_loss: 1206728064.0000\n",
      "Epoch 1305/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 342274112.0000 - val_loss: 1193355776.0000\n",
      "Epoch 1306/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 334139744.0000 - val_loss: 1199768320.0000\n",
      "Epoch 1307/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 341519648.0000 - val_loss: 1213563648.0000\n",
      "Epoch 1308/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 331661696.0000 - val_loss: 1212831488.0000\n",
      "Epoch 1309/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 341047328.0000 - val_loss: 1218366464.0000\n",
      "Epoch 1310/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 348866368.0000 - val_loss: 1217181952.0000\n",
      "Epoch 1311/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 323685472.0000 - val_loss: 1186774656.0000\n",
      "Epoch 1312/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 333856416.0000 - val_loss: 1189168640.0000\n",
      "Epoch 1313/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 337809344.0000 - val_loss: 1198980480.0000\n",
      "Epoch 1314/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 334983680.0000 - val_loss: 1195104896.0000\n",
      "Epoch 1315/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 325188928.0000 - val_loss: 1198955264.0000\n",
      "Epoch 1316/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 337103040.0000 - val_loss: 1234866048.0000\n",
      "Epoch 1317/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 340016416.0000 - val_loss: 1230878592.0000\n",
      "Epoch 1318/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 329072928.0000 - val_loss: 1185705728.0000\n",
      "Epoch 1319/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 334764320.0000 - val_loss: 1208465664.0000\n",
      "Epoch 1320/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 336271200.0000 - val_loss: 1191426560.0000\n",
      "Epoch 1321/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 320068960.0000 - val_loss: 1193938944.0000\n",
      "Epoch 1322/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 328061376.0000 - val_loss: 1195492992.0000\n",
      "Epoch 1323/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 338946208.0000 - val_loss: 1188935424.0000\n",
      "Epoch 1324/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 321988096.0000 - val_loss: 1200539008.0000\n",
      "Epoch 1325/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 329267968.0000 - val_loss: 1175467136.0000\n",
      "Epoch 1326/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 342951072.0000 - val_loss: 1238897536.0000\n",
      "Epoch 1327/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 339547968.0000 - val_loss: 1187139456.0000\n",
      "Epoch 1328/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 328623936.0000 - val_loss: 1175858944.0000\n",
      "Epoch 1329/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 320037632.0000 - val_loss: 1172899584.0000\n",
      "Epoch 1330/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 328182080.0000 - val_loss: 1221721472.0000\n",
      "Epoch 1331/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 330913696.0000 - val_loss: 1213318272.0000\n",
      "Epoch 1332/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 338996000.0000 - val_loss: 1212240640.0000\n",
      "Epoch 1333/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 322293792.0000 - val_loss: 1294453632.0000\n",
      "Epoch 1334/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 327898880.0000 - val_loss: 1180260480.0000\n",
      "Epoch 1335/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 334746016.0000 - val_loss: 1179658752.0000\n",
      "Epoch 1336/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 345267264.0000 - val_loss: 1173782016.0000\n",
      "Epoch 1337/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 333848000.0000 - val_loss: 1196316416.0000\n",
      "Epoch 1338/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 334089920.0000 - val_loss: 1182785408.0000\n",
      "Epoch 1339/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 340609376.0000 - val_loss: 1177836032.0000\n",
      "Epoch 1340/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 317638880.0000 - val_loss: 1174355328.0000\n",
      "Epoch 1341/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 322703936.0000 - val_loss: 1175001984.0000\n",
      "Epoch 1342/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 329534400.0000 - val_loss: 1196469504.0000\n",
      "Epoch 1343/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 333013376.0000 - val_loss: 1184160384.0000\n",
      "Epoch 1344/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 312310624.0000 - val_loss: 1279876608.0000\n",
      "Epoch 1345/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 336320928.0000 - val_loss: 1212231808.0000\n",
      "Epoch 1346/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 337165888.0000 - val_loss: 1159160576.0000\n",
      "Epoch 1347/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 324549728.0000 - val_loss: 1176730240.0000\n",
      "Epoch 1348/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 330131424.0000 - val_loss: 1202994688.0000\n",
      "Epoch 1349/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 329753728.0000 - val_loss: 1178042624.0000\n",
      "Epoch 1350/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 339204992.0000 - val_loss: 1220018816.0000\n",
      "Epoch 1351/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 326362944.0000 - val_loss: 1183649664.0000\n",
      "Epoch 1352/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 321899520.0000 - val_loss: 1196765440.0000\n",
      "Epoch 1353/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 317861184.0000 - val_loss: 1228423680.0000\n",
      "Epoch 1354/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 319236128.0000 - val_loss: 1182017536.0000\n",
      "Epoch 1355/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 319269632.0000 - val_loss: 1176739968.0000\n",
      "Epoch 1356/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 323621920.0000 - val_loss: 1178178560.0000\n",
      "Epoch 1357/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 311105824.0000 - val_loss: 1187179264.0000\n",
      "Epoch 1358/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 322020064.0000 - val_loss: 1172718720.0000\n",
      "Epoch 1359/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 325699968.0000 - val_loss: 1160945024.0000\n",
      "Epoch 1360/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 328610400.0000 - val_loss: 1158558464.0000\n",
      "Epoch 1361/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 306841792.0000 - val_loss: 1180517760.0000\n",
      "Epoch 1362/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 318478112.0000 - val_loss: 1245612160.0000\n",
      "Epoch 1363/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 323550112.0000 - val_loss: 1197378688.0000\n",
      "Epoch 1364/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 321929248.0000 - val_loss: 1222565632.0000\n",
      "Epoch 1365/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 321193984.0000 - val_loss: 1225542784.0000\n",
      "Epoch 1366/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 316305088.0000 - val_loss: 1199271040.0000\n",
      "Epoch 1367/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 314580448.0000 - val_loss: 1185595392.0000\n",
      "Epoch 1368/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 316651968.0000 - val_loss: 1174429440.0000\n",
      "Epoch 1369/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 326762304.0000 - val_loss: 1174004352.0000\n",
      "Epoch 1370/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 317613952.0000 - val_loss: 1168124032.0000\n",
      "Epoch 1371/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 332029952.0000 - val_loss: 1172416640.0000\n",
      "Epoch 1372/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 312000128.0000 - val_loss: 1187239680.0000\n",
      "Epoch 1373/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 322044064.0000 - val_loss: 1168755712.0000\n",
      "Epoch 1374/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 341433408.0000 - val_loss: 1182779520.0000\n",
      "Epoch 1375/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 321529408.0000 - val_loss: 1180346496.0000\n",
      "Epoch 1376/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 325035200.0000 - val_loss: 1170363904.0000\n",
      "Epoch 1377/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 314352992.0000 - val_loss: 1186311808.0000\n",
      "Epoch 1378/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 319934144.0000 - val_loss: 1266143360.0000\n",
      "Epoch 1379/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 321652864.0000 - val_loss: 1186455552.0000\n",
      "Epoch 1380/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 335783072.0000 - val_loss: 1227827072.0000\n",
      "Epoch 1381/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 315077216.0000 - val_loss: 1233484160.0000\n",
      "Epoch 1382/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 329032480.0000 - val_loss: 1194441472.0000\n",
      "Epoch 1383/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 318764800.0000 - val_loss: 1198826368.0000\n",
      "Epoch 1384/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 326640736.0000 - val_loss: 1298251648.0000\n",
      "Epoch 1385/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 324275520.0000 - val_loss: 1160348544.0000\n",
      "Epoch 1386/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 313676224.0000 - val_loss: 1196822656.0000\n",
      "Epoch 1387/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 327618400.0000 - val_loss: 1317464576.0000\n",
      "Epoch 1388/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 323666464.0000 - val_loss: 1172670848.0000\n",
      "Epoch 1389/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 307480512.0000 - val_loss: 1190151296.0000\n",
      "Epoch 1390/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 319702112.0000 - val_loss: 1216702720.0000\n",
      "Epoch 1391/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 318755968.0000 - val_loss: 1193563776.0000\n",
      "Epoch 1392/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 305253568.0000 - val_loss: 1165205504.0000\n",
      "Epoch 1393/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 301762016.0000 - val_loss: 1148613888.0000\n",
      "Epoch 1394/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 305574144.0000 - val_loss: 1182937856.0000\n",
      "Epoch 1395/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 303980704.0000 - val_loss: 1205607040.0000\n",
      "Epoch 1396/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 312147616.0000 - val_loss: 1187768192.0000\n",
      "Epoch 1397/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 311346144.0000 - val_loss: 1163917824.0000\n",
      "Epoch 1398/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 331796768.0000 - val_loss: 1150953344.0000\n",
      "Epoch 1399/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 298575776.0000 - val_loss: 1213679232.0000\n",
      "Epoch 1400/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 327629984.0000 - val_loss: 1161079296.0000\n",
      "Epoch 1401/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 307876096.0000 - val_loss: 1173399680.0000\n",
      "Epoch 1402/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 315891488.0000 - val_loss: 1155608192.0000\n",
      "Epoch 1403/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 307086432.0000 - val_loss: 1204693504.0000\n",
      "Epoch 1404/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 320918080.0000 - val_loss: 1272902400.0000\n",
      "Epoch 1405/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 322655872.0000 - val_loss: 1179811456.0000\n",
      "Epoch 1406/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 308015840.0000 - val_loss: 1191381120.0000\n",
      "Epoch 1407/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 306811872.0000 - val_loss: 1172167168.0000\n",
      "Epoch 1408/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 329332096.0000 - val_loss: 1174330240.0000\n",
      "Epoch 1409/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 298989504.0000 - val_loss: 1182796928.0000\n",
      "Epoch 1410/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 297151968.0000 - val_loss: 1164194560.0000\n",
      "Epoch 1411/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 305354016.0000 - val_loss: 1177126016.0000\n",
      "Epoch 1412/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 314528672.0000 - val_loss: 1218741248.0000\n",
      "Epoch 1413/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 305362464.0000 - val_loss: 1202523648.0000\n",
      "Epoch 1414/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 301534464.0000 - val_loss: 1211561856.0000\n",
      "Epoch 1415/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 317076544.0000 - val_loss: 1175201024.0000\n",
      "Epoch 1416/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 303415328.0000 - val_loss: 1166171904.0000\n",
      "Epoch 1417/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 317962720.0000 - val_loss: 1187064192.0000\n",
      "Epoch 1418/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 310970208.0000 - val_loss: 1221994240.0000\n",
      "Epoch 1419/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 313344992.0000 - val_loss: 1172731648.0000\n",
      "Epoch 1420/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 300250144.0000 - val_loss: 1191068800.0000\n",
      "Epoch 1421/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 317140128.0000 - val_loss: 1203555584.0000\n",
      "Epoch 1422/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 297389024.0000 - val_loss: 1235899904.0000\n",
      "Epoch 1423/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 306869376.0000 - val_loss: 1243686656.0000\n",
      "Epoch 1424/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 312256640.0000 - val_loss: 1167687808.0000\n",
      "Epoch 1425/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 304353344.0000 - val_loss: 1232275968.0000\n",
      "Epoch 1426/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 311691168.0000 - val_loss: 1174425600.0000\n",
      "Epoch 1427/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 293168768.0000 - val_loss: 1160720512.0000\n",
      "Epoch 1428/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 299337440.0000 - val_loss: 1180359168.0000\n",
      "Epoch 1429/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 322026688.0000 - val_loss: 1174936064.0000\n",
      "Epoch 1430/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 303863872.0000 - val_loss: 1157481600.0000\n",
      "Epoch 1431/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 298421152.0000 - val_loss: 1160035968.0000\n",
      "Epoch 1432/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 294817952.0000 - val_loss: 1238111232.0000\n",
      "Epoch 1433/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 312213024.0000 - val_loss: 1186047744.0000\n",
      "Epoch 1434/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 298830912.0000 - val_loss: 1167912320.0000\n",
      "Epoch 1435/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 295232128.0000 - val_loss: 1165491712.0000\n",
      "Epoch 1436/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 300308128.0000 - val_loss: 1172810496.0000\n",
      "Epoch 1437/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 310022208.0000 - val_loss: 1237759616.0000\n",
      "Epoch 1438/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 315299104.0000 - val_loss: 1176728960.0000\n",
      "Epoch 1439/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 304620224.0000 - val_loss: 1156683904.0000\n",
      "Epoch 1440/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 311903808.0000 - val_loss: 1166525056.0000\n",
      "Epoch 1441/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 300093568.0000 - val_loss: 1164028032.0000\n",
      "Epoch 1442/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 293417888.0000 - val_loss: 1181313920.0000\n",
      "Epoch 1443/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 307759776.0000 - val_loss: 1171443712.0000\n",
      "Epoch 1444/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 296700000.0000 - val_loss: 1190911872.0000\n",
      "Epoch 1445/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 303881408.0000 - val_loss: 1211470208.0000\n",
      "Epoch 1446/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 293969824.0000 - val_loss: 1162415360.0000\n",
      "Epoch 1447/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 297764288.0000 - val_loss: 1169468544.0000\n",
      "Epoch 1448/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 311896704.0000 - val_loss: 1185613440.0000\n",
      "Epoch 1449/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 303670208.0000 - val_loss: 1162113664.0000\n",
      "Epoch 1450/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 302225216.0000 - val_loss: 1185169408.0000\n",
      "Epoch 1451/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 305583264.0000 - val_loss: 1158366720.0000\n",
      "Epoch 1452/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 288252576.0000 - val_loss: 1176810880.0000\n",
      "Epoch 1453/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 290511680.0000 - val_loss: 1168727040.0000\n",
      "Epoch 1454/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 297836768.0000 - val_loss: 1164197376.0000\n",
      "Epoch 1455/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 285519680.0000 - val_loss: 1174260608.0000\n",
      "Epoch 1456/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 296791296.0000 - val_loss: 1217914624.0000\n",
      "Epoch 1457/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 295460384.0000 - val_loss: 1191460864.0000\n",
      "Epoch 1458/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 303383072.0000 - val_loss: 1172846848.0000\n",
      "Epoch 1459/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 287874752.0000 - val_loss: 1143783936.0000\n",
      "Epoch 1460/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 302660800.0000 - val_loss: 1164519936.0000\n",
      "Epoch 1461/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 326621824.0000 - val_loss: 1172603392.0000\n",
      "Epoch 1462/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 287979008.0000 - val_loss: 1375718144.0000\n",
      "Epoch 1463/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 302936800.0000 - val_loss: 1161841280.0000\n",
      "Epoch 1464/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 301128192.0000 - val_loss: 1163170432.0000\n",
      "Epoch 1465/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 293808896.0000 - val_loss: 1156792448.0000\n",
      "Epoch 1466/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 299575072.0000 - val_loss: 1168823296.0000\n",
      "Epoch 1467/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 300573120.0000 - val_loss: 1153362560.0000\n",
      "Epoch 1468/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 293064928.0000 - val_loss: 1171623168.0000\n",
      "Epoch 1469/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 295857632.0000 - val_loss: 1271860992.0000\n",
      "Epoch 1470/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 293298816.0000 - val_loss: 1148307328.0000\n",
      "Epoch 1471/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 288465792.0000 - val_loss: 1147842176.0000\n",
      "Epoch 1472/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 302305280.0000 - val_loss: 1157557120.0000\n",
      "Epoch 1473/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 302837664.0000 - val_loss: 1150274176.0000\n",
      "Epoch 1474/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 286935360.0000 - val_loss: 1203760896.0000\n",
      "Epoch 1475/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 290953632.0000 - val_loss: 1166806016.0000\n",
      "Epoch 1476/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 301109888.0000 - val_loss: 1162286464.0000\n",
      "Epoch 1477/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 298613056.0000 - val_loss: 1173189632.0000\n",
      "Epoch 1478/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 300179264.0000 - val_loss: 1154826496.0000\n",
      "Epoch 1479/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 288824352.0000 - val_loss: 1150985472.0000\n",
      "Epoch 1480/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 289323968.0000 - val_loss: 1173031808.0000\n",
      "Epoch 1481/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 307512736.0000 - val_loss: 1189076992.0000\n",
      "Epoch 1482/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 320504384.0000 - val_loss: 1152949760.0000\n",
      "Epoch 1483/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 293284480.0000 - val_loss: 1173051904.0000\n",
      "Epoch 1484/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 283574560.0000 - val_loss: 1189626368.0000\n",
      "Epoch 1485/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 295976704.0000 - val_loss: 1176649728.0000\n",
      "Epoch 1486/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 289597792.0000 - val_loss: 1198485248.0000\n",
      "Epoch 1487/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 283282880.0000 - val_loss: 1170610560.0000\n",
      "Epoch 1488/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 296354880.0000 - val_loss: 1163291648.0000\n",
      "Epoch 1489/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 294423936.0000 - val_loss: 1179126272.0000\n",
      "Epoch 1490/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 292793856.0000 - val_loss: 1351792256.0000\n",
      "Epoch 1491/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 289451648.0000 - val_loss: 1211744128.0000\n",
      "Epoch 1492/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 287209152.0000 - val_loss: 1160966272.0000\n",
      "Epoch 1493/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 299617824.0000 - val_loss: 1155302656.0000\n",
      "Epoch 1494/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 293561152.0000 - val_loss: 1181487488.0000\n",
      "Epoch 1495/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 296943968.0000 - val_loss: 1182739968.0000\n",
      "Epoch 1496/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 286936864.0000 - val_loss: 1203275392.0000\n",
      "Epoch 1497/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 283518656.0000 - val_loss: 1172325888.0000\n",
      "Epoch 1498/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 284739104.0000 - val_loss: 1144790144.0000\n",
      "Epoch 1499/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 282640960.0000 - val_loss: 1168908928.0000\n",
      "Epoch 1500/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 286819808.0000 - val_loss: 1158172800.0000\n",
      "Epoch 1501/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 305298080.0000 - val_loss: 1191514496.0000\n",
      "Epoch 1502/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 301691584.0000 - val_loss: 1193406720.0000\n",
      "Epoch 1503/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 288846656.0000 - val_loss: 1226503936.0000\n",
      "Epoch 1504/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 291285824.0000 - val_loss: 1168092544.0000\n",
      "Epoch 1505/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 279009472.0000 - val_loss: 1193385728.0000\n",
      "Epoch 1506/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 279652896.0000 - val_loss: 1183798912.0000\n",
      "Epoch 1507/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 286158976.0000 - val_loss: 1181495808.0000\n",
      "Epoch 1508/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 292736736.0000 - val_loss: 1149951232.0000\n",
      "Epoch 1509/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 276797056.0000 - val_loss: 1191480320.0000\n",
      "Epoch 1510/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 277348000.0000 - val_loss: 1200931840.0000\n",
      "Epoch 1511/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 288503968.0000 - val_loss: 1205826816.0000\n",
      "Epoch 1512/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 292360192.0000 - val_loss: 1220257152.0000\n",
      "Epoch 1513/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 279628000.0000 - val_loss: 1160475136.0000\n",
      "Epoch 1514/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 288607008.0000 - val_loss: 1216761728.0000\n",
      "Epoch 1515/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 290383712.0000 - val_loss: 1184121344.0000\n",
      "Epoch 1516/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 281313888.0000 - val_loss: 1156664320.0000\n",
      "Epoch 1517/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 281164736.0000 - val_loss: 1180479488.0000\n",
      "Epoch 1518/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 282319424.0000 - val_loss: 1192747264.0000\n",
      "Epoch 1519/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 293234304.0000 - val_loss: 1151748096.0000\n",
      "Epoch 1520/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 278598368.0000 - val_loss: 1197899648.0000\n",
      "Epoch 1521/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 279586784.0000 - val_loss: 1180744704.0000\n",
      "Epoch 1522/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 291541088.0000 - val_loss: 1175616128.0000\n",
      "Epoch 1523/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 288143808.0000 - val_loss: 1194760576.0000\n",
      "Epoch 1524/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 280952064.0000 - val_loss: 1187432448.0000\n",
      "Epoch 1525/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 275048608.0000 - val_loss: 1147344896.0000\n",
      "Epoch 1526/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 294518528.0000 - val_loss: 1161363456.0000\n",
      "Epoch 1527/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 272451072.0000 - val_loss: 1189186560.0000\n",
      "Epoch 1528/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 275577568.0000 - val_loss: 1211474048.0000\n",
      "Epoch 1529/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 284412992.0000 - val_loss: 1176141568.0000\n",
      "Epoch 1530/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 277311008.0000 - val_loss: 1241598848.0000\n",
      "Epoch 1531/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 301881632.0000 - val_loss: 1165242880.0000\n",
      "Epoch 1532/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 276347712.0000 - val_loss: 1161722240.0000\n",
      "Epoch 1533/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 282155808.0000 - val_loss: 1149481216.0000\n",
      "Epoch 1534/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 300694912.0000 - val_loss: 1143502976.0000\n",
      "Epoch 1535/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 287714944.0000 - val_loss: 1132357376.0000\n",
      "Epoch 1536/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 286746752.0000 - val_loss: 1150557312.0000\n",
      "Epoch 1537/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 277674048.0000 - val_loss: 1170271232.0000\n",
      "Epoch 1538/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 279516128.0000 - val_loss: 1148151680.0000\n",
      "Epoch 1539/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 288171168.0000 - val_loss: 1181124224.0000\n",
      "Epoch 1540/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 285166368.0000 - val_loss: 1165844736.0000\n",
      "Epoch 1541/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 283008000.0000 - val_loss: 1212729472.0000\n",
      "Epoch 1542/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 278599904.0000 - val_loss: 1185784448.0000\n",
      "Epoch 1543/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 293422912.0000 - val_loss: 1146594944.0000\n",
      "Epoch 1544/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 284466592.0000 - val_loss: 1161641472.0000\n",
      "Epoch 1545/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 270052832.0000 - val_loss: 1157950464.0000\n",
      "Epoch 1546/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 276644928.0000 - val_loss: 1250426368.0000\n",
      "Epoch 1547/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 290530048.0000 - val_loss: 1150583296.0000\n",
      "Epoch 1548/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 282370752.0000 - val_loss: 1157684480.0000\n",
      "Epoch 1549/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 279557280.0000 - val_loss: 1147573120.0000\n",
      "Epoch 1550/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 269393344.0000 - val_loss: 1156035328.0000\n",
      "Epoch 1551/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 303395456.0000 - val_loss: 1266969600.0000\n",
      "Epoch 1552/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 278049024.0000 - val_loss: 1154714112.0000\n",
      "Epoch 1553/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 267596544.0000 - val_loss: 1190179328.0000\n",
      "Epoch 1554/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 277198592.0000 - val_loss: 1135874816.0000\n",
      "Epoch 1555/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 278043008.0000 - val_loss: 1152816384.0000\n",
      "Epoch 1556/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 273129568.0000 - val_loss: 1197089920.0000\n",
      "Epoch 1557/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 296619648.0000 - val_loss: 1178834432.0000\n",
      "Epoch 1558/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 274063840.0000 - val_loss: 1152552832.0000\n",
      "Epoch 1559/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 276605344.0000 - val_loss: 1175805440.0000\n",
      "Epoch 1560/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 285709632.0000 - val_loss: 1198197504.0000\n",
      "Epoch 1561/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 290405728.0000 - val_loss: 1144506880.0000\n",
      "Epoch 1562/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 276597632.0000 - val_loss: 1189304064.0000\n",
      "Epoch 1563/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 270603200.0000 - val_loss: 1158906496.0000\n",
      "Epoch 1564/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 265154048.0000 - val_loss: 1163304576.0000\n",
      "Epoch 1565/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 269951072.0000 - val_loss: 1173516032.0000\n",
      "Epoch 1566/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 274546816.0000 - val_loss: 1155347712.0000\n",
      "Epoch 1567/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 262609008.0000 - val_loss: 1193043072.0000\n",
      "Epoch 1568/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 288047328.0000 - val_loss: 1143722240.0000\n",
      "Epoch 1569/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 269312800.0000 - val_loss: 1159407616.0000\n",
      "Epoch 1570/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 265439008.0000 - val_loss: 1162009472.0000\n",
      "Epoch 1571/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 267785232.0000 - val_loss: 1186169472.0000\n",
      "Epoch 1572/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 276230144.0000 - val_loss: 1161131008.0000\n",
      "Epoch 1573/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 269912736.0000 - val_loss: 1158628096.0000\n",
      "Epoch 1574/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 267263872.0000 - val_loss: 1179791488.0000\n",
      "Epoch 1575/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 287499488.0000 - val_loss: 1150732288.0000\n",
      "Epoch 1576/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 272735488.0000 - val_loss: 1162862336.0000\n",
      "Epoch 1577/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 262732352.0000 - val_loss: 1186095360.0000\n",
      "Epoch 1578/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 267549536.0000 - val_loss: 1150725376.0000\n",
      "Epoch 1579/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 270475936.0000 - val_loss: 1167264512.0000\n",
      "Epoch 1580/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 275015744.0000 - val_loss: 1159687296.0000\n",
      "Epoch 1581/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 278393440.0000 - val_loss: 1151608320.0000\n",
      "Epoch 1582/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 273386880.0000 - val_loss: 1150318976.0000\n",
      "Epoch 1583/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 267589488.0000 - val_loss: 1154692992.0000\n",
      "Epoch 1584/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 279795648.0000 - val_loss: 1143884544.0000\n",
      "Epoch 1585/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 267318464.0000 - val_loss: 1151051264.0000\n",
      "Epoch 1586/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 265935664.0000 - val_loss: 1163912832.0000\n",
      "Epoch 1587/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 272836384.0000 - val_loss: 1157802112.0000\n",
      "Epoch 1588/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 271293792.0000 - val_loss: 1173696768.0000\n",
      "Epoch 1589/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 265388112.0000 - val_loss: 1151304960.0000\n",
      "Epoch 1590/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 271318976.0000 - val_loss: 1172964352.0000\n",
      "Epoch 1591/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 274931968.0000 - val_loss: 1138458112.0000\n",
      "Epoch 1592/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 268876672.0000 - val_loss: 1157693696.0000\n",
      "Epoch 1593/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 265263584.0000 - val_loss: 1163893760.0000\n",
      "Epoch 1594/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 268283488.0000 - val_loss: 1186473600.0000\n",
      "Epoch 1595/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 263714464.0000 - val_loss: 1166930688.0000\n",
      "Epoch 1596/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 284334208.0000 - val_loss: 1157197312.0000\n",
      "Epoch 1597/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 262880256.0000 - val_loss: 1176072448.0000\n",
      "Epoch 1598/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 284546336.0000 - val_loss: 1137828352.0000\n",
      "Epoch 1599/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 261164768.0000 - val_loss: 1141901056.0000\n",
      "Epoch 1600/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 277634464.0000 - val_loss: 1154968832.0000\n",
      "Epoch 1601/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 275373728.0000 - val_loss: 1167482624.0000\n",
      "Epoch 1602/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 267252544.0000 - val_loss: 1161435776.0000\n",
      "Epoch 1603/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 276992096.0000 - val_loss: 1144181376.0000\n",
      "Epoch 1604/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 268911680.0000 - val_loss: 1143723648.0000\n",
      "Epoch 1605/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 271856320.0000 - val_loss: 1235009024.0000\n",
      "Epoch 1606/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 265923728.0000 - val_loss: 1203080832.0000\n",
      "Epoch 1607/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 267763440.0000 - val_loss: 1242223488.0000\n",
      "Epoch 1608/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 292214176.0000 - val_loss: 1149979904.0000\n",
      "Epoch 1609/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 269075936.0000 - val_loss: 1152594176.0000\n",
      "Epoch 1610/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 272081600.0000 - val_loss: 1192567552.0000\n",
      "Epoch 1611/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 272432608.0000 - val_loss: 1150631168.0000\n",
      "Epoch 1612/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 274780768.0000 - val_loss: 1198595200.0000\n",
      "Epoch 1613/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 276251840.0000 - val_loss: 1162428416.0000\n",
      "Epoch 1614/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 262159280.0000 - val_loss: 1163202048.0000\n",
      "Epoch 1615/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 262329632.0000 - val_loss: 1146214528.0000\n",
      "Epoch 1616/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 273717888.0000 - val_loss: 1166116480.0000\n",
      "Epoch 1617/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 265077504.0000 - val_loss: 1268295296.0000\n",
      "Epoch 1618/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 263437232.0000 - val_loss: 1176305792.0000\n",
      "Epoch 1619/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 274058496.0000 - val_loss: 1145119488.0000\n",
      "Epoch 1620/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 263414144.0000 - val_loss: 1152578560.0000\n",
      "Epoch 1621/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 263538064.0000 - val_loss: 1180267776.0000\n",
      "Epoch 1622/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 279347136.0000 - val_loss: 1168195584.0000\n",
      "Epoch 1623/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 256310656.0000 - val_loss: 1188772736.0000\n",
      "Epoch 1624/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 262442368.0000 - val_loss: 1138415872.0000\n",
      "Epoch 1625/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 268881376.0000 - val_loss: 1190443904.0000\n",
      "Epoch 1626/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 267544208.0000 - val_loss: 1183879552.0000\n",
      "Epoch 1627/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 262391712.0000 - val_loss: 1137784192.0000\n",
      "Epoch 1628/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 281078816.0000 - val_loss: 1160302464.0000\n",
      "Epoch 1629/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 278242816.0000 - val_loss: 1142286464.0000\n",
      "Epoch 1630/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 254438416.0000 - val_loss: 1163452672.0000\n",
      "Epoch 1631/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 276336032.0000 - val_loss: 1142172160.0000\n",
      "Epoch 1632/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 266416976.0000 - val_loss: 1218867712.0000\n",
      "Epoch 1633/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 277242368.0000 - val_loss: 1148022272.0000\n",
      "Epoch 1634/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 261249776.0000 - val_loss: 1159073536.0000\n",
      "Epoch 1635/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 286639424.0000 - val_loss: 1140279168.0000\n",
      "Epoch 1636/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 274799104.0000 - val_loss: 1154724992.0000\n",
      "Epoch 1637/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 278415168.0000 - val_loss: 1191333376.0000\n",
      "Epoch 1638/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 259988752.0000 - val_loss: 1137756928.0000\n",
      "Epoch 1639/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 259497552.0000 - val_loss: 1153223552.0000\n",
      "Epoch 1640/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 281100000.0000 - val_loss: 1138284288.0000\n",
      "Epoch 1641/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 279321472.0000 - val_loss: 1159054464.0000\n",
      "Epoch 1642/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 274757952.0000 - val_loss: 1150741120.0000\n",
      "Epoch 1643/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 262359536.0000 - val_loss: 1189703040.0000\n",
      "Epoch 1644/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 264270544.0000 - val_loss: 1129348736.0000\n",
      "Epoch 1645/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 256017968.0000 - val_loss: 1176628224.0000\n",
      "Epoch 1646/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 257553424.0000 - val_loss: 1152383360.0000\n",
      "Epoch 1647/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 251340384.0000 - val_loss: 1143894144.0000\n",
      "Epoch 1648/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 261953472.0000 - val_loss: 1143304448.0000\n",
      "Epoch 1649/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 254291232.0000 - val_loss: 1261928832.0000\n",
      "Epoch 1650/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 260817024.0000 - val_loss: 1194094592.0000\n",
      "Epoch 1651/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 258114336.0000 - val_loss: 1148109184.0000\n",
      "Epoch 1652/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 248323664.0000 - val_loss: 1129722368.0000\n",
      "Epoch 1653/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 261697696.0000 - val_loss: 1132395264.0000\n",
      "Epoch 1654/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 258103680.0000 - val_loss: 1179899520.0000\n",
      "Epoch 1655/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 259652560.0000 - val_loss: 1139565952.0000\n",
      "Epoch 1656/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 257611040.0000 - val_loss: 1154532736.0000\n",
      "Epoch 1657/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 264243568.0000 - val_loss: 1142069376.0000\n",
      "Epoch 1658/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 256472624.0000 - val_loss: 1155705984.0000\n",
      "Epoch 1659/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 258050656.0000 - val_loss: 1151035648.0000\n",
      "Epoch 1660/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 270411744.0000 - val_loss: 1210025856.0000\n",
      "Epoch 1661/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 268335360.0000 - val_loss: 1133978624.0000\n",
      "Epoch 1662/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 256766848.0000 - val_loss: 1144372096.0000\n",
      "Epoch 1663/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 260093568.0000 - val_loss: 1136880384.0000\n",
      "Epoch 1664/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 269018496.0000 - val_loss: 1185402496.0000\n",
      "Epoch 1665/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 260014144.0000 - val_loss: 1153538176.0000\n",
      "Epoch 1666/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 267786688.0000 - val_loss: 1215872128.0000\n",
      "Epoch 1667/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 265293072.0000 - val_loss: 1171969408.0000\n",
      "Epoch 1668/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 256847344.0000 - val_loss: 1113506944.0000\n",
      "Epoch 1669/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 250864256.0000 - val_loss: 1236047744.0000\n",
      "Epoch 1670/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 251883200.0000 - val_loss: 1129608704.0000\n",
      "Epoch 1671/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 246926768.0000 - val_loss: 1122723456.0000\n",
      "Epoch 1672/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 259990528.0000 - val_loss: 1139744512.0000\n",
      "Epoch 1673/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 273476960.0000 - val_loss: 1136980224.0000\n",
      "Epoch 1674/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 252261344.0000 - val_loss: 1138865536.0000\n",
      "Epoch 1675/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 255456992.0000 - val_loss: 1138657536.0000\n",
      "Epoch 1676/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 272627360.0000 - val_loss: 1142919552.0000\n",
      "Epoch 1677/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 270160864.0000 - val_loss: 1152932480.0000\n",
      "Epoch 1678/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 244667424.0000 - val_loss: 1152596224.0000\n",
      "Epoch 1679/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 252247808.0000 - val_loss: 1148313344.0000\n",
      "Epoch 1680/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 250366160.0000 - val_loss: 1136731776.0000\n",
      "Epoch 1681/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 2ms/step - loss: 253076976.0000 - val_loss: 1183005952.0000\n",
      "Epoch 1682/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 254900320.0000 - val_loss: 1197472128.0000\n",
      "Epoch 1683/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 252369216.0000 - val_loss: 1170030208.0000\n",
      "Epoch 1684/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 263657120.0000 - val_loss: 1168413184.0000\n",
      "Epoch 1685/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 258733440.0000 - val_loss: 1154538496.0000\n",
      "Epoch 1686/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 256418592.0000 - val_loss: 1168305408.0000\n",
      "Epoch 1687/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 269667008.0000 - val_loss: 1193458688.0000\n",
      "Epoch 1688/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 268263088.0000 - val_loss: 1122068992.0000\n",
      "Epoch 1689/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 259561328.0000 - val_loss: 1135650816.0000\n",
      "Epoch 1690/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 248486832.0000 - val_loss: 1143854592.0000\n",
      "Epoch 1691/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 266587456.0000 - val_loss: 1132245888.0000\n",
      "Epoch 1692/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 251697168.0000 - val_loss: 1127615616.0000\n",
      "Epoch 1693/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 260293200.0000 - val_loss: 1236639744.0000\n",
      "Epoch 1694/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 257239600.0000 - val_loss: 1143738368.0000\n",
      "Epoch 1695/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 252527248.0000 - val_loss: 1192241152.0000\n",
      "Epoch 1696/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 281906272.0000 - val_loss: 1118951168.0000\n",
      "Epoch 1697/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 252132560.0000 - val_loss: 1110568960.0000\n",
      "Epoch 1698/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 253065040.0000 - val_loss: 1139660032.0000\n",
      "Epoch 1699/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 272990208.0000 - val_loss: 1131921152.0000\n",
      "Epoch 1700/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 246812576.0000 - val_loss: 1127173504.0000\n",
      "Epoch 1701/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 250946112.0000 - val_loss: 1148779904.0000\n",
      "Epoch 1702/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 260598032.0000 - val_loss: 1168478848.0000\n",
      "Epoch 1703/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 267228512.0000 - val_loss: 1134284544.0000\n",
      "Epoch 1704/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 249573216.0000 - val_loss: 1164340352.0000\n",
      "Epoch 1705/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 249339728.0000 - val_loss: 1107969920.0000\n",
      "Epoch 1706/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 260255504.0000 - val_loss: 1188616704.0000\n",
      "Epoch 1707/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 258366624.0000 - val_loss: 1118482816.0000\n",
      "Epoch 1708/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 254579952.0000 - val_loss: 1182583424.0000\n",
      "Epoch 1709/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 263815104.0000 - val_loss: 1133873024.0000\n",
      "Epoch 1710/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 241364704.0000 - val_loss: 1134512128.0000\n",
      "Epoch 1711/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 245432576.0000 - val_loss: 1115785216.0000\n",
      "Epoch 1712/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 254424528.0000 - val_loss: 1211447296.0000\n",
      "Epoch 1713/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 245176944.0000 - val_loss: 1126881664.0000\n",
      "Epoch 1714/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 259516192.0000 - val_loss: 1141863936.0000\n",
      "Epoch 1715/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 261005216.0000 - val_loss: 1151923968.0000\n",
      "Epoch 1716/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 247537744.0000 - val_loss: 1152855168.0000\n",
      "Epoch 1717/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 253414880.0000 - val_loss: 1155536640.0000\n",
      "Epoch 1718/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 250612688.0000 - val_loss: 1124269568.0000\n",
      "Epoch 1719/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 263065824.0000 - val_loss: 1115180800.0000\n",
      "Epoch 1720/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 241323280.0000 - val_loss: 1178236672.0000\n",
      "Epoch 1721/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 267432336.0000 - val_loss: 1123771136.0000\n",
      "Epoch 1722/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 236301472.0000 - val_loss: 1126070656.0000\n",
      "Epoch 1723/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 241876176.0000 - val_loss: 1148481152.0000\n",
      "Epoch 1724/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 242777904.0000 - val_loss: 1145155200.0000\n",
      "Epoch 1725/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 254336624.0000 - val_loss: 1146566400.0000\n",
      "Epoch 1726/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 253005440.0000 - val_loss: 1130683776.0000\n",
      "Epoch 1727/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 256366768.0000 - val_loss: 1106485888.0000\n",
      "Epoch 1728/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 244573440.0000 - val_loss: 1127922560.0000\n",
      "Epoch 1729/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 244699984.0000 - val_loss: 1118303616.0000\n",
      "Epoch 1730/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 248089472.0000 - val_loss: 1123986944.0000\n",
      "Epoch 1731/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 250887568.0000 - val_loss: 1154888704.0000\n",
      "Epoch 1732/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 251262784.0000 - val_loss: 1153364992.0000\n",
      "Epoch 1733/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 235443520.0000 - val_loss: 1120666496.0000\n",
      "Epoch 1734/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 252904784.0000 - val_loss: 1153994496.0000\n",
      "Epoch 1735/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 251672912.0000 - val_loss: 1127111040.0000\n",
      "Epoch 1736/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 252340832.0000 - val_loss: 1127148416.0000\n",
      "Epoch 1737/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 267850064.0000 - val_loss: 1140210816.0000\n",
      "Epoch 1738/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 250766592.0000 - val_loss: 1120166656.0000\n",
      "Epoch 1739/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 246618768.0000 - val_loss: 1212665472.0000\n",
      "Epoch 1740/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 247376432.0000 - val_loss: 1115033472.0000\n",
      "Epoch 1741/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 243039024.0000 - val_loss: 1132060160.0000\n",
      "Epoch 1742/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 238640912.0000 - val_loss: 1125243648.0000\n",
      "Epoch 1743/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 256784048.0000 - val_loss: 1118685440.0000\n",
      "Epoch 1744/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 257042368.0000 - val_loss: 1111790592.0000\n",
      "Epoch 1745/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 252540352.0000 - val_loss: 1094302464.0000\n",
      "Epoch 1746/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 243666880.0000 - val_loss: 1114470784.0000\n",
      "Epoch 1747/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 249469616.0000 - val_loss: 1098968192.0000\n",
      "Epoch 1748/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 240327552.0000 - val_loss: 1129470592.0000\n",
      "Epoch 1749/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 255179808.0000 - val_loss: 1115475840.0000\n",
      "Epoch 1750/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 253260560.0000 - val_loss: 1128899968.0000\n",
      "Epoch 1751/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 241057776.0000 - val_loss: 1129530496.0000\n",
      "Epoch 1752/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 252409424.0000 - val_loss: 1133696256.0000\n",
      "Epoch 1753/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 241078240.0000 - val_loss: 1128144896.0000\n",
      "Epoch 1754/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 245521424.0000 - val_loss: 1129954176.0000\n",
      "Epoch 1755/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 258350672.0000 - val_loss: 1115118336.0000\n",
      "Epoch 1756/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 244794480.0000 - val_loss: 1139937920.0000\n",
      "Epoch 1757/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 240373936.0000 - val_loss: 1125237888.0000\n",
      "Epoch 1758/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 271882336.0000 - val_loss: 1157175680.0000\n",
      "Epoch 1759/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 237114912.0000 - val_loss: 1131225600.0000\n",
      "Epoch 1760/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 236339424.0000 - val_loss: 1145039232.0000\n",
      "Epoch 1761/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 240375328.0000 - val_loss: 1102362880.0000\n",
      "Epoch 1762/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 248152576.0000 - val_loss: 1131052544.0000\n",
      "Epoch 1763/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 238144304.0000 - val_loss: 1132695552.0000\n",
      "Epoch 1764/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 245014544.0000 - val_loss: 1112620672.0000\n",
      "Epoch 1765/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 249304992.0000 - val_loss: 1138580224.0000\n",
      "Epoch 1766/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 256596032.0000 - val_loss: 1137722368.0000\n",
      "Epoch 1767/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 238737488.0000 - val_loss: 1111439104.0000\n",
      "Epoch 1768/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 243905024.0000 - val_loss: 1119368320.0000\n",
      "Epoch 1769/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 241300496.0000 - val_loss: 1147142912.0000\n",
      "Epoch 1770/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 252581168.0000 - val_loss: 1109772800.0000\n",
      "Epoch 1771/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 239085296.0000 - val_loss: 1139955712.0000\n",
      "Epoch 1772/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 249130400.0000 - val_loss: 1148937216.0000\n",
      "Epoch 1773/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 229444336.0000 - val_loss: 1132338560.0000\n",
      "Epoch 1774/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 235316208.0000 - val_loss: 1149995008.0000\n",
      "Epoch 1775/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 249957712.0000 - val_loss: 1123464320.0000\n",
      "Epoch 1776/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 236514944.0000 - val_loss: 1146364032.0000\n",
      "Epoch 1777/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 247592704.0000 - val_loss: 1134038016.0000\n",
      "Epoch 1778/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 242854304.0000 - val_loss: 1129786752.0000\n",
      "Epoch 1779/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 244198080.0000 - val_loss: 1132015232.0000\n",
      "Epoch 1780/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 250859040.0000 - val_loss: 1144354432.0000\n",
      "Epoch 1781/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 239338272.0000 - val_loss: 1184264832.0000\n",
      "Epoch 1782/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 243314736.0000 - val_loss: 1128910976.0000\n",
      "Epoch 1783/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 238989280.0000 - val_loss: 1142297472.0000\n",
      "Epoch 1784/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 241444512.0000 - val_loss: 1130648320.0000\n",
      "Epoch 1785/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 233955904.0000 - val_loss: 1165751552.0000\n",
      "Epoch 1786/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 248723584.0000 - val_loss: 1163510400.0000\n",
      "Epoch 1787/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 231453264.0000 - val_loss: 1115917696.0000\n",
      "Epoch 1788/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 243061904.0000 - val_loss: 1121205760.0000\n",
      "Epoch 1789/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 245010400.0000 - val_loss: 1116414848.0000\n",
      "Epoch 1790/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 235239072.0000 - val_loss: 1132881536.0000\n",
      "Epoch 1791/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 237092544.0000 - val_loss: 1133472896.0000\n",
      "Epoch 1792/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 250455472.0000 - val_loss: 1122085376.0000\n",
      "Epoch 1793/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 239875056.0000 - val_loss: 1115124352.0000\n",
      "Epoch 1794/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 239022384.0000 - val_loss: 1145441792.0000\n",
      "Epoch 1795/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 236689952.0000 - val_loss: 1228994944.0000\n",
      "Epoch 1796/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 267488880.0000 - val_loss: 1163886464.0000\n",
      "Epoch 1797/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 234733408.0000 - val_loss: 1158397056.0000\n",
      "Epoch 1798/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 238844048.0000 - val_loss: 1219646208.0000\n",
      "Epoch 1799/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 252701104.0000 - val_loss: 1135295872.0000\n",
      "Epoch 1800/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 247821936.0000 - val_loss: 1287253888.0000\n",
      "Epoch 1801/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 243005008.0000 - val_loss: 1137222016.0000\n",
      "Epoch 1802/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 244224176.0000 - val_loss: 1115869440.0000\n",
      "Epoch 1803/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 252182992.0000 - val_loss: 1130608128.0000\n",
      "Epoch 1804/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 243768016.0000 - val_loss: 1159758720.0000\n",
      "Epoch 1805/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 232346480.0000 - val_loss: 1120756864.0000\n",
      "Epoch 1806/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 245490336.0000 - val_loss: 1152387072.0000\n",
      "Epoch 1807/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 226556224.0000 - val_loss: 1128711936.0000\n",
      "Epoch 1808/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 235541088.0000 - val_loss: 1135034880.0000\n",
      "Epoch 1809/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 241219792.0000 - val_loss: 1155793920.0000\n",
      "Epoch 1810/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 247109248.0000 - val_loss: 1117348608.0000\n",
      "Epoch 1811/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 230372672.0000 - val_loss: 1156838528.0000\n",
      "Epoch 1812/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 231210064.0000 - val_loss: 1116478464.0000\n",
      "Epoch 1813/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 234821872.0000 - val_loss: 1127574144.0000\n",
      "Epoch 1814/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 249021792.0000 - val_loss: 1265044992.0000\n",
      "Epoch 1815/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 247700432.0000 - val_loss: 1139766016.0000\n",
      "Epoch 1816/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 234249616.0000 - val_loss: 1186247040.0000\n",
      "Epoch 1817/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 253664864.0000 - val_loss: 1135954688.0000\n",
      "Epoch 1818/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 256108032.0000 - val_loss: 1160597888.0000\n",
      "Epoch 1819/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 238757104.0000 - val_loss: 1123559424.0000\n",
      "Epoch 1820/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 242874256.0000 - val_loss: 1129512448.0000\n",
      "Epoch 1821/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 236456048.0000 - val_loss: 1119137408.0000\n",
      "Epoch 1822/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 234589280.0000 - val_loss: 1110487296.0000\n",
      "Epoch 1823/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 229984480.0000 - val_loss: 1116074624.0000\n",
      "Epoch 1824/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 240949632.0000 - val_loss: 1110037376.0000\n",
      "Epoch 1825/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 223855200.0000 - val_loss: 1138495360.0000\n",
      "Epoch 1826/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 243559152.0000 - val_loss: 1132357376.0000\n",
      "Epoch 1827/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 230845728.0000 - val_loss: 1144238848.0000\n",
      "Epoch 1828/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 236803648.0000 - val_loss: 1170171904.0000\n",
      "Epoch 1829/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 239763488.0000 - val_loss: 1155601408.0000\n",
      "Epoch 1830/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 239402256.0000 - val_loss: 1115337856.0000\n",
      "Epoch 1831/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 245180112.0000 - val_loss: 1230137216.0000\n",
      "Epoch 1832/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 245490416.0000 - val_loss: 1168322176.0000\n",
      "Epoch 1833/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 239272640.0000 - val_loss: 1210513024.0000\n",
      "Epoch 1834/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 243629536.0000 - val_loss: 1159019392.0000\n",
      "Epoch 1835/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 253969520.0000 - val_loss: 1183938432.0000\n",
      "Epoch 1836/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 253086080.0000 - val_loss: 1209702144.0000\n",
      "Epoch 1837/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 237761824.0000 - val_loss: 1125289600.0000\n",
      "Epoch 1838/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 244855520.0000 - val_loss: 1129277696.0000\n",
      "Epoch 1839/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 235069952.0000 - val_loss: 1140714880.0000\n",
      "Epoch 1840/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 234372992.0000 - val_loss: 1163856896.0000\n",
      "Epoch 1841/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 242047648.0000 - val_loss: 1103680640.0000\n",
      "Epoch 1842/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 233783344.0000 - val_loss: 1115816960.0000\n",
      "Epoch 1843/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 241183232.0000 - val_loss: 1140790912.0000\n",
      "Epoch 1844/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 234421904.0000 - val_loss: 1161802368.0000\n",
      "Epoch 1845/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 233140304.0000 - val_loss: 1128738432.0000\n",
      "Epoch 1846/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 233923424.0000 - val_loss: 1162563840.0000\n",
      "Epoch 1847/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 242335296.0000 - val_loss: 1150550784.0000\n",
      "Epoch 1848/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 230816288.0000 - val_loss: 1146803968.0000\n",
      "Epoch 1849/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 234580240.0000 - val_loss: 1159249792.0000\n",
      "Epoch 1850/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 237224576.0000 - val_loss: 1118822912.0000\n",
      "Epoch 1851/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 244397552.0000 - val_loss: 1111931392.0000\n",
      "Epoch 1852/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 238483568.0000 - val_loss: 1121659520.0000\n",
      "Epoch 1853/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 251897184.0000 - val_loss: 1148402816.0000\n",
      "Epoch 1854/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 240651328.0000 - val_loss: 1191917056.0000\n",
      "Epoch 1855/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 223268480.0000 - val_loss: 1159008768.0000\n",
      "Epoch 1856/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 238283248.0000 - val_loss: 1119668992.0000\n",
      "Epoch 1857/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 237331744.0000 - val_loss: 1127805312.0000\n",
      "Epoch 1858/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 247545264.0000 - val_loss: 1112918912.0000\n",
      "Epoch 1859/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 240367072.0000 - val_loss: 1168207232.0000\n",
      "Epoch 1860/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 232411776.0000 - val_loss: 1117228032.0000\n",
      "Epoch 1861/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 236889840.0000 - val_loss: 1134437888.0000\n",
      "Epoch 1862/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 237931056.0000 - val_loss: 1114041600.0000\n",
      "Epoch 1863/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 230395840.0000 - val_loss: 1127335040.0000\n",
      "Epoch 1864/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 231386976.0000 - val_loss: 1135056512.0000\n",
      "Epoch 1865/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 245085584.0000 - val_loss: 1132791168.0000\n",
      "Epoch 1866/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 230262016.0000 - val_loss: 1126904576.0000\n",
      "Epoch 1867/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 241648224.0000 - val_loss: 1152936320.0000\n",
      "Epoch 1868/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 233658160.0000 - val_loss: 1109134592.0000\n",
      "Epoch 1869/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 242595824.0000 - val_loss: 1113510272.0000\n",
      "Epoch 1870/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 220718320.0000 - val_loss: 1135734016.0000\n",
      "Epoch 1871/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 226653792.0000 - val_loss: 1207802368.0000\n",
      "Epoch 1872/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 239552496.0000 - val_loss: 1168608256.0000\n",
      "Epoch 1873/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 236149328.0000 - val_loss: 1196600704.0000\n",
      "Epoch 1874/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 248134720.0000 - val_loss: 1135854464.0000\n",
      "Epoch 1875/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 229744432.0000 - val_loss: 1116845056.0000\n",
      "Epoch 1876/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 235055120.0000 - val_loss: 1132916736.0000\n",
      "Epoch 1877/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 227526208.0000 - val_loss: 1299928192.0000\n",
      "Epoch 1878/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 247820400.0000 - val_loss: 1111376640.0000\n",
      "Epoch 1879/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 232813360.0000 - val_loss: 1170087168.0000\n",
      "Epoch 1880/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 234342336.0000 - val_loss: 1139250176.0000\n",
      "Epoch 1881/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 229258688.0000 - val_loss: 1120673280.0000\n",
      "Epoch 1882/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 255851248.0000 - val_loss: 1119159808.0000\n",
      "Epoch 1883/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 241256032.0000 - val_loss: 1124499584.0000\n",
      "Epoch 1884/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 241816752.0000 - val_loss: 1133206528.0000\n",
      "Epoch 1885/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 237416480.0000 - val_loss: 1150984448.0000\n",
      "Epoch 1886/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 228049120.0000 - val_loss: 1120910208.0000\n",
      "Epoch 1887/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 228811712.0000 - val_loss: 1146157952.0000\n",
      "Epoch 1888/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 223726080.0000 - val_loss: 1163198208.0000\n",
      "Epoch 1889/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 237351120.0000 - val_loss: 1132011136.0000\n",
      "Epoch 1890/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 239069584.0000 - val_loss: 1262142720.0000\n",
      "Epoch 1891/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 263114240.0000 - val_loss: 1151266688.0000\n",
      "Epoch 1892/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 227382896.0000 - val_loss: 1144481536.0000\n",
      "Epoch 1893/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 231170336.0000 - val_loss: 1115654400.0000\n",
      "Epoch 1894/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 229685632.0000 - val_loss: 1157325056.0000\n",
      "Epoch 1895/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 233398064.0000 - val_loss: 1197156864.0000\n",
      "Epoch 1896/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 241018720.0000 - val_loss: 1216124928.0000\n",
      "Epoch 1897/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 235995504.0000 - val_loss: 1182429568.0000\n",
      "Epoch 1898/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 228941456.0000 - val_loss: 1125582208.0000\n",
      "Epoch 1899/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 232572576.0000 - val_loss: 1225791744.0000\n",
      "Epoch 1900/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 225872656.0000 - val_loss: 1126579456.0000\n",
      "Epoch 1901/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 235986096.0000 - val_loss: 1127087360.0000\n",
      "Epoch 1902/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 228170176.0000 - val_loss: 1102153216.0000\n",
      "Epoch 1903/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 223409680.0000 - val_loss: 1132797568.0000\n",
      "Epoch 1904/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 244208976.0000 - val_loss: 1169514496.0000\n",
      "Epoch 1905/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 241326400.0000 - val_loss: 1162901504.0000\n",
      "Epoch 1906/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 222011216.0000 - val_loss: 1116780288.0000\n",
      "Epoch 1907/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 222038800.0000 - val_loss: 1126583040.0000\n",
      "Epoch 1908/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 240191616.0000 - val_loss: 1130010496.0000\n",
      "Epoch 1909/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 241861696.0000 - val_loss: 1168197760.0000\n",
      "Epoch 1910/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 226462272.0000 - val_loss: 1159951872.0000\n",
      "Epoch 1911/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 239226080.0000 - val_loss: 1176121344.0000\n",
      "Epoch 1912/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 226075360.0000 - val_loss: 1141984000.0000\n",
      "Epoch 1913/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 232074800.0000 - val_loss: 1128830080.0000\n",
      "Epoch 1914/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 218608160.0000 - val_loss: 1119837568.0000\n",
      "Epoch 1915/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 236110368.0000 - val_loss: 1272452992.0000\n",
      "Epoch 1916/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 242308896.0000 - val_loss: 1149316992.0000\n",
      "Epoch 1917/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 243115008.0000 - val_loss: 1152207616.0000\n",
      "Epoch 1918/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 229223248.0000 - val_loss: 1130237952.0000\n",
      "Epoch 1919/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 239445344.0000 - val_loss: 1135616256.0000\n",
      "Epoch 1920/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 233958640.0000 - val_loss: 1126090880.0000\n",
      "Epoch 1921/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 229204704.0000 - val_loss: 1158388992.0000\n",
      "Epoch 1922/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 236552400.0000 - val_loss: 1113812736.0000\n",
      "Epoch 1923/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 237891984.0000 - val_loss: 1097606016.0000\n",
      "Epoch 1924/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 232035216.0000 - val_loss: 1147629696.0000\n",
      "Epoch 1925/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 227854096.0000 - val_loss: 1118472448.0000\n",
      "Epoch 1926/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 228391520.0000 - val_loss: 1330722048.0000\n",
      "Epoch 1927/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 230041648.0000 - val_loss: 1142166784.0000\n",
      "Epoch 1928/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 225385888.0000 - val_loss: 1133821184.0000\n",
      "Epoch 1929/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 237057600.0000 - val_loss: 1163551232.0000\n",
      "Epoch 1930/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 226805552.0000 - val_loss: 1107753472.0000\n",
      "Epoch 1931/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 240939216.0000 - val_loss: 1143576576.0000\n",
      "Epoch 1932/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 227933184.0000 - val_loss: 1176137344.0000\n",
      "Epoch 1933/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 245384688.0000 - val_loss: 1098208256.0000\n",
      "Epoch 1934/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 225638208.0000 - val_loss: 1133434880.0000\n",
      "Epoch 1935/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 226699712.0000 - val_loss: 1196183552.0000\n",
      "Epoch 1936/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 246433712.0000 - val_loss: 1133162240.0000\n",
      "Epoch 1937/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 233700784.0000 - val_loss: 1149480448.0000\n",
      "Epoch 1938/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 214830864.0000 - val_loss: 1180550144.0000\n",
      "Epoch 1939/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 229293504.0000 - val_loss: 1137855104.0000\n",
      "Epoch 1940/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 232063392.0000 - val_loss: 1141579136.0000\n",
      "Epoch 1941/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 232470288.0000 - val_loss: 1138112896.0000\n",
      "Epoch 1942/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 235294176.0000 - val_loss: 1102043008.0000\n",
      "Epoch 1943/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 220443008.0000 - val_loss: 1116602112.0000\n",
      "Epoch 1944/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 233743280.0000 - val_loss: 1139973504.0000\n",
      "Epoch 1945/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 223358672.0000 - val_loss: 1107400192.0000\n",
      "Epoch 1946/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 223908928.0000 - val_loss: 1107434368.0000\n",
      "Epoch 1947/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 226313440.0000 - val_loss: 1132117504.0000\n",
      "Epoch 1948/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 227329968.0000 - val_loss: 1136896768.0000\n",
      "Epoch 1949/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/114 [==============================] - 0s 1ms/step - loss: 219617184.0000 - val_loss: 1112143232.0000\n",
      "Epoch 1950/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 240052448.0000 - val_loss: 1100150144.0000\n",
      "Epoch 1951/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 219128032.0000 - val_loss: 1101408000.0000\n",
      "Epoch 1952/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 218176336.0000 - val_loss: 1167961728.0000\n",
      "Epoch 1953/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 234408528.0000 - val_loss: 1151451904.0000\n",
      "Epoch 1954/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 235170992.0000 - val_loss: 1182095488.0000\n",
      "Epoch 1955/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 236033248.0000 - val_loss: 1130087808.0000\n",
      "Epoch 1956/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 222298800.0000 - val_loss: 1125442048.0000\n",
      "Epoch 1957/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 235109872.0000 - val_loss: 1113766144.0000\n",
      "Epoch 1958/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 224538224.0000 - val_loss: 1137395456.0000\n",
      "Epoch 1959/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 219514768.0000 - val_loss: 1108495104.0000\n",
      "Epoch 1960/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 230389840.0000 - val_loss: 1122353792.0000\n",
      "Epoch 1961/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 219014992.0000 - val_loss: 1323863040.0000\n",
      "Epoch 1962/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 234108736.0000 - val_loss: 1142550400.0000\n",
      "Epoch 1963/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 222698208.0000 - val_loss: 1166953728.0000\n",
      "Epoch 1964/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 218831872.0000 - val_loss: 1146820992.0000\n",
      "Epoch 1965/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 232065616.0000 - val_loss: 1138405632.0000\n",
      "Epoch 1966/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 219331392.0000 - val_loss: 1121704704.0000\n",
      "Epoch 1967/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 225735728.0000 - val_loss: 1119118208.0000\n",
      "Epoch 1968/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 226168464.0000 - val_loss: 1110418304.0000\n",
      "Epoch 1969/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 217935840.0000 - val_loss: 1138481920.0000\n",
      "Epoch 1970/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 219484688.0000 - val_loss: 1108979584.0000\n",
      "Epoch 1971/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 229611328.0000 - val_loss: 1126569600.0000\n",
      "Epoch 1972/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 226164272.0000 - val_loss: 1266939392.0000\n",
      "Epoch 1973/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 226708960.0000 - val_loss: 1136327168.0000\n",
      "Epoch 1974/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 222793760.0000 - val_loss: 1142184704.0000\n",
      "Epoch 1975/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 221540880.0000 - val_loss: 1154827392.0000\n",
      "Epoch 1976/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 219628256.0000 - val_loss: 1134549888.0000\n",
      "Epoch 1977/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 223690512.0000 - val_loss: 1165148928.0000\n",
      "Epoch 1978/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 220786224.0000 - val_loss: 1132540544.0000\n",
      "Epoch 1979/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 219428112.0000 - val_loss: 1195997568.0000\n",
      "Epoch 1980/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 219514384.0000 - val_loss: 1160682880.0000\n",
      "Epoch 1981/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 234477968.0000 - val_loss: 1137653760.0000\n",
      "Epoch 1982/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 243275056.0000 - val_loss: 1137034496.0000\n",
      "Epoch 1983/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 210711936.0000 - val_loss: 1132492032.0000\n",
      "Epoch 1984/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 224681680.0000 - val_loss: 1118252416.0000\n",
      "Epoch 1985/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 234237168.0000 - val_loss: 1103215360.0000\n",
      "Epoch 1986/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 245465920.0000 - val_loss: 1124124544.0000\n",
      "Epoch 1987/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 224355312.0000 - val_loss: 1138477696.0000\n",
      "Epoch 1988/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 212824432.0000 - val_loss: 1123193088.0000\n",
      "Epoch 1989/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 222182544.0000 - val_loss: 1105075328.0000\n",
      "Epoch 1990/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 219294832.0000 - val_loss: 1106718592.0000\n",
      "Epoch 1991/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 225946624.0000 - val_loss: 1117856512.0000\n",
      "Epoch 1992/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 225738080.0000 - val_loss: 1105897984.0000\n",
      "Epoch 1993/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 221553152.0000 - val_loss: 1123931776.0000\n",
      "Epoch 1994/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 217133744.0000 - val_loss: 1118104832.0000\n",
      "Epoch 1995/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 239417872.0000 - val_loss: 1122968320.0000\n",
      "Epoch 1996/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 232452688.0000 - val_loss: 1220623744.0000\n",
      "Epoch 1997/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 224799280.0000 - val_loss: 1142008448.0000\n",
      "Epoch 1998/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 215111840.0000 - val_loss: 1136407552.0000\n",
      "Epoch 1999/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 234983696.0000 - val_loss: 1197990528.0000\n",
      "Epoch 2000/2000\n",
      "114/114 [==============================] - 0s 1ms/step - loss: 219780640.0000 - val_loss: 1122887296.0000\n"
     ]
    }
   ],
   "source": [
    "#keras.layers.Dense(units, activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)\n",
    "#classifier.add(Dense(6, activation='relu', kernel_initializer='glorot_uniform',input_dim=11))\n",
    "\n",
    "\n",
    "# Initialising the Artifical Neural Network\n",
    "classifier = Sequential()\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(50, kernel_initializer = 'he_uniform',activation='relu',input_dim = 174))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(50, kernel_initializer = 'he_uniform',activation='relu'))\n",
    "\n",
    "# Adding the third hidden layer\n",
    "classifier.add(Dense(50, kernel_initializer = 'he_uniform',activation='relu'))\n",
    "# Adding the output layer\n",
    "classifier.add(Dense(1, kernel_initializer = 'he_uniform'))\n",
    "\n",
    "# Compiling the ANN\n",
    "classifier.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer='Adamax')\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "model_history=classifier.fit(X_train.values, Y_train.values,validation_split=0.20, batch_size = 10, epochs = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3206cdc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 [==============================] - 0s 708us/step\n"
     ]
    }
   ],
   "source": [
    "Y_pred=classifier.predict(df_Test.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fc71487f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create Sample Submission file and Submit using ANN\n",
    "pred_df=pd.DataFrame(Y_pred) #Converting to DF\n",
    "submission_df=pd.read_csv('Project_data/sample_submission.csv') #Reading website's sample as csv\n",
    "datasets=pd.concat([submission_df['Id'],pred_df],axis=1) #Taking the ID from the submission after we deleted it at the beggning\n",
    "datasets.columns=['Id','SalePrice']\n",
    "datasets.to_csv('sample_submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632ef212",
   "metadata": {},
   "source": [
    "# CONGRATZ!\n",
    "WE DID IT!)\n",
    "\n",
    "![ML results](Results/Improvment.JPG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e4733d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
